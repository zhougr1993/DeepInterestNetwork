2017-12-29 13:24:36.910589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-12-29 13:24:36.911356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:84:00.0
totalMemory: 15.89GiB freeMemory: 13.26GiB
2017-12-29 13:24:36.911403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)
[None, 128]
[None, 128]
[None, 128]
test_auc: 0.5233
Epoch 0 Global_step 1000	Train_loss: 0.6966	Eval_AUC: 0.6703
Epoch 0 Global_step 2000	Train_loss: 0.6847	Eval_AUC: 0.6987
Epoch 0 Global_step 3000	Train_loss: 0.6793	Eval_AUC: 0.7128
Epoch 0 Global_step 4000	Train_loss: 0.6735	Eval_AUC: 0.7214
Epoch 0 Global_step 5000	Train_loss: 0.6693	Eval_AUC: 0.7289
Epoch 0 Global_step 6000	Train_loss: 0.6656	Eval_AUC: 0.7344
Epoch 0 Global_step 7000	Train_loss: 0.6616	Eval_AUC: 0.7397
Epoch 0 Global_step 8000	Train_loss: 0.6584	Eval_AUC: 0.7434
Epoch 0 Global_step 9000	Train_loss: 0.6558	Eval_AUC: 0.7458
Epoch 0 Global_step 10000	Train_loss: 0.6521	Eval_AUC: 0.7485
Epoch 0 Global_step 11000	Train_loss: 0.6486	Eval_AUC: 0.7511
Epoch 0 Global_step 12000	Train_loss: 0.6464	Eval_AUC: 0.7526
Epoch 0 Global_step 13000	Train_loss: 0.6444	Eval_AUC: 0.7543
Epoch 0 Global_step 14000	Train_loss: 0.6418	Eval_AUC: 0.7557
Epoch 0 Global_step 15000	Train_loss: 0.6375	Eval_AUC: 0.7570
Epoch 0 Global_step 16000	Train_loss: 0.6365	Eval_AUC: 0.7578
Epoch 0 Global_step 17000	Train_loss: 0.6338	Eval_AUC: 0.7588
Epoch 0 Global_step 18000	Train_loss: 0.6322	Eval_AUC: 0.7605
Epoch 0 Global_step 19000	Train_loss: 0.6296	Eval_AUC: 0.7610
Epoch 0 Global_step 20000	Train_loss: 0.6275	Eval_AUC: 0.7620
Epoch 0 Global_step 21000	Train_loss: 0.6270	Eval_AUC: 0.7622
Epoch 0 Global_step 22000	Train_loss: 0.6229	Eval_AUC: 0.7633
Epoch 0 Global_step 23000	Train_loss: 0.6221	Eval_AUC: 0.7638
Epoch 0 Global_step 24000	Train_loss: 0.6222	Eval_AUC: 0.7651
Epoch 0 Global_step 25000	Train_loss: 0.6199	Eval_AUC: 0.7656
Epoch 0 Global_step 26000	Train_loss: 0.6185	Eval_AUC: 0.7656
Epoch 0 Global_step 27000	Train_loss: 0.6163	Eval_AUC: 0.7658
Epoch 0 Global_step 28000	Train_loss: 0.6161	Eval_AUC: 0.7662
Epoch 0 Global_step 29000	Train_loss: 0.6138	Eval_AUC: 0.7664
Epoch 0 Global_step 30000	Train_loss: 0.6130	Eval_AUC: 0.7669
Epoch 0 Global_step 31000	Train_loss: 0.6116	Eval_AUC: 0.7676
Epoch 0 Global_step 32000	Train_loss: 0.6116	Eval_AUC: 0.7677
Epoch 0 Global_step 33000	Train_loss: 0.6105	Eval_AUC: 0.7679
Epoch 0 Global_step 34000	Train_loss: 0.6071	Eval_AUC: 0.7686
Epoch 0 Global_step 35000	Train_loss: 0.6070	Eval_AUC: 0.7684
Epoch 0 Global_step 36000	Train_loss: 0.6045	Eval_AUC: 0.7685
Epoch 0 Global_step 37000	Train_loss: 0.6051	Eval_AUC: 0.7689
Epoch 0 Global_step 38000	Train_loss: 0.6027	Eval_AUC: 0.7690
Epoch 0 Global_step 39000	Train_loss: 0.6020	Eval_AUC: 0.7690
Epoch 0 Global_step 40000	Train_loss: 0.6004	Eval_AUC: 0.7696
Epoch 0 Global_step 41000	Train_loss: 0.5995	Eval_AUC: 0.7700
Epoch 0 Global_step 42000	Train_loss: 0.5987	Eval_AUC: 0.7700
Epoch 0 Global_step 43000	Train_loss: 0.5985	Eval_AUC: 0.7705
Epoch 0 Global_step 44000	Train_loss: 0.5995	Eval_AUC: 0.7709
Epoch 0 Global_step 45000	Train_loss: 0.5951	Eval_AUC: 0.7710
Epoch 0 Global_step 46000	Train_loss: 0.5972	Eval_AUC: 0.7715
Epoch 0 Global_step 47000	Train_loss: 0.5943	Eval_AUC: 0.7718
Epoch 0 Global_step 48000	Train_loss: 0.5940	Eval_AUC: 0.7718
Epoch 0 Global_step 49000	Train_loss: 0.5917	Eval_AUC: 0.7722
Epoch 0 Global_step 50000	Train_loss: 0.5899	Eval_AUC: 0.7727
Epoch 0 Global_step 51000	Train_loss: 0.5917	Eval_AUC: 0.7729
Epoch 0 Global_step 52000	Train_loss: 0.5913	Eval_AUC: 0.7725
Epoch 0 Global_step 53000	Train_loss: 0.5883	Eval_AUC: 0.7729
Epoch 0 Global_step 54000	Train_loss: 0.5862	Eval_AUC: 0.7728
Epoch 0 Global_step 55000	Train_loss: 0.5883	Eval_AUC: 0.7720
Epoch 0 Global_step 56000	Train_loss: 0.5856	Eval_AUC: 0.7694
Epoch 0 Global_step 57000	Train_loss: 0.5841	Eval_AUC: 0.7667
Epoch 0 Global_step 58000	Train_loss: 0.5818	Eval_AUC: 0.7643
Epoch 0 Global_step 59000	Train_loss: 0.5834	Eval_AUC: 0.7662
Epoch 0 Global_step 60000	Train_loss: 0.5829	Eval_AUC: 0.7658
Epoch 0 Global_step 61000	Train_loss: 0.5786	Eval_AUC: 0.7628
Epoch 0 Global_step 62000	Train_loss: 0.5806	Eval_AUC: 0.7662
Epoch 0 Global_step 63000	Train_loss: 0.5794	Eval_AUC: 0.7697
Epoch 0 Global_step 64000	Train_loss: 0.5787	Eval_AUC: 0.7631
Epoch 0 Global_step 65000	Train_loss: 0.5786	Eval_AUC: 0.7677
Epoch 0 Global_step 66000	Train_loss: 0.5810	Eval_AUC: 0.7623
Epoch 0 Global_step 67000	Train_loss: 0.5780	Eval_AUC: 0.7684
Epoch 0 Global_step 68000	Train_loss: 0.5772	Eval_AUC: 0.7652
Epoch 0 Global_step 69000	Train_loss: 0.5773	Eval_AUC: 0.7652
Epoch 0 Global_step 70000	Train_loss: 0.5762	Eval_AUC: 0.7631
Epoch 0 Global_step 71000	Train_loss: 0.5771	Eval_AUC: 0.7674
Epoch 0 Global_step 72000	Train_loss: 0.5742	Eval_AUC: 0.7714
Epoch 0 Global_step 73000	Train_loss: 0.5759	Eval_AUC: 0.7666
Epoch 0 Global_step 74000	Train_loss: 0.5735	Eval_AUC: 0.7709
Epoch 0 Global_step 75000	Train_loss: 0.5746	Eval_AUC: 0.7731
Epoch 0 Global_step 76000	Train_loss: 0.5752	Eval_AUC: 0.7746
Epoch 0 Global_step 77000	Train_loss: 0.5699	Eval_AUC: 0.7699
Epoch 0 Global_step 78000	Train_loss: 0.5712	Eval_AUC: 0.7718
Epoch 0 Global_step 79000	Train_loss: 0.5684	Eval_AUC: 0.7728
Epoch 0 Global_step 80000	Train_loss: 0.5678	Eval_AUC: 0.7746
Epoch 0 Global_step 81000	Train_loss: 0.5697	Eval_AUC: 0.7795
Epoch 0 DONE	Cost time: 986.05
Epoch 1 Global_step 82000	Train_loss: 0.2679	Eval_AUC: 0.7808
Epoch 1 Global_step 83000	Train_loss: 0.5599	Eval_AUC: 0.7777
Epoch 1 Global_step 84000	Train_loss: 0.5628	Eval_AUC: 0.7777
Epoch 1 Global_step 85000	Train_loss: 0.5605	Eval_AUC: 0.7827
Epoch 1 Global_step 86000	Train_loss: 0.5610	Eval_AUC: 0.7838
Epoch 1 Global_step 87000	Train_loss: 0.5576	Eval_AUC: 0.7818
Epoch 1 Global_step 88000	Train_loss: 0.5585	Eval_AUC: 0.7891
Epoch 1 Global_step 89000	Train_loss: 0.5584	Eval_AUC: 0.7863
Epoch 1 Global_step 90000	Train_loss: 0.5551	Eval_AUC: 0.7862
Epoch 1 Global_step 91000	Train_loss: 0.5539	Eval_AUC: 0.7819
Epoch 1 Global_step 92000	Train_loss: 0.5564	Eval_AUC: 0.7904
Epoch 1 Global_step 93000	Train_loss: 0.5526	Eval_AUC: 0.7880
Epoch 1 Global_step 94000	Train_loss: 0.5534	Eval_AUC: 0.7864
Epoch 1 Global_step 95000	Train_loss: 0.5567	Eval_AUC: 0.7892
Epoch 1 Global_step 96000	Train_loss: 0.5494	Eval_AUC: 0.7900
Epoch 1 Global_step 97000	Train_loss: 0.5545	Eval_AUC: 0.7911
Epoch 1 Global_step 98000	Train_loss: 0.5484	Eval_AUC: 0.7894
Epoch 1 Global_step 99000	Train_loss: 0.5504	Eval_AUC: 0.7910
Epoch 1 Global_step 100000	Train_loss: 0.5517	Eval_AUC: 0.7899
Epoch 1 Global_step 101000	Train_loss: 0.5529	Eval_AUC: 0.7889
Epoch 1 Global_step 102000	Train_loss: 0.5505	Eval_AUC: 0.7887
Epoch 1 Global_step 103000	Train_loss: 0.5504	Eval_AUC: 0.7910
Epoch 1 Global_step 104000	Train_loss: 0.5482	Eval_AUC: 0.7885
Epoch 1 Global_step 105000	Train_loss: 0.5468	Eval_AUC: 0.7901
Epoch 1 Global_step 106000	Train_loss: 0.5504	Eval_AUC: 0.7902
Epoch 1 Global_step 107000	Train_loss: 0.5472	Eval_AUC: 0.7891
Epoch 1 Global_step 108000	Train_loss: 0.5479	Eval_AUC: 0.7921
Epoch 1 Global_step 109000	Train_loss: 0.5474	Eval_AUC: 0.7918
Epoch 1 Global_step 110000	Train_loss: 0.5494	Eval_AUC: 0.7920
Epoch 1 Global_step 111000	Train_loss: 0.5495	Eval_AUC: 0.7911
Epoch 1 Global_step 112000	Train_loss: 0.5481	Eval_AUC: 0.7931
Epoch 1 Global_step 113000	Train_loss: 0.5493	Eval_AUC: 0.7919
Epoch 1 Global_step 114000	Train_loss: 0.5462	Eval_AUC: 0.7923
Epoch 1 Global_step 115000	Train_loss: 0.5466	Eval_AUC: 0.7916
Epoch 1 Global_step 116000	Train_loss: 0.5453	Eval_AUC: 0.7917
Epoch 1 Global_step 117000	Train_loss: 0.5440	Eval_AUC: 0.7924
Epoch 1 Global_step 118000	Train_loss: 0.5488	Eval_AUC: 0.7921
Epoch 1 Global_step 119000	Train_loss: 0.5474	Eval_AUC: 0.7907
Epoch 1 Global_step 120000	Train_loss: 0.5473	Eval_AUC: 0.7921
Epoch 1 Global_step 121000	Train_loss: 0.5453	Eval_AUC: 0.7951
Epoch 1 Global_step 122000	Train_loss: 0.5423	Eval_AUC: 0.7986
Epoch 1 Global_step 123000	Train_loss: 0.5378	Eval_AUC: 0.7965
Epoch 1 Global_step 124000	Train_loss: 0.5394	Eval_AUC: 0.7967
Epoch 1 Global_step 125000	Train_loss: 0.5345	Eval_AUC: 0.7958
Epoch 1 Global_step 126000	Train_loss: 0.5356	Eval_AUC: 0.7991
Epoch 1 Global_step 127000	Train_loss: 0.5354	Eval_AUC: 0.7944
Epoch 1 Global_step 128000	Train_loss: 0.5297	Eval_AUC: 0.8000
Epoch 1 Global_step 129000	Train_loss: 0.5313	Eval_AUC: 0.8013
Epoch 1 Global_step 130000	Train_loss: 0.5300	Eval_AUC: 0.7987
Epoch 1 Global_step 131000	Train_loss: 0.5317	Eval_AUC: 0.7990
Epoch 1 Global_step 132000	Train_loss: 0.5312	Eval_AUC: 0.8024
Epoch 1 Global_step 133000	Train_loss: 0.5268	Eval_AUC: 0.8032
Epoch 1 Global_step 134000	Train_loss: 0.5258	Eval_AUC: 0.8015
Epoch 1 Global_step 135000	Train_loss: 0.5247	Eval_AUC: 0.8004
Epoch 1 Global_step 136000	Train_loss: 0.5303	Eval_AUC: 0.8035
Epoch 1 Global_step 137000	Train_loss: 0.5286	Eval_AUC: 0.8054
Epoch 1 Global_step 138000	Train_loss: 0.5206	Eval_AUC: 0.8056
Epoch 1 Global_step 139000	Train_loss: 0.5234	Eval_AUC: 0.8073
Epoch 1 Global_step 140000	Train_loss: 0.5255	Eval_AUC: 0.8076
Epoch 1 Global_step 141000	Train_loss: 0.5196	Eval_AUC: 0.8059
Epoch 1 Global_step 142000	Train_loss: 0.5225	Eval_AUC: 0.8079
Epoch 1 Global_step 143000	Train_loss: 0.5199	Eval_AUC: 0.8079
Epoch 1 Global_step 144000	Train_loss: 0.5166	Eval_AUC: 0.8089
Epoch 1 Global_step 145000	Train_loss: 0.5207	Eval_AUC: 0.8050
Epoch 1 Global_step 146000	Train_loss: 0.5174	Eval_AUC: 0.8089
Epoch 1 Global_step 147000	Train_loss: 0.5150	Eval_AUC: 0.8109
Epoch 1 Global_step 148000	Train_loss: 0.5215	Eval_AUC: 0.8104
Epoch 1 Global_step 149000	Train_loss: 0.5157	Eval_AUC: 0.8122
Epoch 1 Global_step 150000	Train_loss: 0.5140	Eval_AUC: 0.8146
Epoch 1 Global_step 151000	Train_loss: 0.5122	Eval_AUC: 0.8152
Epoch 1 Global_step 152000	Train_loss: 0.5137	Eval_AUC: 0.8190
Epoch 1 Global_step 153000	Train_loss: 0.5099	Eval_AUC: 0.8206
Epoch 1 Global_step 154000	Train_loss: 0.5169	Eval_AUC: 0.8212
Epoch 1 Global_step 155000	Train_loss: 0.5106	Eval_AUC: 0.8237
Epoch 1 Global_step 156000	Train_loss: 0.5089	Eval_AUC: 0.8256
Epoch 1 Global_step 157000	Train_loss: 0.5083	Eval_AUC: 0.8271
Epoch 1 Global_step 158000	Train_loss: 0.5076	Eval_AUC: 0.8287
Epoch 1 Global_step 159000	Train_loss: 0.5019	Eval_AUC: 0.8314
Epoch 1 Global_step 160000	Train_loss: 0.5121	Eval_AUC: 0.8326
Epoch 1 Global_step 161000	Train_loss: 0.5060	Eval_AUC: 0.8300
Epoch 1 Global_step 162000	Train_loss: 0.5079	Eval_AUC: 0.8290
Epoch 1 Global_step 163000	Train_loss: 0.5074	Eval_AUC: 0.8335
Epoch 1 DONE	Cost time: 2108.60
Epoch 2 Global_step 164000	Train_loss: 0.4747	Eval_AUC: 0.8328
Epoch 2 Global_step 165000	Train_loss: 0.4964	Eval_AUC: 0.8330
Epoch 2 Global_step 166000	Train_loss: 0.4954	Eval_AUC: 0.8346
Epoch 2 Global_step 167000	Train_loss: 0.5013	Eval_AUC: 0.8349
Epoch 2 Global_step 168000	Train_loss: 0.4909	Eval_AUC: 0.8306
Epoch 2 Global_step 169000	Train_loss: 0.4967	Eval_AUC: 0.8352
Epoch 2 Global_step 170000	Train_loss: 0.4953	Eval_AUC: 0.8378
Epoch 2 Global_step 171000	Train_loss: 0.4903	Eval_AUC: 0.8364
Epoch 2 Global_step 172000	Train_loss: 0.4952	Eval_AUC: 0.8375
Epoch 2 Global_step 173000	Train_loss: 0.4936	Eval_AUC: 0.8384
Epoch 2 Global_step 174000	Train_loss: 0.4915	Eval_AUC: 0.8390
Epoch 2 Global_step 175000	Train_loss: 0.4942	Eval_AUC: 0.8385
Epoch 2 Global_step 176000	Train_loss: 0.4921	Eval_AUC: 0.8393
Epoch 2 Global_step 177000	Train_loss: 0.4943	Eval_AUC: 0.8418
Epoch 2 Global_step 178000	Train_loss: 0.4937	Eval_AUC: 0.8399
Epoch 2 Global_step 179000	Train_loss: 0.4876	Eval_AUC: 0.8416
Epoch 2 Global_step 180000	Train_loss: 0.4902	Eval_AUC: 0.8423
Epoch 2 Global_step 181000	Train_loss: 0.4992	Eval_AUC: 0.8429
Epoch 2 Global_step 182000	Train_loss: 0.4915	Eval_AUC: 0.8450
Epoch 2 Global_step 183000	Train_loss: 0.4937	Eval_AUC: 0.8427
Epoch 2 Global_step 184000	Train_loss: 0.4917	Eval_AUC: 0.8431
Epoch 2 Global_step 185000	Train_loss: 0.4921	Eval_AUC: 0.8432
Epoch 2 Global_step 186000	Train_loss: 0.4924	Eval_AUC: 0.8445
Epoch 2 Global_step 187000	Train_loss: 0.4882	Eval_AUC: 0.8454
Epoch 2 Global_step 188000	Train_loss: 0.4900	Eval_AUC: 0.8466
Epoch 2 Global_step 189000	Train_loss: 0.4927	Eval_AUC: 0.8397
Epoch 2 Global_step 190000	Train_loss: 0.4943	Eval_AUC: 0.8448
Epoch 2 Global_step 191000	Train_loss: 0.4945	Eval_AUC: 0.8448
Epoch 2 Global_step 192000	Train_loss: 0.4933	Eval_AUC: 0.8471
Epoch 2 Global_step 193000	Train_loss: 0.4873	Eval_AUC: 0.8444
Epoch 2 Global_step 194000	Train_loss: 0.4944	Eval_AUC: 0.8482
Epoch 2 Global_step 195000	Train_loss: 0.4898	Eval_AUC: 0.8491
Epoch 2 Global_step 196000	Train_loss: 0.4861	Eval_AUC: 0.8473
Epoch 2 Global_step 197000	Train_loss: 0.4870	Eval_AUC: 0.8446
Epoch 2 Global_step 198000	Train_loss: 0.4934	Eval_AUC: 0.8505
Epoch 2 Global_step 199000	Train_loss: 0.4843	Eval_AUC: 0.8510
Epoch 2 Global_step 200000	Train_loss: 0.4849	Eval_AUC: 0.8495
Epoch 2 Global_step 201000	Train_loss: 0.4875	Eval_AUC: 0.8474
Epoch 2 Global_step 202000	Train_loss: 0.4930	Eval_AUC: 0.8463
Epoch 2 Global_step 203000	Train_loss: 0.4891	Eval_AUC: 0.8480
Epoch 2 Global_step 204000	Train_loss: 0.4881	Eval_AUC: 0.8480
Epoch 2 Global_step 205000	Train_loss: 0.4869	Eval_AUC: 0.8486
Epoch 2 Global_step 206000	Train_loss: 0.4797	Eval_AUC: 0.8492
Epoch 2 Global_step 207000	Train_loss: 0.4840	Eval_AUC: 0.8532
Epoch 2 Global_step 208000	Train_loss: 0.4893	Eval_AUC: 0.8469
Epoch 2 Global_step 209000	Train_loss: 0.4818	Eval_AUC: 0.8517
Epoch 2 Global_step 210000	Train_loss: 0.4816	Eval_AUC: 0.8513
Epoch 2 Global_step 211000	Train_loss: 0.4827	Eval_AUC: 0.8514
Epoch 2 Global_step 212000	Train_loss: 0.4764	Eval_AUC: 0.8527
Epoch 2 Global_step 213000	Train_loss: 0.4782	Eval_AUC: 0.8534
Epoch 2 Global_step 214000	Train_loss: 0.4874	Eval_AUC: 0.8497
Epoch 2 Global_step 215000	Train_loss: 0.4795	Eval_AUC: 0.8501
Epoch 2 Global_step 216000	Train_loss: 0.4812	Eval_AUC: 0.8511
Epoch 2 Global_step 217000	Train_loss: 0.4821	Eval_AUC: 0.8580
Epoch 2 Global_step 218000	Train_loss: 0.4828	Eval_AUC: 0.8509
Epoch 2 Global_step 219000	Train_loss: 0.4819	Eval_AUC: 0.8543
Epoch 2 Global_step 220000	Train_loss: 0.4750	Eval_AUC: 0.8558
Epoch 2 Global_step 221000	Train_loss: 0.4816	Eval_AUC: 0.8568
Epoch 2 Global_step 222000	Train_loss: 0.4808	Eval_AUC: 0.8543
Epoch 2 Global_step 223000	Train_loss: 0.4782	Eval_AUC: 0.8549
Epoch 2 Global_step 224000	Train_loss: 0.4799	Eval_AUC: 0.8551
Epoch 2 Global_step 225000	Train_loss: 0.4810	Eval_AUC: 0.8585
Epoch 2 Global_step 226000	Train_loss: 0.4782	Eval_AUC: 0.8573
Epoch 2 Global_step 227000	Train_loss: 0.4789	Eval_AUC: 0.8543
Epoch 2 Global_step 228000	Train_loss: 0.4779	Eval_AUC: 0.8571
Epoch 2 Global_step 229000	Train_loss: 0.4782	Eval_AUC: 0.8597
Epoch 2 Global_step 230000	Train_loss: 0.4799	Eval_AUC: 0.8601
Epoch 2 Global_step 231000	Train_loss: 0.4737	Eval_AUC: 0.8569
Epoch 2 Global_step 232000	Train_loss: 0.4807	Eval_AUC: 0.8575
Epoch 2 Global_step 233000	Train_loss: 0.4731	Eval_AUC: 0.8597
Epoch 2 Global_step 234000	Train_loss: 0.4773	Eval_AUC: 0.8561
Epoch 2 Global_step 235000	Train_loss: 0.4734	Eval_AUC: 0.8583
Epoch 2 Global_step 236000	Train_loss: 0.4730	Eval_AUC: 0.8604
Epoch 2 Global_step 237000	Train_loss: 0.4761	Eval_AUC: 0.8613
Epoch 2 Global_step 238000	Train_loss: 0.4699	Eval_AUC: 0.8566
Epoch 2 Global_step 239000	Train_loss: 0.4765	Eval_AUC: 0.8577
Epoch 2 Global_step 240000	Train_loss: 0.4757	Eval_AUC: 0.8596
Epoch 2 Global_step 241000	Train_loss: 0.4714	Eval_AUC: 0.8615
Epoch 2 Global_step 242000	Train_loss: 0.4734	Eval_AUC: 0.8581
Epoch 2 Global_step 243000	Train_loss: 0.4682	Eval_AUC: 0.8583
Epoch 2 Global_step 244000	Train_loss: 0.4704	Eval_AUC: 0.8615
Epoch 2 DONE	Cost time: 3241.71
Epoch 3 Global_step 245000	Train_loss: 0.1923	Eval_AUC: 0.8622
Epoch 3 Global_step 246000	Train_loss: 0.4561	Eval_AUC: 0.8574
Epoch 3 Global_step 247000	Train_loss: 0.4520	Eval_AUC: 0.8575
Epoch 3 Global_step 248000	Train_loss: 0.4597	Eval_AUC: 0.8600
Epoch 3 Global_step 249000	Train_loss: 0.4552	Eval_AUC: 0.8585
Epoch 3 Global_step 250000	Train_loss: 0.4593	Eval_AUC: 0.8609
Epoch 3 Global_step 251000	Train_loss: 0.4591	Eval_AUC: 0.8579
Epoch 3 Global_step 252000	Train_loss: 0.4559	Eval_AUC: 0.8616
Epoch 3 Global_step 253000	Train_loss: 0.4549	Eval_AUC: 0.8598
Epoch 3 Global_step 254000	Train_loss: 0.4600	Eval_AUC: 0.8585
Epoch 3 Global_step 255000	Train_loss: 0.4561	Eval_AUC: 0.8591
Epoch 3 Global_step 256000	Train_loss: 0.4563	Eval_AUC: 0.8624
Epoch 3 Global_step 257000	Train_loss: 0.4586	Eval_AUC: 0.8614
Epoch 3 Global_step 258000	Train_loss: 0.4603	Eval_AUC: 0.8619
Epoch 3 Global_step 259000	Train_loss: 0.4603	Eval_AUC: 0.8622
Epoch 3 Global_step 260000	Train_loss: 0.4538	Eval_AUC: 0.8600
Epoch 3 Global_step 261000	Train_loss: 0.4564	Eval_AUC: 0.8643
Epoch 3 Global_step 262000	Train_loss: 0.4592	Eval_AUC: 0.8625
Epoch 3 Global_step 263000	Train_loss: 0.4545	Eval_AUC: 0.8606
Epoch 3 Global_step 264000	Train_loss: 0.4613	Eval_AUC: 0.8579
Epoch 3 Global_step 265000	Train_loss: 0.4583	Eval_AUC: 0.8583
Epoch 3 Global_step 266000	Train_loss: 0.4543	Eval_AUC: 0.8610
Epoch 3 Global_step 267000	Train_loss: 0.4585	Eval_AUC: 0.8630
Epoch 3 Global_step 268000	Train_loss: 0.4565	Eval_AUC: 0.8610
Epoch 3 Global_step 269000	Train_loss: 0.4616	Eval_AUC: 0.8608
Epoch 3 Global_step 270000	Train_loss: 0.4601	Eval_AUC: 0.8634
Epoch 3 Global_step 271000	Train_loss: 0.4573	Eval_AUC: 0.8599
Epoch 3 Global_step 272000	Train_loss: 0.4566	Eval_AUC: 0.8612
Epoch 3 Global_step 273000	Train_loss: 0.4517	Eval_AUC: 0.8587
Epoch 3 Global_step 274000	Train_loss: 0.4565	Eval_AUC: 0.8648
Epoch 3 Global_step 275000	Train_loss: 0.4588	Eval_AUC: 0.8624
Epoch 3 Global_step 276000	Train_loss: 0.4558	Eval_AUC: 0.8640
Epoch 3 Global_step 277000	Train_loss: 0.4539	Eval_AUC: 0.8634
Epoch 3 Global_step 278000	Train_loss: 0.4591	Eval_AUC: 0.8662
Epoch 3 Global_step 279000	Train_loss: 0.4538	Eval_AUC: 0.8619
Epoch 3 Global_step 280000	Train_loss: 0.4518	Eval_AUC: 0.8673
Epoch 3 Global_step 281000	Train_loss: 0.4518	Eval_AUC: 0.8656
Epoch 3 Global_step 282000	Train_loss: 0.4588	Eval_AUC: 0.8624
Epoch 3 Global_step 283000	Train_loss: 0.4581	Eval_AUC: 0.8633
Epoch 3 Global_step 284000	Train_loss: 0.4553	Eval_AUC: 0.8628
Epoch 3 Global_step 285000	Train_loss: 0.4556	Eval_AUC: 0.8668
Epoch 3 Global_step 286000	Train_loss: 0.4545	Eval_AUC: 0.8649
Epoch 3 Global_step 287000	Train_loss: 0.4494	Eval_AUC: 0.8677
Epoch 3 Global_step 288000	Train_loss: 0.4571	Eval_AUC: 0.8680
Epoch 3 Global_step 289000	Train_loss: 0.4554	Eval_AUC: 0.8690
Epoch 3 Global_step 290000	Train_loss: 0.4519	Eval_AUC: 0.8683
Epoch 3 Global_step 291000	Train_loss: 0.4530	Eval_AUC: 0.8644
Epoch 3 Global_step 292000	Train_loss: 0.4482	Eval_AUC: 0.8683
Epoch 3 Global_step 293000	Train_loss: 0.4518	Eval_AUC: 0.8657
Epoch 3 Global_step 294000	Train_loss: 0.4544	Eval_AUC: 0.8690
Epoch 3 Global_step 295000	Train_loss: 0.4547	Eval_AUC: 0.8668
Epoch 3 Global_step 296000	Train_loss: 0.4527	Eval_AUC: 0.8648
Epoch 3 Global_step 297000	Train_loss: 0.4487	Eval_AUC: 0.8693
Epoch 3 Global_step 298000	Train_loss: 0.4510	Eval_AUC: 0.8663
Epoch 3 Global_step 299000	Train_loss: 0.4529	Eval_AUC: 0.8656
Epoch 3 Global_step 300000	Train_loss: 0.4468	Eval_AUC: 0.8693
Epoch 3 Global_step 301000	Train_loss: 0.4511	Eval_AUC: 0.8666
Epoch 3 Global_step 302000	Train_loss: 0.4454	Eval_AUC: 0.8679
Epoch 3 Global_step 303000	Train_loss: 0.4526	Eval_AUC: 0.8701
Epoch 3 Global_step 304000	Train_loss: 0.4523	Eval_AUC: 0.8675
Epoch 3 Global_step 305000	Train_loss: 0.4517	Eval_AUC: 0.8672
Epoch 3 Global_step 306000	Train_loss: 0.4463	Eval_AUC: 0.8653
Epoch 3 Global_step 307000	Train_loss: 0.4561	Eval_AUC: 0.8711
Epoch 3 Global_step 308000	Train_loss: 0.4495	Eval_AUC: 0.8694
Epoch 3 Global_step 309000	Train_loss: 0.4511	Eval_AUC: 0.8655
Epoch 3 Global_step 310000	Train_loss: 0.4532	Eval_AUC: 0.8663
Epoch 3 Global_step 311000	Train_loss: 0.4513	Eval_AUC: 0.8660
Epoch 3 Global_step 312000	Train_loss: 0.4574	Eval_AUC: 0.8687
Epoch 3 Global_step 313000	Train_loss: 0.4487	Eval_AUC: 0.8679
Epoch 3 Global_step 314000	Train_loss: 0.4526	Eval_AUC: 0.8671
Epoch 3 Global_step 315000	Train_loss: 0.4499	Eval_AUC: 0.8696
Epoch 3 Global_step 316000	Train_loss: 0.4457	Eval_AUC: 0.8705
Epoch 3 Global_step 317000	Train_loss: 0.4468	Eval_AUC: 0.8699
Epoch 3 Global_step 318000	Train_loss: 0.4480	Eval_AUC: 0.8732
Epoch 3 Global_step 319000	Train_loss: 0.4507	Eval_AUC: 0.8703
Epoch 3 Global_step 320000	Train_loss: 0.4441	Eval_AUC: 0.8686
Epoch 3 Global_step 321000	Train_loss: 0.4531	Eval_AUC: 0.8687
Epoch 3 Global_step 322000	Train_loss: 0.4507	Eval_AUC: 0.8687
Epoch 3 Global_step 323000	Train_loss: 0.4497	Eval_AUC: 0.8743
Epoch 3 Global_step 324000	Train_loss: 0.4502	Eval_AUC: 0.8740
Epoch 3 Global_step 325000	Train_loss: 0.4476	Eval_AUC: 0.8690
Epoch 3 Global_step 326000	Train_loss: 0.4501	Eval_AUC: 0.8731
Epoch 3 DONE	Cost time: 4294.60
Epoch 4 Global_step 327000	Train_loss: 0.3783	Eval_AUC: 0.8686
Epoch 4 Global_step 328000	Train_loss: 0.4190	Eval_AUC: 0.8665
Epoch 4 Global_step 329000	Train_loss: 0.4165	Eval_AUC: 0.8730
Epoch 4 Global_step 330000	Train_loss: 0.4233	Eval_AUC: 0.8694
Epoch 4 Global_step 331000	Train_loss: 0.4200	Eval_AUC: 0.8706
Epoch 4 Global_step 332000	Train_loss: 0.4214	Eval_AUC: 0.8684
Epoch 4 Global_step 333000	Train_loss: 0.4246	Eval_AUC: 0.8701
Epoch 4 Global_step 334000	Train_loss: 0.4256	Eval_AUC: 0.8674
Epoch 4 Global_step 335000	Train_loss: 0.4218	Eval_AUC: 0.8633
Epoch 4 Global_step 336000	Train_loss: 0.4267	Eval_AUC: 0.8709
Epoch 4 Global_step 337000	Train_loss: 0.4205	Eval_AUC: 0.8706
Epoch 4 Global_step 338000	Train_loss: 0.4227	Eval_AUC: 0.8722
Epoch 4 Global_step 339000	Train_loss: 0.4201	Eval_AUC: 0.8712
Epoch 4 Global_step 340000	Train_loss: 0.4156	Eval_AUC: 0.8715
Epoch 4 Global_step 341000	Train_loss: 0.4176	Eval_AUC: 0.8717
Epoch 4 Global_step 342000	Train_loss: 0.4143	Eval_AUC: 0.8704
Epoch 4 Global_step 343000	Train_loss: 0.4143	Eval_AUC: 0.8729
Epoch 4 Global_step 344000	Train_loss: 0.4164	Eval_AUC: 0.8728
Epoch 4 Global_step 345000	Train_loss: 0.4191	Eval_AUC: 0.8716
Epoch 4 Global_step 346000	Train_loss: 0.4181	Eval_AUC: 0.8720
Epoch 4 Global_step 347000	Train_loss: 0.4189	Eval_AUC: 0.8727
Epoch 4 Global_step 348000	Train_loss: 0.4194	Eval_AUC: 0.8716
Epoch 4 Global_step 349000	Train_loss: 0.4141	Eval_AUC: 0.8730
Epoch 4 Global_step 350000	Train_loss: 0.4105	Eval_AUC: 0.8732
Epoch 4 Global_step 351000	Train_loss: 0.4108	Eval_AUC: 0.8733
Epoch 4 Global_step 352000	Train_loss: 0.4175	Eval_AUC: 0.8729
Epoch 4 Global_step 353000	Train_loss: 0.4109	Eval_AUC: 0.8732
Epoch 4 Global_step 354000	Train_loss: 0.4169	Eval_AUC: 0.8721
Epoch 4 Global_step 355000	Train_loss: 0.4158	Eval_AUC: 0.8739
Epoch 4 Global_step 356000	Train_loss: 0.4148	Eval_AUC: 0.8736
Epoch 4 Global_step 357000	Train_loss: 0.4189	Eval_AUC: 0.8738
Epoch 4 Global_step 358000	Train_loss: 0.4150	Eval_AUC: 0.8740
Epoch 4 Global_step 359000	Train_loss: 0.4123	Eval_AUC: 0.8733
Epoch 4 Global_step 360000	Train_loss: 0.4163	Eval_AUC: 0.8724
Epoch 4 Global_step 361000	Train_loss: 0.4138	Eval_AUC: 0.8738
Epoch 4 Global_step 362000	Train_loss: 0.4134	Eval_AUC: 0.8744
Epoch 4 Global_step 363000	Train_loss: 0.4104	Eval_AUC: 0.8756
Epoch 4 Global_step 364000	Train_loss: 0.4149	Eval_AUC: 0.8743
Epoch 4 Global_step 365000	Train_loss: 0.4140	Eval_AUC: 0.8752
Epoch 4 Global_step 366000	Train_loss: 0.4176	Eval_AUC: 0.8746
Epoch 4 Global_step 367000	Train_loss: 0.4087	Eval_AUC: 0.8745
Epoch 4 Global_step 368000	Train_loss: 0.4161	Eval_AUC: 0.8744
Epoch 4 Global_step 369000	Train_loss: 0.4177	Eval_AUC: 0.8733
Epoch 4 Global_step 370000	Train_loss: 0.4147	Eval_AUC: 0.8751
Epoch 4 Global_step 371000	Train_loss: 0.4116	Eval_AUC: 0.8745
Epoch 4 Global_step 372000	Train_loss: 0.4088	Eval_AUC: 0.8739
Epoch 4 Global_step 373000	Train_loss: 0.4104	Eval_AUC: 0.8740
Epoch 4 Global_step 374000	Train_loss: 0.4165	Eval_AUC: 0.8733
Epoch 4 Global_step 375000	Train_loss: 0.4113	Eval_AUC: 0.8748
Epoch 4 Global_step 376000	Train_loss: 0.4143	Eval_AUC: 0.8747
Epoch 4 Global_step 377000	Train_loss: 0.4112	Eval_AUC: 0.8753
Epoch 4 Global_step 378000	Train_loss: 0.4124	Eval_AUC: 0.8749
Epoch 4 Global_step 379000	Train_loss: 0.4132	Eval_AUC: 0.8753
Epoch 4 Global_step 380000	Train_loss: 0.4076	Eval_AUC: 0.8746
Epoch 4 Global_step 381000	Train_loss: 0.4131	Eval_AUC: 0.8760
Epoch 4 Global_step 382000	Train_loss: 0.4096	Eval_AUC: 0.8753
Epoch 4 Global_step 383000	Train_loss: 0.4156	Eval_AUC: 0.8744
Epoch 4 Global_step 384000	Train_loss: 0.4114	Eval_AUC: 0.8749
Epoch 4 Global_step 385000	Train_loss: 0.4128	Eval_AUC: 0.8741
Epoch 4 Global_step 386000	Train_loss: 0.4117	Eval_AUC: 0.8754
Epoch 4 Global_step 387000	Train_loss: 0.4120	Eval_AUC: 0.8749
Epoch 4 Global_step 388000	Train_loss: 0.4127	Eval_AUC: 0.8764
Epoch 4 Global_step 389000	Train_loss: 0.4005	Eval_AUC: 0.8736
Epoch 4 Global_step 390000	Train_loss: 0.4148	Eval_AUC: 0.8762
Epoch 4 Global_step 391000	Train_loss: 0.4089	Eval_AUC: 0.8775
Epoch 4 Global_step 392000	Train_loss: 0.4113	Eval_AUC: 0.8760
Epoch 4 Global_step 393000	Train_loss: 0.4095	Eval_AUC: 0.8752
Epoch 4 Global_step 394000	Train_loss: 0.4135	Eval_AUC: 0.8763
Epoch 4 Global_step 395000	Train_loss: 0.4101	Eval_AUC: 0.8776
Epoch 4 Global_step 396000	Train_loss: 0.4114	Eval_AUC: 0.8766
Epoch 4 Global_step 397000	Train_loss: 0.4193	Eval_AUC: 0.8766
Epoch 4 Global_step 398000	Train_loss: 0.4124	Eval_AUC: 0.8755
Epoch 4 Global_step 399000	Train_loss: 0.4095	Eval_AUC: 0.8764
Epoch 4 Global_step 400000	Train_loss: 0.4166	Eval_AUC: 0.8767
Epoch 4 Global_step 401000	Train_loss: 0.4103	Eval_AUC: 0.8754
Epoch 4 Global_step 402000	Train_loss: 0.4072	Eval_AUC: 0.8764
Epoch 4 Global_step 403000	Train_loss: 0.4099	Eval_AUC: 0.8775
Epoch 4 Global_step 404000	Train_loss: 0.4113	Eval_AUC: 0.8758
Epoch 4 Global_step 405000	Train_loss: 0.4051	Eval_AUC: 0.8766
Epoch 4 Global_step 406000	Train_loss: 0.4081	Eval_AUC: 0.8741
Epoch 4 Global_step 407000	Train_loss: 0.4121	Eval_AUC: 0.8754
Epoch 4 DONE	Cost time: 5211.77
Epoch 5 Global_step 408000	Train_loss: 0.1547	Eval_AUC: 0.8769
Epoch 5 Global_step 409000	Train_loss: 0.3936	Eval_AUC: 0.8759
Epoch 5 Global_step 410000	Train_loss: 0.3964	Eval_AUC: 0.8775
Epoch 5 Global_step 411000	Train_loss: 0.3928	Eval_AUC: 0.8758
Epoch 5 Global_step 412000	Train_loss: 0.3928	Eval_AUC: 0.8754
Epoch 5 Global_step 413000	Train_loss: 0.3923	Eval_AUC: 0.8746
Epoch 5 Global_step 414000	Train_loss: 0.3934	Eval_AUC: 0.8755
Epoch 5 Global_step 415000	Train_loss: 0.3926	Eval_AUC: 0.8742
Epoch 5 Global_step 416000	Train_loss: 0.3909	Eval_AUC: 0.8745
Epoch 5 Global_step 417000	Train_loss: 0.3959	Eval_AUC: 0.8755
Epoch 5 Global_step 418000	Train_loss: 0.3896	Eval_AUC: 0.8763
Epoch 5 Global_step 419000	Train_loss: 0.3902	Eval_AUC: 0.8742
Epoch 5 Global_step 420000	Train_loss: 0.3899	Eval_AUC: 0.8751
Epoch 5 Global_step 421000	Train_loss: 0.3933	Eval_AUC: 0.8764
Epoch 5 Global_step 422000	Train_loss: 0.3917	Eval_AUC: 0.8749
Epoch 5 Global_step 423000	Train_loss: 0.3896	Eval_AUC: 0.8744
Epoch 5 Global_step 424000	Train_loss: 0.3941	Eval_AUC: 0.8759
Epoch 5 Global_step 425000	Train_loss: 0.3941	Eval_AUC: 0.8751
Epoch 5 Global_step 426000	Train_loss: 0.3953	Eval_AUC: 0.8745
Epoch 5 Global_step 427000	Train_loss: 0.3884	Eval_AUC: 0.8756
Epoch 5 Global_step 428000	Train_loss: 0.4004	Eval_AUC: 0.8752
Epoch 5 Global_step 429000	Train_loss: 0.3963	Eval_AUC: 0.8749
Epoch 5 Global_step 430000	Train_loss: 0.3969	Eval_AUC: 0.8744
Epoch 5 Global_step 431000	Train_loss: 0.3957	Eval_AUC: 0.8753
Epoch 5 Global_step 432000	Train_loss: 0.3941	Eval_AUC: 0.8754
Epoch 5 Global_step 433000	Train_loss: 0.3976	Eval_AUC: 0.8743
Epoch 5 Global_step 434000	Train_loss: 0.3935	Eval_AUC: 0.8764
Epoch 5 Global_step 435000	Train_loss: 0.3883	Eval_AUC: 0.8755
Epoch 5 Global_step 436000	Train_loss: 0.3917	Eval_AUC: 0.8755
Epoch 5 Global_step 437000	Train_loss: 0.3948	Eval_AUC: 0.8754
Epoch 5 Global_step 438000	Train_loss: 0.3981	Eval_AUC: 0.8761
Epoch 5 Global_step 439000	Train_loss: 0.3953	Eval_AUC: 0.8758
Epoch 5 Global_step 440000	Train_loss: 0.3989	Eval_AUC: 0.8754
Epoch 5 Global_step 441000	Train_loss: 0.3938	Eval_AUC: 0.8754
Epoch 5 Global_step 442000	Train_loss: 0.3940	Eval_AUC: 0.8747
Epoch 5 Global_step 443000	Train_loss: 0.3954	Eval_AUC: 0.8743
Epoch 5 Global_step 444000	Train_loss: 0.3960	Eval_AUC: 0.8771
Epoch 5 Global_step 445000	Train_loss: 0.3971	Eval_AUC: 0.8747
Epoch 5 Global_step 446000	Train_loss: 0.3949	Eval_AUC: 0.8759
Epoch 5 Global_step 447000	Train_loss: 0.3951	Eval_AUC: 0.8761
Epoch 5 Global_step 448000	Train_loss: 0.3900	Eval_AUC: 0.8754
Epoch 5 Global_step 449000	Train_loss: 0.3962	Eval_AUC: 0.8757
Epoch 5 Global_step 450000	Train_loss: 0.3997	Eval_AUC: 0.8751
Epoch 5 Global_step 451000	Train_loss: 0.3878	Eval_AUC: 0.8746
Epoch 5 Global_step 452000	Train_loss: 0.3969	Eval_AUC: 0.8767
Epoch 5 Global_step 453000	Train_loss: 0.3981	Eval_AUC: 0.8762
Epoch 5 Global_step 454000	Train_loss: 0.4005	Eval_AUC: 0.8755
Epoch 5 Global_step 455000	Train_loss: 0.3964	Eval_AUC: 0.8765
Epoch 5 Global_step 456000	Train_loss: 0.4008	Eval_AUC: 0.8756
Epoch 5 Global_step 457000	Train_loss: 0.4016	Eval_AUC: 0.8766
Epoch 5 Global_step 458000	Train_loss: 0.3931	Eval_AUC: 0.8746
Epoch 5 Global_step 459000	Train_loss: 0.3954	Eval_AUC: 0.8750
Epoch 5 Global_step 460000	Train_loss: 0.3942	Eval_AUC: 0.8767
Epoch 5 Global_step 461000	Train_loss: 0.3948	Eval_AUC: 0.8758
Epoch 5 Global_step 462000	Train_loss: 0.3942	Eval_AUC: 0.8772
Epoch 5 Global_step 463000	Train_loss: 0.3986	Eval_AUC: 0.8761
Epoch 5 Global_step 464000	Train_loss: 0.3946	Eval_AUC: 0.8756
Epoch 5 Global_step 465000	Train_loss: 0.3922	Eval_AUC: 0.8786
Epoch 5 Global_step 466000	Train_loss: 0.3922	Eval_AUC: 0.8760
Epoch 5 Global_step 467000	Train_loss: 0.3951	Eval_AUC: 0.8745
Epoch 5 Global_step 468000	Train_loss: 0.3937	Eval_AUC: 0.8745
Epoch 5 Global_step 469000	Train_loss: 0.3935	Eval_AUC: 0.8769
Epoch 5 Global_step 470000	Train_loss: 0.3952	Eval_AUC: 0.8781
Epoch 5 Global_step 471000	Train_loss: 0.3963	Eval_AUC: 0.8773
Epoch 5 Global_step 472000	Train_loss: 0.3927	Eval_AUC: 0.8750
Epoch 5 Global_step 473000	Train_loss: 0.3947	Eval_AUC: 0.8764
Epoch 5 Global_step 474000	Train_loss: 0.3948	Eval_AUC: 0.8754
Epoch 5 Global_step 475000	Train_loss: 0.3956	Eval_AUC: 0.8791
Epoch 5 Global_step 476000	Train_loss: 0.3959	Eval_AUC: 0.8763
Epoch 5 Global_step 477000	Train_loss: 0.3971	Eval_AUC: 0.8783
Epoch 5 Global_step 478000	Train_loss: 0.3931	Eval_AUC: 0.8780
Epoch 5 Global_step 479000	Train_loss: 0.3947	Eval_AUC: 0.8760
Epoch 5 Global_step 480000	Train_loss: 0.3876	Eval_AUC: 0.8759
Epoch 5 Global_step 481000	Train_loss: 0.3970	Eval_AUC: 0.8771
Epoch 5 Global_step 482000	Train_loss: 0.4004	Eval_AUC: 0.8772
Epoch 5 Global_step 483000	Train_loss: 0.3974	Eval_AUC: 0.8771
Epoch 5 Global_step 484000	Train_loss: 0.3990	Eval_AUC: 0.8773
Epoch 5 Global_step 485000	Train_loss: 0.3971	Eval_AUC: 0.8764
Epoch 5 Global_step 486000	Train_loss: 0.3932	Eval_AUC: 0.8762
Epoch 5 Global_step 487000	Train_loss: 0.3960	Eval_AUC: 0.8779
Epoch 5 Global_step 488000	Train_loss: 0.3972	Eval_AUC: 0.8767
Epoch 5 Global_step 489000	Train_loss: 0.3968	Eval_AUC: 0.8769
Epoch 5 DONE	Cost time: 6058.22
Epoch 6 Global_step 490000	Train_loss: 0.3311	Eval_AUC: 0.8779
Epoch 6 Global_step 491000	Train_loss: 0.3827	Eval_AUC: 0.8780
Epoch 6 Global_step 492000	Train_loss: 0.3796	Eval_AUC: 0.8747
Epoch 6 Global_step 493000	Train_loss: 0.3807	Eval_AUC: 0.8760
Epoch 6 Global_step 494000	Train_loss: 0.3795	Eval_AUC: 0.8757
Epoch 6 Global_step 495000	Train_loss: 0.3831	Eval_AUC: 0.8756
Epoch 6 Global_step 496000	Train_loss: 0.3858	Eval_AUC: 0.8789
Epoch 6 Global_step 497000	Train_loss: 0.3818	Eval_AUC: 0.8758
Epoch 6 Global_step 498000	Train_loss: 0.3817	Eval_AUC: 0.8763
Epoch 6 Global_step 499000	Train_loss: 0.3838	Eval_AUC: 0.8755
Epoch 6 Global_step 500000	Train_loss: 0.3850	Eval_AUC: 0.8766
Epoch 6 Global_step 501000	Train_loss: 0.3800	Eval_AUC: 0.8751
Epoch 6 Global_step 502000	Train_loss: 0.3806	Eval_AUC: 0.8754
Epoch 6 Global_step 503000	Train_loss: 0.3861	Eval_AUC: 0.8758
Epoch 6 Global_step 504000	Train_loss: 0.3846	Eval_AUC: 0.8762
Epoch 6 Global_step 505000	Train_loss: 0.3835	Eval_AUC: 0.8763
Epoch 6 Global_step 506000	Train_loss: 0.3910	Eval_AUC: 0.8758
Epoch 6 Global_step 507000	Train_loss: 0.3859	Eval_AUC: 0.8769
Epoch 6 Global_step 508000	Train_loss: 0.3888	Eval_AUC: 0.8778
Epoch 6 Global_step 509000	Train_loss: 0.3845	Eval_AUC: 0.8774
Epoch 6 Global_step 510000	Train_loss: 0.3836	Eval_AUC: 0.8788
Epoch 6 Global_step 511000	Train_loss: 0.3881	Eval_AUC: 0.8763
Epoch 6 Global_step 512000	Train_loss: 0.3835	Eval_AUC: 0.8785
Epoch 6 Global_step 513000	Train_loss: 0.3891	Eval_AUC: 0.8763
Epoch 6 Global_step 514000	Train_loss: 0.3836	Eval_AUC: 0.8787
Epoch 6 Global_step 515000	Train_loss: 0.3866	Eval_AUC: 0.8754
Epoch 6 Global_step 516000	Train_loss: 0.3817	Eval_AUC: 0.8754
Epoch 6 Global_step 517000	Train_loss: 0.3855	Eval_AUC: 0.8758
Epoch 6 Global_step 518000	Train_loss: 0.3834	Eval_AUC: 0.8773
Epoch 6 Global_step 519000	Train_loss: 0.3822	Eval_AUC: 0.8767
Epoch 6 Global_step 520000	Train_loss: 0.3861	Eval_AUC: 0.8753
Epoch 6 Global_step 521000	Train_loss: 0.3840	Eval_AUC: 0.8785
Epoch 6 Global_step 522000	Train_loss: 0.3840	Eval_AUC: 0.8784
Epoch 6 Global_step 523000	Train_loss: 0.3798	Eval_AUC: 0.8765
Epoch 6 Global_step 524000	Train_loss: 0.3837	Eval_AUC: 0.8758
Epoch 6 Global_step 525000	Train_loss: 0.3818	Eval_AUC: 0.8755
Epoch 6 Global_step 526000	Train_loss: 0.3877	Eval_AUC: 0.8766
Epoch 6 Global_step 527000	Train_loss: 0.3837	Eval_AUC: 0.8766
Epoch 6 Global_step 528000	Train_loss: 0.3824	Eval_AUC: 0.8776
Epoch 6 Global_step 529000	Train_loss: 0.3804	Eval_AUC: 0.8772
Epoch 6 Global_step 530000	Train_loss: 0.3839	Eval_AUC: 0.8770
Epoch 6 Global_step 531000	Train_loss: 0.3791	Eval_AUC: 0.8779
Epoch 6 Global_step 532000	Train_loss: 0.3837	Eval_AUC: 0.8758
Epoch 6 Global_step 533000	Train_loss: 0.3877	Eval_AUC: 0.8763
Epoch 6 Global_step 534000	Train_loss: 0.3915	Eval_AUC: 0.8762
Epoch 6 Global_step 535000	Train_loss: 0.3888	Eval_AUC: 0.8772
Epoch 6 Global_step 536000	Train_loss: 0.3864	Eval_AUC: 0.8779
Epoch 6 Global_step 537000	Train_loss: 0.3883	Eval_AUC: 0.8733
Epoch 6 Global_step 538000	Train_loss: 0.3896	Eval_AUC: 0.8766
Epoch 6 Global_step 539000	Train_loss: 0.3827	Eval_AUC: 0.8774
Epoch 6 Global_step 540000	Train_loss: 0.3844	Eval_AUC: 0.8780
Epoch 6 Global_step 541000	Train_loss: 0.3866	Eval_AUC: 0.8764
Epoch 6 Global_step 542000	Train_loss: 0.3836	Eval_AUC: 0.8775
Epoch 6 Global_step 543000	Train_loss: 0.3887	Eval_AUC: 0.8754
Epoch 6 Global_step 544000	Train_loss: 0.3868	Eval_AUC: 0.8746
Epoch 6 Global_step 545000	Train_loss: 0.3867	Eval_AUC: 0.8760
Epoch 6 Global_step 546000	Train_loss: 0.3920	Eval_AUC: 0.8793
Epoch 6 Global_step 547000	Train_loss: 0.3807	Eval_AUC: 0.8752
Epoch 6 Global_step 548000	Train_loss: 0.3917	Eval_AUC: 0.8773
Epoch 6 Global_step 549000	Train_loss: 0.3856	Eval_AUC: 0.8773
Epoch 6 Global_step 550000	Train_loss: 0.3915	Eval_AUC: 0.8769
Epoch 6 Global_step 551000	Train_loss: 0.3796	Eval_AUC: 0.8782
Epoch 6 Global_step 552000	Train_loss: 0.3852	Eval_AUC: 0.8796
Epoch 6 Global_step 553000	Train_loss: 0.3842	Eval_AUC: 0.8763
Epoch 6 Global_step 554000	Train_loss: 0.3924	Eval_AUC: 0.8790
Epoch 6 Global_step 555000	Train_loss: 0.3839	Eval_AUC: 0.8779
Epoch 6 Global_step 556000	Train_loss: 0.3803	Eval_AUC: 0.8779
Epoch 6 Global_step 557000	Train_loss: 0.3859	Eval_AUC: 0.8800
Epoch 6 Global_step 558000	Train_loss: 0.3867	Eval_AUC: 0.8770
Epoch 6 Global_step 559000	Train_loss: 0.3870	Eval_AUC: 0.8772
Epoch 6 Global_step 560000	Train_loss: 0.3834	Eval_AUC: 0.8781
Epoch 6 Global_step 561000	Train_loss: 0.3882	Eval_AUC: 0.8786
Epoch 6 Global_step 562000	Train_loss: 0.3905	Eval_AUC: 0.8780
Epoch 6 Global_step 563000	Train_loss: 0.3847	Eval_AUC: 0.8747
Epoch 6 Global_step 564000	Train_loss: 0.3857	Eval_AUC: 0.8763
Epoch 6 Global_step 565000	Train_loss: 0.3919	Eval_AUC: 0.8785
Epoch 6 Global_step 566000	Train_loss: 0.3871	Eval_AUC: 0.8764
Epoch 6 Global_step 567000	Train_loss: 0.3865	Eval_AUC: 0.8781
Epoch 6 Global_step 568000	Train_loss: 0.3879	Eval_AUC: 0.8793
Epoch 6 Global_step 569000	Train_loss: 0.3894	Eval_AUC: 0.8797
Epoch 6 Global_step 570000	Train_loss: 0.3901	Eval_AUC: 0.8820
Epoch 6 DONE	Cost time: 6952.58
Epoch 7 Global_step 571000	Train_loss: 0.1259	Eval_AUC: 0.8786
Epoch 7 Global_step 572000	Train_loss: 0.3752	Eval_AUC: 0.8773
Epoch 7 Global_step 573000	Train_loss: 0.3694	Eval_AUC: 0.8777
Epoch 7 Global_step 574000	Train_loss: 0.3710	Eval_AUC: 0.8770
Epoch 7 Global_step 575000	Train_loss: 0.3710	Eval_AUC: 0.8767
Epoch 7 Global_step 576000	Train_loss: 0.3728	Eval_AUC: 0.8769
Epoch 7 Global_step 577000	Train_loss: 0.3680	Eval_AUC: 0.8784
Epoch 7 Global_step 578000	Train_loss: 0.3711	Eval_AUC: 0.8758
Epoch 7 Global_step 579000	Train_loss: 0.3733	Eval_AUC: 0.8765
Epoch 7 Global_step 580000	Train_loss: 0.3708	Eval_AUC: 0.8764
Epoch 7 Global_step 581000	Train_loss: 0.3730	Eval_AUC: 0.8790
Epoch 7 Global_step 582000	Train_loss: 0.3718	Eval_AUC: 0.8787
Epoch 7 Global_step 583000	Train_loss: 0.3711	Eval_AUC: 0.8755
Epoch 7 Global_step 584000	Train_loss: 0.3745	Eval_AUC: 0.8755
Epoch 7 Global_step 585000	Train_loss: 0.3662	Eval_AUC: 0.8788
Epoch 7 Global_step 586000	Train_loss: 0.3736	Eval_AUC: 0.8738
Epoch 7 Global_step 587000	Train_loss: 0.3746	Eval_AUC: 0.8796
Epoch 7 Global_step 588000	Train_loss: 0.3739	Eval_AUC: 0.8787
Epoch 7 Global_step 589000	Train_loss: 0.3807	Eval_AUC: 0.8765
Epoch 7 Global_step 590000	Train_loss: 0.3690	Eval_AUC: 0.8788
Epoch 7 Global_step 591000	Train_loss: 0.3753	Eval_AUC: 0.8767
Epoch 7 Global_step 592000	Train_loss: 0.3794	Eval_AUC: 0.8771
Epoch 7 Global_step 593000	Train_loss: 0.3808	Eval_AUC: 0.8790
Epoch 7 Global_step 594000	Train_loss: 0.3699	Eval_AUC: 0.8777
Epoch 7 Global_step 595000	Train_loss: 0.3724	Eval_AUC: 0.8764
Epoch 7 Global_step 596000	Train_loss: 0.3732	Eval_AUC: 0.8768
Epoch 7 Global_step 597000	Train_loss: 0.3798	Eval_AUC: 0.8769
Epoch 7 Global_step 598000	Train_loss: 0.3788	Eval_AUC: 0.8782
Epoch 7 Global_step 599000	Train_loss: 0.3760	Eval_AUC: 0.8770
Epoch 7 Global_step 600000	Train_loss: 0.3759	Eval_AUC: 0.8764
Epoch 7 Global_step 601000	Train_loss: 0.3722	Eval_AUC: 0.8789
Epoch 7 Global_step 602000	Train_loss: 0.3725	Eval_AUC: 0.8779
Epoch 7 Global_step 603000	Train_loss: 0.3726	Eval_AUC: 0.8793
Epoch 7 Global_step 604000	Train_loss: 0.3749	Eval_AUC: 0.8791
Epoch 7 Global_step 605000	Train_loss: 0.3738	Eval_AUC: 0.8763
Epoch 7 Global_step 606000	Train_loss: 0.3734	Eval_AUC: 0.8790
Epoch 7 Global_step 607000	Train_loss: 0.3700	Eval_AUC: 0.8765
Epoch 7 Global_step 608000	Train_loss: 0.3731	Eval_AUC: 0.8761
Epoch 7 Global_step 609000	Train_loss: 0.3812	Eval_AUC: 0.8770
Epoch 7 Global_step 610000	Train_loss: 0.3754	Eval_AUC: 0.8767
Epoch 7 Global_step 611000	Train_loss: 0.3782	Eval_AUC: 0.8755
Epoch 7 Global_step 612000	Train_loss: 0.3722	Eval_AUC: 0.8794
Epoch 7 Global_step 613000	Train_loss: 0.3820	Eval_AUC: 0.8786
Epoch 7 Global_step 614000	Train_loss: 0.3698	Eval_AUC: 0.8780
Epoch 7 Global_step 615000	Train_loss: 0.3780	Eval_AUC: 0.8786
Epoch 7 Global_step 616000	Train_loss: 0.3795	Eval_AUC: 0.8780
Epoch 7 Global_step 617000	Train_loss: 0.3782	Eval_AUC: 0.8775
Epoch 7 Global_step 618000	Train_loss: 0.3764	Eval_AUC: 0.8778
Epoch 7 Global_step 619000	Train_loss: 0.3792	Eval_AUC: 0.8787
Epoch 7 Global_step 620000	Train_loss: 0.3793	Eval_AUC: 0.8749
Epoch 7 Global_step 621000	Train_loss: 0.3753	Eval_AUC: 0.8791
Epoch 7 Global_step 622000	Train_loss: 0.3765	Eval_AUC: 0.8799
Epoch 7 Global_step 623000	Train_loss: 0.3802	Eval_AUC: 0.8795
Epoch 7 Global_step 624000	Train_loss: 0.3815	Eval_AUC: 0.8788
Epoch 7 Global_step 625000	Train_loss: 0.3845	Eval_AUC: 0.8791
Epoch 7 Global_step 626000	Train_loss: 0.3785	Eval_AUC: 0.8750
Epoch 7 Global_step 627000	Train_loss: 0.3826	Eval_AUC: 0.8775
Epoch 7 Global_step 628000	Train_loss: 0.3810	Eval_AUC: 0.8768
Epoch 7 Global_step 629000	Train_loss: 0.3822	Eval_AUC: 0.8760
Epoch 7 Global_step 630000	Train_loss: 0.3755	Eval_AUC: 0.8762
Epoch 7 Global_step 631000	Train_loss: 0.3761	Eval_AUC: 0.8794
Epoch 7 Global_step 632000	Train_loss: 0.3761	Eval_AUC: 0.8764
Epoch 7 Global_step 633000	Train_loss: 0.3772	Eval_AUC: 0.8754
Epoch 7 Global_step 634000	Train_loss: 0.3754	Eval_AUC: 0.8762
Epoch 7 Global_step 635000	Train_loss: 0.3790	Eval_AUC: 0.8771
Epoch 7 Global_step 636000	Train_loss: 0.3845	Eval_AUC: 0.8767
Epoch 7 Global_step 637000	Train_loss: 0.3836	Eval_AUC: 0.8768
Epoch 7 Global_step 638000	Train_loss: 0.3764	Eval_AUC: 0.8780
Epoch 7 Global_step 639000	Train_loss: 0.3799	Eval_AUC: 0.8789
Epoch 7 Global_step 640000	Train_loss: 0.3772	Eval_AUC: 0.8771
Epoch 7 Global_step 641000	Train_loss: 0.3787	Eval_AUC: 0.8768
Epoch 7 Global_step 642000	Train_loss: 0.3859	Eval_AUC: 0.8795
Epoch 7 Global_step 643000	Train_loss: 0.3797	Eval_AUC: 0.8773
Epoch 7 Global_step 644000	Train_loss: 0.3809	Eval_AUC: 0.8776
Epoch 7 Global_step 645000	Train_loss: 0.3824	Eval_AUC: 0.8773
Epoch 7 Global_step 646000	Train_loss: 0.3819	Eval_AUC: 0.8803
Epoch 7 Global_step 647000	Train_loss: 0.3784	Eval_AUC: 0.8794
Epoch 7 Global_step 648000	Train_loss: 0.3766	Eval_AUC: 0.8795
Epoch 7 Global_step 649000	Train_loss: 0.3801	Eval_AUC: 0.8728
Epoch 7 Global_step 650000	Train_loss: 0.3796	Eval_AUC: 0.8768
Epoch 7 Global_step 651000	Train_loss: 0.3774	Eval_AUC: 0.8801
Epoch 7 Global_step 652000	Train_loss: 0.3865	Eval_AUC: 0.8786
Epoch 7 DONE	Cost time: 7779.96
Epoch 8 Global_step 653000	Train_loss: 0.2883	Eval_AUC: 0.8773
Epoch 8 Global_step 654000	Train_loss: 0.3590	Eval_AUC: 0.8786
Epoch 8 Global_step 655000	Train_loss: 0.3625	Eval_AUC: 0.8760
Epoch 8 Global_step 656000	Train_loss: 0.3580	Eval_AUC: 0.8753
Epoch 8 Global_step 657000	Train_loss: 0.3565	Eval_AUC: 0.8761
Epoch 8 Global_step 658000	Train_loss: 0.3640	Eval_AUC: 0.8781
Epoch 8 Global_step 659000	Train_loss: 0.3642	Eval_AUC: 0.8753
Epoch 8 Global_step 660000	Train_loss: 0.3584	Eval_AUC: 0.8767
Epoch 8 Global_step 661000	Train_loss: 0.3589	Eval_AUC: 0.8766
Epoch 8 Global_step 662000	Train_loss: 0.3584	Eval_AUC: 0.8758
Epoch 8 Global_step 663000	Train_loss: 0.3659	Eval_AUC: 0.8782
Epoch 8 Global_step 664000	Train_loss: 0.3558	Eval_AUC: 0.8762
Epoch 8 Global_step 665000	Train_loss: 0.3603	Eval_AUC: 0.8776
Epoch 8 Global_step 666000	Train_loss: 0.3597	Eval_AUC: 0.8757
Epoch 8 Global_step 667000	Train_loss: 0.3664	Eval_AUC: 0.8768
Epoch 8 Global_step 668000	Train_loss: 0.3649	Eval_AUC: 0.8745
Epoch 8 Global_step 669000	Train_loss: 0.3691	Eval_AUC: 0.8746
Epoch 8 Global_step 670000	Train_loss: 0.3624	Eval_AUC: 0.8768
Epoch 8 Global_step 671000	Train_loss: 0.3587	Eval_AUC: 0.8765
Epoch 8 Global_step 672000	Train_loss: 0.3656	Eval_AUC: 0.8787
Epoch 8 Global_step 673000	Train_loss: 0.3615	Eval_AUC: 0.8749
Epoch 8 Global_step 674000	Train_loss: 0.3654	Eval_AUC: 0.8762
Epoch 8 Global_step 675000	Train_loss: 0.3675	Eval_AUC: 0.8749
Epoch 8 Global_step 676000	Train_loss: 0.3676	Eval_AUC: 0.8770
Epoch 8 Global_step 677000	Train_loss: 0.3613	Eval_AUC: 0.8776
Epoch 8 Global_step 678000	Train_loss: 0.3640	Eval_AUC: 0.8759
Epoch 8 Global_step 679000	Train_loss: 0.3673	Eval_AUC: 0.8799
Epoch 8 Global_step 680000	Train_loss: 0.3587	Eval_AUC: 0.8775
Epoch 8 Global_step 681000	Train_loss: 0.3657	Eval_AUC: 0.8770
Epoch 8 Global_step 682000	Train_loss: 0.3698	Eval_AUC: 0.8747
Epoch 8 Global_step 683000	Train_loss: 0.3643	Eval_AUC: 0.8779
Epoch 8 Global_step 684000	Train_loss: 0.3734	Eval_AUC: 0.8755
Epoch 8 Global_step 685000	Train_loss: 0.3671	Eval_AUC: 0.8755
Epoch 8 Global_step 686000	Train_loss: 0.3677	Eval_AUC: 0.8756
Epoch 8 Global_step 687000	Train_loss: 0.3720	Eval_AUC: 0.8767
Epoch 8 Global_step 688000	Train_loss: 0.3721	Eval_AUC: 0.8767
Epoch 8 Global_step 689000	Train_loss: 0.3618	Eval_AUC: 0.8743
Epoch 8 Global_step 690000	Train_loss: 0.3654	Eval_AUC: 0.8768
Epoch 8 Global_step 691000	Train_loss: 0.3636	Eval_AUC: 0.8744
Epoch 8 Global_step 692000	Train_loss: 0.3679	Eval_AUC: 0.8782
Epoch 8 Global_step 693000	Train_loss: 0.3707	Eval_AUC: 0.8753
Epoch 8 Global_step 694000	Train_loss: 0.3721	Eval_AUC: 0.8778
Epoch 8 Global_step 695000	Train_loss: 0.3709	Eval_AUC: 0.8775
Epoch 8 Global_step 696000	Train_loss: 0.3702	Eval_AUC: 0.8768
Epoch 8 Global_step 697000	Train_loss: 0.3730	Eval_AUC: 0.8755
Epoch 8 Global_step 698000	Train_loss: 0.3714	Eval_AUC: 0.8763
Epoch 8 Global_step 699000	Train_loss: 0.3715	Eval_AUC: 0.8783
Epoch 8 Global_step 700000	Train_loss: 0.3726	Eval_AUC: 0.8761
Epoch 8 Global_step 701000	Train_loss: 0.3690	Eval_AUC: 0.8782
Epoch 8 Global_step 702000	Train_loss: 0.3676	Eval_AUC: 0.8763
Epoch 8 Global_step 703000	Train_loss: 0.3674	Eval_AUC: 0.8760
Epoch 8 Global_step 704000	Train_loss: 0.3768	Eval_AUC: 0.8758
Epoch 8 Global_step 705000	Train_loss: 0.3708	Eval_AUC: 0.8755
Epoch 8 Global_step 706000	Train_loss: 0.3685	Eval_AUC: 0.8772
Epoch 8 Global_step 707000	Train_loss: 0.3715	Eval_AUC: 0.8798
Epoch 8 Global_step 708000	Train_loss: 0.3703	Eval_AUC: 0.8767
Epoch 8 Global_step 709000	Train_loss: 0.3696	Eval_AUC: 0.8760
Epoch 8 Global_step 710000	Train_loss: 0.3670	Eval_AUC: 0.8779
Epoch 8 Global_step 711000	Train_loss: 0.3717	Eval_AUC: 0.8747
Epoch 8 Global_step 712000	Train_loss: 0.3689	Eval_AUC: 0.8779
Epoch 8 Global_step 713000	Train_loss: 0.3772	Eval_AUC: 0.8753
Epoch 8 Global_step 714000	Train_loss: 0.3732	Eval_AUC: 0.8760
Epoch 8 Global_step 715000	Train_loss: 0.3677	Eval_AUC: 0.8781
Epoch 8 Global_step 716000	Train_loss: 0.3729	Eval_AUC: 0.8759
Epoch 8 Global_step 717000	Train_loss: 0.3636	Eval_AUC: 0.8760
Epoch 8 Global_step 718000	Train_loss: 0.3742	Eval_AUC: 0.8787
Epoch 8 Global_step 719000	Train_loss: 0.3764	Eval_AUC: 0.8794
Epoch 8 Global_step 720000	Train_loss: 0.3703	Eval_AUC: 0.8791
Epoch 8 Global_step 721000	Train_loss: 0.3757	Eval_AUC: 0.8776
Epoch 8 Global_step 722000	Train_loss: 0.3720	Eval_AUC: 0.8767
Epoch 8 Global_step 723000	Train_loss: 0.3762	Eval_AUC: 0.8782
Epoch 8 Global_step 724000	Train_loss: 0.3690	Eval_AUC: 0.8772
Epoch 8 Global_step 725000	Train_loss: 0.3704	Eval_AUC: 0.8762
Epoch 8 Global_step 726000	Train_loss: 0.3742	Eval_AUC: 0.8784
Epoch 8 Global_step 727000	Train_loss: 0.3702	Eval_AUC: 0.8783
Epoch 8 Global_step 728000	Train_loss: 0.3732	Eval_AUC: 0.8751
Epoch 8 Global_step 729000	Train_loss: 0.3757	Eval_AUC: 0.8796
Epoch 8 Global_step 730000	Train_loss: 0.3726	Eval_AUC: 0.8784
Epoch 8 Global_step 731000	Train_loss: 0.3738	Eval_AUC: 0.8760
Epoch 8 Global_step 732000	Train_loss: 0.3691	Eval_AUC: 0.8764
Epoch 8 Global_step 733000	Train_loss: 0.3762	Eval_AUC: 0.8781
Epoch 8 DONE	Cost time: 8607.17
Epoch 9 Global_step 734000	Train_loss: 0.1003	Eval_AUC: 0.8762
Epoch 9 Global_step 735000	Train_loss: 0.3439	Eval_AUC: 0.8786
Epoch 9 Global_step 736000	Train_loss: 0.3440	Eval_AUC: 0.8768
Epoch 9 Global_step 737000	Train_loss: 0.3485	Eval_AUC: 0.8758
Epoch 9 Global_step 738000	Train_loss: 0.3418	Eval_AUC: 0.8776
Epoch 9 Global_step 739000	Train_loss: 0.3488	Eval_AUC: 0.8767
Epoch 9 Global_step 740000	Train_loss: 0.3471	Eval_AUC: 0.8746
Epoch 9 Global_step 741000	Train_loss: 0.3481	Eval_AUC: 0.8742
Epoch 9 Global_step 742000	Train_loss: 0.3536	Eval_AUC: 0.8777
Epoch 9 Global_step 743000	Train_loss: 0.3507	Eval_AUC: 0.8758
Epoch 9 Global_step 744000	Train_loss: 0.3535	Eval_AUC: 0.8759
Epoch 9 Global_step 745000	Train_loss: 0.3479	Eval_AUC: 0.8734
Epoch 9 Global_step 746000	Train_loss: 0.3538	Eval_AUC: 0.8753
Epoch 9 Global_step 747000	Train_loss: 0.3553	Eval_AUC: 0.8737
Epoch 9 Global_step 748000	Train_loss: 0.3542	Eval_AUC: 0.8725
Epoch 9 Global_step 749000	Train_loss: 0.3506	Eval_AUC: 0.8775
Epoch 9 Global_step 750000	Train_loss: 0.3514	Eval_AUC: 0.8714
Epoch 9 Global_step 751000	Train_loss: 0.3493	Eval_AUC: 0.8767
Epoch 9 Global_step 752000	Train_loss: 0.3560	Eval_AUC: 0.8729
Epoch 9 Global_step 753000	Train_loss: 0.3521	Eval_AUC: 0.8783
Epoch 9 Global_step 754000	Train_loss: 0.3546	Eval_AUC: 0.8770
Epoch 9 Global_step 755000	Train_loss: 0.3556	Eval_AUC: 0.8750
Epoch 9 Global_step 756000	Train_loss: 0.3563	Eval_AUC: 0.8758
Epoch 9 Global_step 757000	Train_loss: 0.3488	Eval_AUC: 0.8738
Epoch 9 Global_step 758000	Train_loss: 0.3525	Eval_AUC: 0.8738
Epoch 9 Global_step 759000	Train_loss: 0.3616	Eval_AUC: 0.8736
Epoch 9 Global_step 760000	Train_loss: 0.3574	Eval_AUC: 0.8724
Epoch 9 Global_step 761000	Train_loss: 0.3555	Eval_AUC: 0.8733
Epoch 9 Global_step 762000	Train_loss: 0.3520	Eval_AUC: 0.8774
Epoch 9 Global_step 763000	Train_loss: 0.3556	Eval_AUC: 0.8774
Epoch 9 Global_step 764000	Train_loss: 0.3547	Eval_AUC: 0.8747
Epoch 9 Global_step 765000	Train_loss: 0.3523	Eval_AUC: 0.8748
Epoch 9 Global_step 766000	Train_loss: 0.3610	Eval_AUC: 0.8784
Epoch 9 Global_step 767000	Train_loss: 0.3611	Eval_AUC: 0.8754
Epoch 9 Global_step 768000	Train_loss: 0.3565	Eval_AUC: 0.8760
Epoch 9 Global_step 769000	Train_loss: 0.3623	Eval_AUC: 0.8757
Epoch 9 Global_step 770000	Train_loss: 0.3578	Eval_AUC: 0.8757
Epoch 9 Global_step 771000	Train_loss: 0.3615	Eval_AUC: 0.8751
Epoch 9 Global_step 772000	Train_loss: 0.3529	Eval_AUC: 0.8753
Epoch 9 Global_step 773000	Train_loss: 0.3619	Eval_AUC: 0.8721
Epoch 9 Global_step 774000	Train_loss: 0.3648	Eval_AUC: 0.8755
Epoch 9 Global_step 775000	Train_loss: 0.3580	Eval_AUC: 0.8769
Epoch 9 Global_step 776000	Train_loss: 0.3659	Eval_AUC: 0.8779
Epoch 9 Global_step 777000	Train_loss: 0.3611	Eval_AUC: 0.8738
Epoch 9 Global_step 778000	Train_loss: 0.3582	Eval_AUC: 0.8755
Epoch 9 Global_step 779000	Train_loss: 0.3564	Eval_AUC: 0.8759
Epoch 9 Global_step 780000	Train_loss: 0.3626	Eval_AUC: 0.8773
Epoch 9 Global_step 781000	Train_loss: 0.3601	Eval_AUC: 0.8763
Epoch 9 Global_step 782000	Train_loss: 0.3616	Eval_AUC: 0.8762
Epoch 9 Global_step 783000	Train_loss: 0.3613	Eval_AUC: 0.8760
Epoch 9 Global_step 784000	Train_loss: 0.3661	Eval_AUC: 0.8752
Epoch 9 Global_step 785000	Train_loss: 0.3637	Eval_AUC: 0.8753
Epoch 9 Global_step 786000	Train_loss: 0.3603	Eval_AUC: 0.8761
Epoch 9 Global_step 787000	Train_loss: 0.3667	Eval_AUC: 0.8761
Epoch 9 Global_step 788000	Train_loss: 0.3708	Eval_AUC: 0.8738
Epoch 9 Global_step 789000	Train_loss: 0.3599	Eval_AUC: 0.8754
Epoch 9 Global_step 790000	Train_loss: 0.3630	Eval_AUC: 0.8749
Epoch 9 Global_step 791000	Train_loss: 0.3663	Eval_AUC: 0.8757
Epoch 9 Global_step 792000	Train_loss: 0.3590	Eval_AUC: 0.8767
Epoch 9 Global_step 793000	Train_loss: 0.3659	Eval_AUC: 0.8757
Epoch 9 Global_step 794000	Train_loss: 0.3623	Eval_AUC: 0.8769
Epoch 9 Global_step 795000	Train_loss: 0.3676	Eval_AUC: 0.8776
Epoch 9 Global_step 796000	Train_loss: 0.3608	Eval_AUC: 0.8765
Epoch 9 Global_step 797000	Train_loss: 0.3653	Eval_AUC: 0.8776
Epoch 9 Global_step 798000	Train_loss: 0.3649	Eval_AUC: 0.8774
Epoch 9 Global_step 799000	Train_loss: 0.3658	Eval_AUC: 0.8754
Epoch 9 Global_step 800000	Train_loss: 0.3690	Eval_AUC: 0.8738
Epoch 9 Global_step 801000	Train_loss: 0.3647	Eval_AUC: 0.8759
Epoch 9 Global_step 802000	Train_loss: 0.3644	Eval_AUC: 0.8762
Epoch 9 Global_step 803000	Train_loss: 0.3642	Eval_AUC: 0.8778
Epoch 9 Global_step 804000	Train_loss: 0.3576	Eval_AUC: 0.8770
Epoch 9 Global_step 805000	Train_loss: 0.3664	Eval_AUC: 0.8792
Epoch 9 Global_step 806000	Train_loss: 0.3697	Eval_AUC: 0.8772
Epoch 9 Global_step 807000	Train_loss: 0.3670	Eval_AUC: 0.8772
Epoch 9 Global_step 808000	Train_loss: 0.3628	Eval_AUC: 0.8787
Epoch 9 Global_step 809000	Train_loss: 0.3690	Eval_AUC: 0.8735
Epoch 9 Global_step 810000	Train_loss: 0.3691	Eval_AUC: 0.8762
Epoch 9 Global_step 811000	Train_loss: 0.3709	Eval_AUC: 0.8781
Epoch 9 Global_step 812000	Train_loss: 0.3762	Eval_AUC: 0.8776
Epoch 9 Global_step 813000	Train_loss: 0.3655	Eval_AUC: 0.8786
Epoch 9 Global_step 814000	Train_loss: 0.3722	Eval_AUC: 0.8795
Epoch 9 Global_step 815000	Train_loss: 0.3674	Eval_AUC: 0.8765
Epoch 9 DONE	Cost time: 9454.14
Epoch 10 Global_step 816000	Train_loss: 0.2534	Eval_AUC: 0.8756
Epoch 10 Global_step 817000	Train_loss: 0.3383	Eval_AUC: 0.8761
Epoch 10 Global_step 818000	Train_loss: 0.3340	Eval_AUC: 0.8720
Epoch 10 Global_step 819000	Train_loss: 0.3382	Eval_AUC: 0.8760
Epoch 10 Global_step 820000	Train_loss: 0.3354	Eval_AUC: 0.8708
Epoch 10 Global_step 821000	Train_loss: 0.3382	Eval_AUC: 0.8737
Epoch 10 Global_step 822000	Train_loss: 0.3373	Eval_AUC: 0.8751
Epoch 10 Global_step 823000	Train_loss: 0.3334	Eval_AUC: 0.8724
Epoch 10 Global_step 824000	Train_loss: 0.3412	Eval_AUC: 0.8746
Epoch 10 Global_step 825000	Train_loss: 0.3399	Eval_AUC: 0.8716
Epoch 10 Global_step 826000	Train_loss: 0.3397	Eval_AUC: 0.8710
Epoch 10 Global_step 827000	Train_loss: 0.3381	Eval_AUC: 0.8739
Epoch 10 Global_step 828000	Train_loss: 0.3391	Eval_AUC: 0.8752
Epoch 10 Global_step 829000	Train_loss: 0.3398	Eval_AUC: 0.8728
Epoch 10 Global_step 830000	Train_loss: 0.3382	Eval_AUC: 0.8728
Epoch 10 Global_step 831000	Train_loss: 0.3445	Eval_AUC: 0.8758
Epoch 10 Global_step 832000	Train_loss: 0.3401	Eval_AUC: 0.8726
Epoch 10 Global_step 833000	Train_loss: 0.3403	Eval_AUC: 0.8756
Epoch 10 Global_step 834000	Train_loss: 0.3392	Eval_AUC: 0.8705
Epoch 10 Global_step 835000	Train_loss: 0.3402	Eval_AUC: 0.8720
Epoch 10 Global_step 836000	Train_loss: 0.3438	Eval_AUC: 0.8713
Epoch 10 Global_step 837000	Train_loss: 0.3443	Eval_AUC: 0.8730
Epoch 10 Global_step 838000	Train_loss: 0.3467	Eval_AUC: 0.8726
Epoch 10 Global_step 839000	Train_loss: 0.3422	Eval_AUC: 0.8727
Epoch 10 Global_step 840000	Train_loss: 0.3488	Eval_AUC: 0.8732
Epoch 10 Global_step 841000	Train_loss: 0.3449	Eval_AUC: 0.8698
Epoch 10 Global_step 842000	Train_loss: 0.3472	Eval_AUC: 0.8726
Epoch 10 Global_step 843000	Train_loss: 0.3469	Eval_AUC: 0.8716
Epoch 10 Global_step 844000	Train_loss: 0.3437	Eval_AUC: 0.8728
Epoch 10 Global_step 845000	Train_loss: 0.3483	Eval_AUC: 0.8730
Epoch 10 Global_step 846000	Train_loss: 0.3520	Eval_AUC: 0.8730
Epoch 10 Global_step 847000	Train_loss: 0.3509	Eval_AUC: 0.8728
Epoch 10 Global_step 848000	Train_loss: 0.3499	Eval_AUC: 0.8756
Epoch 10 Global_step 849000	Train_loss: 0.3523	Eval_AUC: 0.8709
Epoch 10 Global_step 850000	Train_loss: 0.3515	Eval_AUC: 0.8726
Epoch 10 Global_step 851000	Train_loss: 0.3523	Eval_AUC: 0.8738
Epoch 10 Global_step 852000	Train_loss: 0.3545	Eval_AUC: 0.8705
Epoch 10 Global_step 853000	Train_loss: 0.3508	Eval_AUC: 0.8741
Epoch 10 Global_step 854000	Train_loss: 0.3595	Eval_AUC: 0.8731
Epoch 10 Global_step 855000	Train_loss: 0.3483	Eval_AUC: 0.8723
Epoch 10 Global_step 856000	Train_loss: 0.3515	Eval_AUC: 0.8737
Epoch 10 Global_step 857000	Train_loss: 0.3507	Eval_AUC: 0.8732
Epoch 10 Global_step 858000	Train_loss: 0.3553	Eval_AUC: 0.8728
Epoch 10 Global_step 859000	Train_loss: 0.3490	Eval_AUC: 0.8745
Epoch 10 Global_step 860000	Train_loss: 0.3460	Eval_AUC: 0.8738
Epoch 10 Global_step 861000	Train_loss: 0.3547	Eval_AUC: 0.8733
Epoch 10 Global_step 862000	Train_loss: 0.3567	Eval_AUC: 0.8760
Epoch 10 Global_step 863000	Train_loss: 0.3610	Eval_AUC: 0.8748
Epoch 10 Global_step 864000	Train_loss: 0.3544	Eval_AUC: 0.8751
Epoch 10 Global_step 865000	Train_loss: 0.3581	Eval_AUC: 0.8742
Epoch 10 Global_step 866000	Train_loss: 0.3576	Eval_AUC: 0.8759
Epoch 10 Global_step 867000	Train_loss: 0.3502	Eval_AUC: 0.8723
Epoch 10 Global_step 868000	Train_loss: 0.3558	Eval_AUC: 0.8748
Epoch 10 Global_step 869000	Train_loss: 0.3608	Eval_AUC: 0.8713
Epoch 10 Global_step 870000	Train_loss: 0.3604	Eval_AUC: 0.8726
Epoch 10 Global_step 871000	Train_loss: 0.3593	Eval_AUC: 0.8722
Epoch 10 Global_step 872000	Train_loss: 0.3555	Eval_AUC: 0.8750
Epoch 10 Global_step 873000	Train_loss: 0.3563	Eval_AUC: 0.8724
Epoch 10 Global_step 874000	Train_loss: 0.3561	Eval_AUC: 0.8759
Epoch 10 Global_step 875000	Train_loss: 0.3576	Eval_AUC: 0.8758
Epoch 10 Global_step 876000	Train_loss: 0.3549	Eval_AUC: 0.8761
Epoch 10 Global_step 877000	Train_loss: 0.3575	Eval_AUC: 0.8770
Epoch 10 Global_step 878000	Train_loss: 0.3592	Eval_AUC: 0.8758
Epoch 10 Global_step 879000	Train_loss: 0.3602	Eval_AUC: 0.8735
Epoch 10 Global_step 880000	Train_loss: 0.3566	Eval_AUC: 0.8759
Epoch 10 Global_step 881000	Train_loss: 0.3570	Eval_AUC: 0.8770
Epoch 10 Global_step 882000	Train_loss: 0.3611	Eval_AUC: 0.8769
Epoch 10 Global_step 883000	Train_loss: 0.3584	Eval_AUC: 0.8735
Epoch 10 Global_step 884000	Train_loss: 0.3586	Eval_AUC: 0.8729
Epoch 10 Global_step 885000	Train_loss: 0.3578	Eval_AUC: 0.8737
Epoch 10 Global_step 886000	Train_loss: 0.3581	Eval_AUC: 0.8753
Epoch 10 Global_step 887000	Train_loss: 0.3550	Eval_AUC: 0.8770
Epoch 10 Global_step 888000	Train_loss: 0.3632	Eval_AUC: 0.8760
Epoch 10 Global_step 889000	Train_loss: 0.3609	Eval_AUC: 0.8765
Epoch 10 Global_step 890000	Train_loss: 0.3598	Eval_AUC: 0.8763
Epoch 10 Global_step 891000	Train_loss: 0.3579	Eval_AUC: 0.8755
Epoch 10 Global_step 892000	Train_loss: 0.3602	Eval_AUC: 0.8757
Epoch 10 Global_step 893000	Train_loss: 0.3594	Eval_AUC: 0.8764
Epoch 10 Global_step 894000	Train_loss: 0.3637	Eval_AUC: 0.8758
Epoch 10 Global_step 895000	Train_loss: 0.3673	Eval_AUC: 0.8761
Epoch 10 Global_step 896000	Train_loss: 0.3574	Eval_AUC: 0.8730
Epoch 10 DONE	Cost time: 10279.34
Epoch 11 Global_step 897000	Train_loss: 0.0769	Eval_AUC: 0.8749
Epoch 11 Global_step 898000	Train_loss: 0.3304	Eval_AUC: 0.8735
Epoch 11 Global_step 899000	Train_loss: 0.3264	Eval_AUC: 0.8699
Epoch 11 Global_step 900000	Train_loss: 0.3263	Eval_AUC: 0.8736
Epoch 11 Global_step 901000	Train_loss: 0.3343	Eval_AUC: 0.8739
Epoch 11 Global_step 902000	Train_loss: 0.3293	Eval_AUC: 0.8729
Epoch 11 Global_step 903000	Train_loss: 0.3258	Eval_AUC: 0.8723
Epoch 11 Global_step 904000	Train_loss: 0.3289	Eval_AUC: 0.8723
Epoch 11 Global_step 905000	Train_loss: 0.3296	Eval_AUC: 0.8705
Epoch 11 Global_step 906000	Train_loss: 0.3307	Eval_AUC: 0.8724
Epoch 11 Global_step 907000	Train_loss: 0.3295	Eval_AUC: 0.8712
Epoch 11 Global_step 908000	Train_loss: 0.3308	Eval_AUC: 0.8704
Epoch 11 Global_step 909000	Train_loss: 0.3265	Eval_AUC: 0.8704
Epoch 11 Global_step 910000	Train_loss: 0.3291	Eval_AUC: 0.8676
Epoch 11 Global_step 911000	Train_loss: 0.3284	Eval_AUC: 0.8705
Epoch 11 Global_step 912000	Train_loss: 0.3321	Eval_AUC: 0.8697
Epoch 11 Global_step 913000	Train_loss: 0.3304	Eval_AUC: 0.8733
Epoch 11 Global_step 914000	Train_loss: 0.3307	Eval_AUC: 0.8721
Epoch 11 Global_step 915000	Train_loss: 0.3377	Eval_AUC: 0.8691
Epoch 11 Global_step 916000	Train_loss: 0.3304	Eval_AUC: 0.8688
Epoch 11 Global_step 917000	Train_loss: 0.3309	Eval_AUC: 0.8671
Epoch 11 Global_step 918000	Train_loss: 0.3361	Eval_AUC: 0.8727
Epoch 11 Global_step 919000	Train_loss: 0.3400	Eval_AUC: 0.8700
Epoch 11 Global_step 920000	Train_loss: 0.3352	Eval_AUC: 0.8683
Epoch 11 Global_step 921000	Train_loss: 0.3354	Eval_AUC: 0.8717
Epoch 11 Global_step 922000	Train_loss: 0.3343	Eval_AUC: 0.8722
Epoch 11 Global_step 923000	Train_loss: 0.3362	Eval_AUC: 0.8724
Epoch 11 Global_step 924000	Train_loss: 0.3307	Eval_AUC: 0.8713
Epoch 11 Global_step 925000	Train_loss: 0.3403	Eval_AUC: 0.8724
Epoch 11 Global_step 926000	Train_loss: 0.3460	Eval_AUC: 0.8726
Epoch 11 Global_step 927000	Train_loss: 0.3394	Eval_AUC: 0.8726
Epoch 11 Global_step 928000	Train_loss: 0.3385	Eval_AUC: 0.8705
Epoch 11 Global_step 929000	Train_loss: 0.3353	Eval_AUC: 0.8689
Epoch 11 Global_step 930000	Train_loss: 0.3411	Eval_AUC: 0.8690
Epoch 11 Global_step 931000	Train_loss: 0.3382	Eval_AUC: 0.8718
Epoch 11 Global_step 932000	Train_loss: 0.3435	Eval_AUC: 0.8724
Epoch 11 Global_step 933000	Train_loss: 0.3421	Eval_AUC: 0.8731
Epoch 11 Global_step 934000	Train_loss: 0.3408	Eval_AUC: 0.8708
Epoch 11 Global_step 935000	Train_loss: 0.3438	Eval_AUC: 0.8702
Epoch 11 Global_step 936000	Train_loss: 0.3435	Eval_AUC: 0.8696
Epoch 11 Global_step 937000	Train_loss: 0.3502	Eval_AUC: 0.8693
Epoch 11 Global_step 938000	Train_loss: 0.3493	Eval_AUC: 0.8690
Epoch 11 Global_step 939000	Train_loss: 0.3419	Eval_AUC: 0.8716
Epoch 11 Global_step 940000	Train_loss: 0.3462	Eval_AUC: 0.8727
Epoch 11 Global_step 941000	Train_loss: 0.3454	Eval_AUC: 0.8738
Epoch 11 Global_step 942000	Train_loss: 0.3482	Eval_AUC: 0.8730
Epoch 11 Global_step 943000	Train_loss: 0.3420	Eval_AUC: 0.8708
Epoch 11 Global_step 944000	Train_loss: 0.3540	Eval_AUC: 0.8744
Epoch 11 Global_step 945000	Train_loss: 0.3527	Eval_AUC: 0.8713
Epoch 11 Global_step 946000	Train_loss: 0.3446	Eval_AUC: 0.8713
Epoch 11 Global_step 947000	Train_loss: 0.3500	Eval_AUC: 0.8738
Epoch 11 Global_step 948000	Train_loss: 0.3458	Eval_AUC: 0.8727
Epoch 11 Global_step 949000	Train_loss: 0.3469	Eval_AUC: 0.8740
Epoch 11 Global_step 950000	Train_loss: 0.3458	Eval_AUC: 0.8700
Epoch 11 Global_step 951000	Train_loss: 0.3528	Eval_AUC: 0.8747
Epoch 11 Global_step 952000	Train_loss: 0.3505	Eval_AUC: 0.8714
Epoch 11 Global_step 953000	Train_loss: 0.3497	Eval_AUC: 0.8726
Epoch 11 Global_step 954000	Train_loss: 0.3538	Eval_AUC: 0.8709
Epoch 11 Global_step 955000	Train_loss: 0.3513	Eval_AUC: 0.8730
Epoch 11 Global_step 956000	Train_loss: 0.3536	Eval_AUC: 0.8739
Epoch 11 Global_step 957000	Train_loss: 0.3454	Eval_AUC: 0.8706
Epoch 11 Global_step 958000	Train_loss: 0.3520	Eval_AUC: 0.8702
Epoch 11 Global_step 959000	Train_loss: 0.3545	Eval_AUC: 0.8706
Epoch 11 Global_step 960000	Train_loss: 0.3461	Eval_AUC: 0.8756
Epoch 11 Global_step 961000	Train_loss: 0.3478	Eval_AUC: 0.8729
Epoch 11 Global_step 962000	Train_loss: 0.3522	Eval_AUC: 0.8739
Epoch 11 Global_step 963000	Train_loss: 0.3538	Eval_AUC: 0.8727
Epoch 11 Global_step 964000	Train_loss: 0.3500	Eval_AUC: 0.8732
Epoch 11 Global_step 965000	Train_loss: 0.3494	Eval_AUC: 0.8747
Epoch 11 Global_step 966000	Train_loss: 0.3491	Eval_AUC: 0.8746
Epoch 11 Global_step 967000	Train_loss: 0.3555	Eval_AUC: 0.8727
Epoch 11 Global_step 968000	Train_loss: 0.3511	Eval_AUC: 0.8710
Epoch 11 Global_step 969000	Train_loss: 0.3512	Eval_AUC: 0.8725
Epoch 11 Global_step 970000	Train_loss: 0.3468	Eval_AUC: 0.8727
Epoch 11 Global_step 971000	Train_loss: 0.3552	Eval_AUC: 0.8731
Epoch 11 Global_step 972000	Train_loss: 0.3542	Eval_AUC: 0.8717
Epoch 11 Global_step 973000	Train_loss: 0.3533	Eval_AUC: 0.8749
Epoch 11 Global_step 974000	Train_loss: 0.3552	Eval_AUC: 0.8736
Epoch 11 Global_step 975000	Train_loss: 0.3521	Eval_AUC: 0.8747
Epoch 11 Global_step 976000	Train_loss: 0.3534	Eval_AUC: 0.8737
Epoch 11 Global_step 977000	Train_loss: 0.3511	Eval_AUC: 0.8713
Epoch 11 Global_step 978000	Train_loss: 0.3542	Eval_AUC: 0.8760
Epoch 11 DONE	Cost time: 11107.41
Epoch 12 Global_step 979000	Train_loss: 0.2235	Eval_AUC: 0.8725
Epoch 12 Global_step 980000	Train_loss: 0.3167	Eval_AUC: 0.8728
Epoch 12 Global_step 981000	Train_loss: 0.3131	Eval_AUC: 0.8702
Epoch 12 Global_step 982000	Train_loss: 0.3115	Eval_AUC: 0.8711
Epoch 12 Global_step 983000	Train_loss: 0.3177	Eval_AUC: 0.8705
Epoch 12 Global_step 984000	Train_loss: 0.3151	Eval_AUC: 0.8724
Epoch 12 Global_step 985000	Train_loss: 0.3170	Eval_AUC: 0.8713
Epoch 12 Global_step 986000	Train_loss: 0.3179	Eval_AUC: 0.8732
Epoch 12 Global_step 987000	Train_loss: 0.3171	Eval_AUC: 0.8693
Epoch 12 Global_step 988000	Train_loss: 0.3211	Eval_AUC: 0.8694
Epoch 12 Global_step 989000	Train_loss: 0.3215	Eval_AUC: 0.8701
Epoch 12 Global_step 990000	Train_loss: 0.3283	Eval_AUC: 0.8695
Epoch 12 Global_step 991000	Train_loss: 0.3191	Eval_AUC: 0.8674
Epoch 12 Global_step 992000	Train_loss: 0.3266	Eval_AUC: 0.8686
Epoch 12 Global_step 993000	Train_loss: 0.3216	Eval_AUC: 0.8687
Epoch 12 Global_step 994000	Train_loss: 0.3241	Eval_AUC: 0.8695
Epoch 12 Global_step 995000	Train_loss: 0.3218	Eval_AUC: 0.8672
Epoch 12 Global_step 996000	Train_loss: 0.3217	Eval_AUC: 0.8686
Epoch 12 Global_step 997000	Train_loss: 0.3241	Eval_AUC: 0.8671
Epoch 12 Global_step 998000	Train_loss: 0.3261	Eval_AUC: 0.8658
Epoch 12 Global_step 999000	Train_loss: 0.3247	Eval_AUC: 0.8720
Epoch 12 Global_step 1000000	Train_loss: 0.3310	Eval_AUC: 0.8693
Epoch 12 Global_step 1001000	Train_loss: 0.3244	Eval_AUC: 0.8650
Epoch 12 Global_step 1002000	Train_loss: 0.3288	Eval_AUC: 0.8677
Epoch 12 Global_step 1003000	Train_loss: 0.3309	Eval_AUC: 0.8687
Epoch 12 Global_step 1004000	Train_loss: 0.3292	Eval_AUC: 0.8671
Epoch 12 Global_step 1005000	Train_loss: 0.3283	Eval_AUC: 0.8714
Epoch 12 Global_step 1006000	Train_loss: 0.3349	Eval_AUC: 0.8707
Epoch 12 Global_step 1007000	Train_loss: 0.3327	Eval_AUC: 0.8675
Epoch 12 Global_step 1008000	Train_loss: 0.3273	Eval_AUC: 0.8691
Epoch 12 Global_step 1009000	Train_loss: 0.3328	Eval_AUC: 0.8697
Epoch 12 Global_step 1010000	Train_loss: 0.3334	Eval_AUC: 0.8705
Epoch 12 Global_step 1011000	Train_loss: 0.3346	Eval_AUC: 0.8697
Epoch 12 Global_step 1012000	Train_loss: 0.3339	Eval_AUC: 0.8733
Epoch 12 Global_step 1013000	Train_loss: 0.3375	Eval_AUC: 0.8701
Epoch 12 Global_step 1014000	Train_loss: 0.3398	Eval_AUC: 0.8683
Epoch 12 Global_step 1015000	Train_loss: 0.3312	Eval_AUC: 0.8713
Epoch 12 Global_step 1016000	Train_loss: 0.3358	Eval_AUC: 0.8704
Epoch 12 Global_step 1017000	Train_loss: 0.3302	Eval_AUC: 0.8684
Epoch 12 Global_step 1018000	Train_loss: 0.3380	Eval_AUC: 0.8710
Epoch 12 Global_step 1019000	Train_loss: 0.3378	Eval_AUC: 0.8703
Epoch 12 Global_step 1020000	Train_loss: 0.3316	Eval_AUC: 0.8688
Epoch 12 Global_step 1021000	Train_loss: 0.3325	Eval_AUC: 0.8690
Epoch 12 Global_step 1022000	Train_loss: 0.3342	Eval_AUC: 0.8721
Epoch 12 Global_step 1023000	Train_loss: 0.3402	Eval_AUC: 0.8705
Epoch 12 Global_step 1024000	Train_loss: 0.3400	Eval_AUC: 0.8710
Epoch 12 Global_step 1025000	Train_loss: 0.3365	Eval_AUC: 0.8685
Epoch 12 Global_step 1026000	Train_loss: 0.3385	Eval_AUC: 0.8710
Epoch 12 Global_step 1027000	Train_loss: 0.3436	Eval_AUC: 0.8700
Epoch 12 Global_step 1028000	Train_loss: 0.3400	Eval_AUC: 0.8703
Epoch 12 Global_step 1029000	Train_loss: 0.3406	Eval_AUC: 0.8696
Epoch 12 Global_step 1030000	Train_loss: 0.3401	Eval_AUC: 0.8703
Epoch 12 Global_step 1031000	Train_loss: 0.3360	Eval_AUC: 0.8691
Epoch 12 Global_step 1032000	Train_loss: 0.3432	Eval_AUC: 0.8692
Epoch 12 Global_step 1033000	Train_loss: 0.3386	Eval_AUC: 0.8714
Epoch 12 Global_step 1034000	Train_loss: 0.3491	Eval_AUC: 0.8722
Epoch 12 Global_step 1035000	Train_loss: 0.3438	Eval_AUC: 0.8710
Epoch 12 Global_step 1036000	Train_loss: 0.3451	Eval_AUC: 0.8704
Epoch 12 Global_step 1037000	Train_loss: 0.3485	Eval_AUC: 0.8718
Epoch 12 Global_step 1038000	Train_loss: 0.3456	Eval_AUC: 0.8701
Epoch 12 Global_step 1039000	Train_loss: 0.3425	Eval_AUC: 0.8687
Epoch 12 Global_step 1040000	Train_loss: 0.3425	Eval_AUC: 0.8705
Epoch 12 Global_step 1041000	Train_loss: 0.3431	Eval_AUC: 0.8710
Epoch 12 Global_step 1042000	Train_loss: 0.3421	Eval_AUC: 0.8729
Epoch 12 Global_step 1043000	Train_loss: 0.3441	Eval_AUC: 0.8710
Epoch 12 Global_step 1044000	Train_loss: 0.3416	Eval_AUC: 0.8705
Epoch 12 Global_step 1045000	Train_loss: 0.3463	Eval_AUC: 0.8727
Epoch 12 Global_step 1046000	Train_loss: 0.3453	Eval_AUC: 0.8708
Epoch 12 Global_step 1047000	Train_loss: 0.3450	Eval_AUC: 0.8690
Epoch 12 Global_step 1048000	Train_loss: 0.3421	Eval_AUC: 0.8702
Epoch 12 Global_step 1049000	Train_loss: 0.3484	Eval_AUC: 0.8708
Epoch 12 Global_step 1050000	Train_loss: 0.3480	Eval_AUC: 0.8699
Epoch 12 Global_step 1051000	Train_loss: 0.3419	Eval_AUC: 0.8677
Epoch 12 Global_step 1052000	Train_loss: 0.3420	Eval_AUC: 0.8680
Epoch 12 Global_step 1053000	Train_loss: 0.3468	Eval_AUC: 0.8684
Epoch 12 Global_step 1054000	Train_loss: 0.3482	Eval_AUC: 0.8720
Epoch 12 Global_step 1055000	Train_loss: 0.3484	Eval_AUC: 0.8705
Epoch 12 Global_step 1056000	Train_loss: 0.3508	Eval_AUC: 0.8739
Epoch 12 Global_step 1057000	Train_loss: 0.3431	Eval_AUC: 0.8696
Epoch 12 Global_step 1058000	Train_loss: 0.3482	Eval_AUC: 0.8708
Epoch 12 Global_step 1059000	Train_loss: 0.3505	Eval_AUC: 0.8739
Epoch 12 DONE	Cost time: 11938.83
Epoch 13 Global_step 1060000	Train_loss: 0.0587	Eval_AUC: 0.8695
Epoch 13 Global_step 1061000	Train_loss: 0.3058	Eval_AUC: 0.8703
Epoch 13 Global_step 1062000	Train_loss: 0.3074	Eval_AUC: 0.8702
Epoch 13 Global_step 1063000	Train_loss: 0.3111	Eval_AUC: 0.8690
Epoch 13 Global_step 1064000	Train_loss: 0.3040	Eval_AUC: 0.8672
Epoch 13 Global_step 1065000	Train_loss: 0.3068	Eval_AUC: 0.8684
Epoch 13 Global_step 1066000	Train_loss: 0.3078	Eval_AUC: 0.8686
Epoch 13 Global_step 1067000	Train_loss: 0.3108	Eval_AUC: 0.8693
Epoch 13 Global_step 1068000	Train_loss: 0.3124	Eval_AUC: 0.8670
Epoch 13 Global_step 1069000	Train_loss: 0.3162	Eval_AUC: 0.8670
Epoch 13 Global_step 1070000	Train_loss: 0.3123	Eval_AUC: 0.8667
Epoch 13 Global_step 1071000	Train_loss: 0.3123	Eval_AUC: 0.8656
Epoch 13 Global_step 1072000	Train_loss: 0.3162	Eval_AUC: 0.8665
Epoch 13 Global_step 1073000	Train_loss: 0.3088	Eval_AUC: 0.8660
Epoch 13 Global_step 1074000	Train_loss: 0.3144	Eval_AUC: 0.8685
Epoch 13 Global_step 1075000	Train_loss: 0.3142	Eval_AUC: 0.8658
Epoch 13 Global_step 1076000	Train_loss: 0.3118	Eval_AUC: 0.8627
Epoch 13 Global_step 1077000	Train_loss: 0.3089	Eval_AUC: 0.8682
Epoch 13 Global_step 1078000	Train_loss: 0.3157	Eval_AUC: 0.8658
Epoch 13 Global_step 1079000	Train_loss: 0.3151	Eval_AUC: 0.8656
Epoch 13 Global_step 1080000	Train_loss: 0.3172	Eval_AUC: 0.8677
Epoch 13 Global_step 1081000	Train_loss: 0.3243	Eval_AUC: 0.8654
Epoch 13 Global_step 1082000	Train_loss: 0.3192	Eval_AUC: 0.8690
Epoch 13 Global_step 1083000	Train_loss: 0.3219	Eval_AUC: 0.8656
Epoch 13 Global_step 1084000	Train_loss: 0.3176	Eval_AUC: 0.8663
Epoch 13 Global_step 1085000	Train_loss: 0.3202	Eval_AUC: 0.8666
Epoch 13 Global_step 1086000	Train_loss: 0.3205	Eval_AUC: 0.8644
Epoch 13 Global_step 1087000	Train_loss: 0.3292	Eval_AUC: 0.8688
Epoch 13 Global_step 1088000	Train_loss: 0.3256	Eval_AUC: 0.8657
Epoch 13 Global_step 1089000	Train_loss: 0.3228	Eval_AUC: 0.8681
Epoch 13 Global_step 1090000	Train_loss: 0.3241	Eval_AUC: 0.8686
Epoch 13 Global_step 1091000	Train_loss: 0.3212	Eval_AUC: 0.8679
Epoch 13 Global_step 1092000	Train_loss: 0.3259	Eval_AUC: 0.8668
Epoch 13 Global_step 1093000	Train_loss: 0.3244	Eval_AUC: 0.8686
Epoch 13 Global_step 1094000	Train_loss: 0.3249	Eval_AUC: 0.8632
Epoch 13 Global_step 1095000	Train_loss: 0.3294	Eval_AUC: 0.8648
Epoch 13 Global_step 1096000	Train_loss: 0.3308	Eval_AUC: 0.8694
Epoch 13 Global_step 1097000	Train_loss: 0.3311	Eval_AUC: 0.8682
Epoch 13 Global_step 1098000	Train_loss: 0.3277	Eval_AUC: 0.8643
Epoch 13 Global_step 1099000	Train_loss: 0.3312	Eval_AUC: 0.8678
Epoch 13 Global_step 1100000	Train_loss: 0.3333	Eval_AUC: 0.8671
Epoch 13 Global_step 1101000	Train_loss: 0.3244	Eval_AUC: 0.8698
Epoch 13 Global_step 1102000	Train_loss: 0.3333	Eval_AUC: 0.8675
Epoch 13 Global_step 1103000	Train_loss: 0.3289	Eval_AUC: 0.8693
Epoch 13 Global_step 1104000	Train_loss: 0.3311	Eval_AUC: 0.8685
Epoch 13 Global_step 1105000	Train_loss: 0.3362	Eval_AUC: 0.8695
Epoch 13 Global_step 1106000	Train_loss: 0.3346	Eval_AUC: 0.8692
Epoch 13 Global_step 1107000	Train_loss: 0.3307	Eval_AUC: 0.8699
Epoch 13 Global_step 1108000	Train_loss: 0.3267	Eval_AUC: 0.8689
Epoch 13 Global_step 1109000	Train_loss: 0.3330	Eval_AUC: 0.8708
Epoch 13 Global_step 1110000	Train_loss: 0.3322	Eval_AUC: 0.8686
Epoch 13 Global_step 1111000	Train_loss: 0.3368	Eval_AUC: 0.8701
Epoch 13 Global_step 1112000	Train_loss: 0.3320	Eval_AUC: 0.8669
Epoch 13 Global_step 1113000	Train_loss: 0.3344	Eval_AUC: 0.8671
Epoch 13 Global_step 1114000	Train_loss: 0.3341	Eval_AUC: 0.8680
Epoch 13 Global_step 1115000	Train_loss: 0.3311	Eval_AUC: 0.8690
Epoch 13 Global_step 1116000	Train_loss: 0.3331	Eval_AUC: 0.8679
Epoch 13 Global_step 1117000	Train_loss: 0.3341	Eval_AUC: 0.8675
Epoch 13 Global_step 1118000	Train_loss: 0.3349	Eval_AUC: 0.8673
Epoch 13 Global_step 1119000	Train_loss: 0.3365	Eval_AUC: 0.8696
Epoch 13 Global_step 1120000	Train_loss: 0.3354	Eval_AUC: 0.8676
Epoch 13 Global_step 1121000	Train_loss: 0.3380	Eval_AUC: 0.8694
Epoch 13 Global_step 1122000	Train_loss: 0.3372	Eval_AUC: 0.8683
Epoch 13 Global_step 1123000	Train_loss: 0.3349	Eval_AUC: 0.8704
Epoch 13 Global_step 1124000	Train_loss: 0.3355	Eval_AUC: 0.8687
Epoch 13 Global_step 1125000	Train_loss: 0.3378	Eval_AUC: 0.8691
Epoch 13 Global_step 1126000	Train_loss: 0.3307	Eval_AUC: 0.8712
Epoch 13 Global_step 1127000	Train_loss: 0.3414	Eval_AUC: 0.8714
Epoch 13 Global_step 1128000	Train_loss: 0.3371	Eval_AUC: 0.8708
Epoch 13 Global_step 1129000	Train_loss: 0.3384	Eval_AUC: 0.8693
Epoch 13 Global_step 1130000	Train_loss: 0.3389	Eval_AUC: 0.8698
Epoch 13 Global_step 1131000	Train_loss: 0.3415	Eval_AUC: 0.8667
Epoch 13 Global_step 1132000	Train_loss: 0.3409	Eval_AUC: 0.8688
Epoch 13 Global_step 1133000	Train_loss: 0.3380	Eval_AUC: 0.8697
Epoch 13 Global_step 1134000	Train_loss: 0.3360	Eval_AUC: 0.8703
Epoch 13 Global_step 1135000	Train_loss: 0.3352	Eval_AUC: 0.8688
Epoch 13 Global_step 1136000	Train_loss: 0.3380	Eval_AUC: 0.8698
Epoch 13 Global_step 1137000	Train_loss: 0.3407	Eval_AUC: 0.8712
Epoch 13 Global_step 1138000	Train_loss: 0.3407	Eval_AUC: 0.8668
Epoch 13 Global_step 1139000	Train_loss: 0.3445	Eval_AUC: 0.8689
Epoch 13 Global_step 1140000	Train_loss: 0.3422	Eval_AUC: 0.8712
Epoch 13 Global_step 1141000	Train_loss: 0.3425	Eval_AUC: 0.8728
Epoch 13 DONE	Cost time: 12778.95
Epoch 14 Global_step 1142000	Train_loss: 0.2005	Eval_AUC: 0.8693
Epoch 14 Global_step 1143000	Train_loss: 0.2965	Eval_AUC: 0.8700
Epoch 14 Global_step 1144000	Train_loss: 0.3020	Eval_AUC: 0.8691
Epoch 14 Global_step 1145000	Train_loss: 0.3010	Eval_AUC: 0.8672
Epoch 14 Global_step 1146000	Train_loss: 0.3029	Eval_AUC: 0.8666
Epoch 14 Global_step 1147000	Train_loss: 0.3023	Eval_AUC: 0.8662
Epoch 14 Global_step 1148000	Train_loss: 0.3027	Eval_AUC: 0.8663
Epoch 14 Global_step 1149000	Train_loss: 0.3016	Eval_AUC: 0.8647
Epoch 14 Global_step 1150000	Train_loss: 0.3019	Eval_AUC: 0.8663
Epoch 14 Global_step 1151000	Train_loss: 0.3044	Eval_AUC: 0.8640
Epoch 14 Global_step 1152000	Train_loss: 0.2967	Eval_AUC: 0.8648
Epoch 14 Global_step 1153000	Train_loss: 0.3116	Eval_AUC: 0.8648
Epoch 14 Global_step 1154000	Train_loss: 0.3125	Eval_AUC: 0.8655
Epoch 14 Global_step 1155000	Train_loss: 0.2990	Eval_AUC: 0.8661
Epoch 14 Global_step 1156000	Train_loss: 0.3048	Eval_AUC: 0.8662
Epoch 14 Global_step 1157000	Train_loss: 0.3083	Eval_AUC: 0.8628
Epoch 14 Global_step 1158000	Train_loss: 0.3142	Eval_AUC: 0.8637
Epoch 14 Global_step 1159000	Train_loss: 0.3079	Eval_AUC: 0.8639
Epoch 14 Global_step 1160000	Train_loss: 0.3075	Eval_AUC: 0.8632
Epoch 14 Global_step 1161000	Train_loss: 0.3123	Eval_AUC: 0.8634
Epoch 14 Global_step 1162000	Train_loss: 0.3052	Eval_AUC: 0.8658
Epoch 14 Global_step 1163000	Train_loss: 0.3142	Eval_AUC: 0.8642
Epoch 14 Global_step 1164000	Train_loss: 0.3145	Eval_AUC: 0.8675
Epoch 14 Global_step 1165000	Train_loss: 0.3107	Eval_AUC: 0.8646
Epoch 14 Global_step 1166000	Train_loss: 0.3098	Eval_AUC: 0.8658
Epoch 14 Global_step 1167000	Train_loss: 0.3183	Eval_AUC: 0.8668
Epoch 14 Global_step 1168000	Train_loss: 0.3192	Eval_AUC: 0.8663
Epoch 14 Global_step 1169000	Train_loss: 0.3173	Eval_AUC: 0.8668
Epoch 14 Global_step 1170000	Train_loss: 0.3121	Eval_AUC: 0.8643
Epoch 14 Global_step 1171000	Train_loss: 0.3127	Eval_AUC: 0.8668
Epoch 14 Global_step 1172000	Train_loss: 0.3169	Eval_AUC: 0.8644
Epoch 14 Global_step 1173000	Train_loss: 0.3230	Eval_AUC: 0.8629
Epoch 14 Global_step 1174000	Train_loss: 0.3234	Eval_AUC: 0.8663
Epoch 14 Global_step 1175000	Train_loss: 0.3178	Eval_AUC: 0.8669
Epoch 14 Global_step 1176000	Train_loss: 0.3203	Eval_AUC: 0.8673
Epoch 14 Global_step 1177000	Train_loss: 0.3193	Eval_AUC: 0.8659
Epoch 14 Global_step 1178000	Train_loss: 0.3233	Eval_AUC: 0.8659
Epoch 14 Global_step 1179000	Train_loss: 0.3167	Eval_AUC: 0.8642
Epoch 14 Global_step 1180000	Train_loss: 0.3227	Eval_AUC: 0.8683
Epoch 14 Global_step 1181000	Train_loss: 0.3222	Eval_AUC: 0.8676
Epoch 14 Global_step 1182000	Train_loss: 0.3187	Eval_AUC: 0.8659
Epoch 14 Global_step 1183000	Train_loss: 0.3227	Eval_AUC: 0.8648
Epoch 14 Global_step 1184000	Train_loss: 0.3244	Eval_AUC: 0.8647
Epoch 14 Global_step 1185000	Train_loss: 0.3226	Eval_AUC: 0.8689
Epoch 14 Global_step 1186000	Train_loss: 0.3212	Eval_AUC: 0.8655
Epoch 14 Global_step 1187000	Train_loss: 0.3175	Eval_AUC: 0.8654
Epoch 14 Global_step 1188000	Train_loss: 0.3277	Eval_AUC: 0.8628
Epoch 14 Global_step 1189000	Train_loss: 0.3269	Eval_AUC: 0.8682
Epoch 14 Global_step 1190000	Train_loss: 0.3235	Eval_AUC: 0.8669
Epoch 14 Global_step 1191000	Train_loss: 0.3264	Eval_AUC: 0.8646
Epoch 14 Global_step 1192000	Train_loss: 0.3253	Eval_AUC: 0.8644
Epoch 14 Global_step 1193000	Train_loss: 0.3240	Eval_AUC: 0.8673
Epoch 14 Global_step 1194000	Train_loss: 0.3254	Eval_AUC: 0.8665
Epoch 14 Global_step 1195000	Train_loss: 0.3283	Eval_AUC: 0.8682
Epoch 14 Global_step 1196000	Train_loss: 0.3301	Eval_AUC: 0.8654
Epoch 14 Global_step 1197000	Train_loss: 0.3311	Eval_AUC: 0.8700
Epoch 14 Global_step 1198000	Train_loss: 0.3324	Eval_AUC: 0.8690
Epoch 14 Global_step 1199000	Train_loss: 0.3293	Eval_AUC: 0.8694
Epoch 14 Global_step 1200000	Train_loss: 0.3284	Eval_AUC: 0.8668
Epoch 14 Global_step 1201000	Train_loss: 0.3292	Eval_AUC: 0.8673
Epoch 14 Global_step 1202000	Train_loss: 0.3309	Eval_AUC: 0.8679
Epoch 14 Global_step 1203000	Train_loss: 0.3246	Eval_AUC: 0.8663
Epoch 14 Global_step 1204000	Train_loss: 0.3340	Eval_AUC: 0.8653
Epoch 14 Global_step 1205000	Train_loss: 0.3306	Eval_AUC: 0.8681
Epoch 14 Global_step 1206000	Train_loss: 0.3252	Eval_AUC: 0.8667
Epoch 14 Global_step 1207000	Train_loss: 0.3282	Eval_AUC: 0.8691
Epoch 14 Global_step 1208000	Train_loss: 0.3307	Eval_AUC: 0.8640
Epoch 14 Global_step 1209000	Train_loss: 0.3283	Eval_AUC: 0.8647
Epoch 14 Global_step 1210000	Train_loss: 0.3317	Eval_AUC: 0.8687
Epoch 14 Global_step 1211000	Train_loss: 0.3295	Eval_AUC: 0.8661
Epoch 14 Global_step 1212000	Train_loss: 0.3291	Eval_AUC: 0.8664
Epoch 14 Global_step 1213000	Train_loss: 0.3321	Eval_AUC: 0.8661
Epoch 14 Global_step 1214000	Train_loss: 0.3336	Eval_AUC: 0.8693
Epoch 14 Global_step 1215000	Train_loss: 0.3296	Eval_AUC: 0.8665
Epoch 14 Global_step 1216000	Train_loss: 0.3349	Eval_AUC: 0.8674
Epoch 14 Global_step 1217000	Train_loss: 0.3383	Eval_AUC: 0.8668
Epoch 14 Global_step 1218000	Train_loss: 0.3334	Eval_AUC: 0.8664
Epoch 14 Global_step 1219000	Train_loss: 0.3297	Eval_AUC: 0.8673
Epoch 14 Global_step 1220000	Train_loss: 0.3365	Eval_AUC: 0.8679
Epoch 14 Global_step 1221000	Train_loss: 0.3304	Eval_AUC: 0.8680
Epoch 14 Global_step 1222000	Train_loss: 0.3332	Eval_AUC: 0.8678
Epoch 14 DONE	Cost time: 13603.67
Epoch 15 Global_step 1223000	Train_loss: 0.0426	Eval_AUC: 0.8675
Epoch 15 Global_step 1224000	Train_loss: 0.2881	Eval_AUC: 0.8640
Epoch 15 Global_step 1225000	Train_loss: 0.2880	Eval_AUC: 0.8665
Epoch 15 Global_step 1226000	Train_loss: 0.2954	Eval_AUC: 0.8644
Epoch 15 Global_step 1227000	Train_loss: 0.2887	Eval_AUC: 0.8636
Epoch 15 Global_step 1228000	Train_loss: 0.2896	Eval_AUC: 0.8636
Epoch 15 Global_step 1229000	Train_loss: 0.2885	Eval_AUC: 0.8647
Epoch 15 Global_step 1230000	Train_loss: 0.2925	Eval_AUC: 0.8637
Epoch 15 Global_step 1231000	Train_loss: 0.2917	Eval_AUC: 0.8628
Epoch 15 Global_step 1232000	Train_loss: 0.2981	Eval_AUC: 0.8653
Epoch 15 Global_step 1233000	Train_loss: 0.2954	Eval_AUC: 0.8627
Epoch 15 Global_step 1234000	Train_loss: 0.2981	Eval_AUC: 0.8609
Epoch 15 Global_step 1235000	Train_loss: 0.2995	Eval_AUC: 0.8616
Epoch 15 Global_step 1236000	Train_loss: 0.2953	Eval_AUC: 0.8638
Epoch 15 Global_step 1237000	Train_loss: 0.2973	Eval_AUC: 0.8611
Epoch 15 Global_step 1238000	Train_loss: 0.3027	Eval_AUC: 0.8649
Epoch 15 Global_step 1239000	Train_loss: 0.3000	Eval_AUC: 0.8637
Epoch 15 Global_step 1240000	Train_loss: 0.3050	Eval_AUC: 0.8622
Epoch 15 Global_step 1241000	Train_loss: 0.3026	Eval_AUC: 0.8644
Epoch 15 Global_step 1242000	Train_loss: 0.3054	Eval_AUC: 0.8623
Epoch 15 Global_step 1243000	Train_loss: 0.3029	Eval_AUC: 0.8601
Epoch 15 Global_step 1244000	Train_loss: 0.3081	Eval_AUC: 0.8639
Epoch 15 Global_step 1245000	Train_loss: 0.3052	Eval_AUC: 0.8630
Epoch 15 Global_step 1246000	Train_loss: 0.3116	Eval_AUC: 0.8592
Epoch 15 Global_step 1247000	Train_loss: 0.3025	Eval_AUC: 0.8603
Epoch 15 Global_step 1248000	Train_loss: 0.3091	Eval_AUC: 0.8626
Epoch 15 Global_step 1249000	Train_loss: 0.3129	Eval_AUC: 0.8624
Epoch 15 Global_step 1250000	Train_loss: 0.3052	Eval_AUC: 0.8629
Epoch 15 Global_step 1251000	Train_loss: 0.3068	Eval_AUC: 0.8627
Epoch 15 Global_step 1252000	Train_loss: 0.3080	Eval_AUC: 0.8625
Epoch 15 Global_step 1253000	Train_loss: 0.3122	Eval_AUC: 0.8618
Epoch 15 Global_step 1254000	Train_loss: 0.3093	Eval_AUC: 0.8631
Epoch 15 Global_step 1255000	Train_loss: 0.3141	Eval_AUC: 0.8639
Epoch 15 Global_step 1256000	Train_loss: 0.3082	Eval_AUC: 0.8636
Epoch 15 Global_step 1257000	Train_loss: 0.3114	Eval_AUC: 0.8634
Epoch 15 Global_step 1258000	Train_loss: 0.3034	Eval_AUC: 0.8636
Epoch 15 Global_step 1259000	Train_loss: 0.3132	Eval_AUC: 0.8641
Epoch 15 Global_step 1260000	Train_loss: 0.3179	Eval_AUC: 0.8623
Epoch 15 Global_step 1261000	Train_loss: 0.3129	Eval_AUC: 0.8645
Epoch 15 Global_step 1262000	Train_loss: 0.3152	Eval_AUC: 0.8630
Epoch 15 Global_step 1263000	Train_loss: 0.3161	Eval_AUC: 0.8627
Epoch 15 Global_step 1264000	Train_loss: 0.3124	Eval_AUC: 0.8648
Epoch 15 Global_step 1265000	Train_loss: 0.3214	Eval_AUC: 0.8653
Epoch 15 Global_step 1266000	Train_loss: 0.3243	Eval_AUC: 0.8650
Epoch 15 Global_step 1267000	Train_loss: 0.3204	Eval_AUC: 0.8622
Epoch 15 Global_step 1268000	Train_loss: 0.3067	Eval_AUC: 0.8645
Epoch 15 Global_step 1269000	Train_loss: 0.3186	Eval_AUC: 0.8675
Epoch 15 Global_step 1270000	Train_loss: 0.3174	Eval_AUC: 0.8642
Epoch 15 Global_step 1271000	Train_loss: 0.3234	Eval_AUC: 0.8635
Epoch 15 Global_step 1272000	Train_loss: 0.3240	Eval_AUC: 0.8643
Epoch 15 Global_step 1273000	Train_loss: 0.3181	Eval_AUC: 0.8650
Epoch 15 Global_step 1274000	Train_loss: 0.3166	Eval_AUC: 0.8643
Epoch 15 Global_step 1275000	Train_loss: 0.3142	Eval_AUC: 0.8634
Epoch 15 Global_step 1276000	Train_loss: 0.3207	Eval_AUC: 0.8670
Epoch 15 Global_step 1277000	Train_loss: 0.3152	Eval_AUC: 0.8642
Epoch 15 Global_step 1278000	Train_loss: 0.3152	Eval_AUC: 0.8670
Epoch 15 Global_step 1279000	Train_loss: 0.3225	Eval_AUC: 0.8635
Epoch 15 Global_step 1280000	Train_loss: 0.3195	Eval_AUC: 0.8654
Epoch 15 Global_step 1281000	Train_loss: 0.3219	Eval_AUC: 0.8649
Epoch 15 Global_step 1282000	Train_loss: 0.3250	Eval_AUC: 0.8649
Epoch 15 Global_step 1283000	Train_loss: 0.3275	Eval_AUC: 0.8629
Epoch 15 Global_step 1284000	Train_loss: 0.3248	Eval_AUC: 0.8617
Epoch 15 Global_step 1285000	Train_loss: 0.3259	Eval_AUC: 0.8614
Epoch 15 Global_step 1286000	Train_loss: 0.3297	Eval_AUC: 0.8656
Epoch 15 Global_step 1287000	Train_loss: 0.3224	Eval_AUC: 0.8651
Epoch 15 Global_step 1288000	Train_loss: 0.3246	Eval_AUC: 0.8610
Epoch 15 Global_step 1289000	Train_loss: 0.3210	Eval_AUC: 0.8627
Epoch 15 Global_step 1290000	Train_loss: 0.3250	Eval_AUC: 0.8619
Epoch 15 Global_step 1291000	Train_loss: 0.3283	Eval_AUC: 0.8662
Epoch 15 Global_step 1292000	Train_loss: 0.3261	Eval_AUC: 0.8664
Epoch 15 Global_step 1293000	Train_loss: 0.3237	Eval_AUC: 0.8644
Epoch 15 Global_step 1294000	Train_loss: 0.3246	Eval_AUC: 0.8676
Epoch 15 Global_step 1295000	Train_loss: 0.3240	Eval_AUC: 0.8633
Epoch 15 Global_step 1296000	Train_loss: 0.3233	Eval_AUC: 0.8643
Epoch 15 Global_step 1297000	Train_loss: 0.3237	Eval_AUC: 0.8682
Epoch 15 Global_step 1298000	Train_loss: 0.3196	Eval_AUC: 0.8645
Epoch 15 Global_step 1299000	Train_loss: 0.3276	Eval_AUC: 0.8694
Epoch 15 Global_step 1300000	Train_loss: 0.3279	Eval_AUC: 0.8648
Epoch 15 Global_step 1301000	Train_loss: 0.3284	Eval_AUC: 0.8653
Epoch 15 Global_step 1302000	Train_loss: 0.3278	Eval_AUC: 0.8663
Epoch 15 Global_step 1303000	Train_loss: 0.3252	Eval_AUC: 0.8647
Epoch 15 Global_step 1304000	Train_loss: 0.3304	Eval_AUC: 0.8658
Epoch 15 DONE	Cost time: 14434.30
Epoch 16 Global_step 1305000	Train_loss: 0.1742	Eval_AUC: 0.8664
Epoch 16 Global_step 1306000	Train_loss: 0.2842	Eval_AUC: 0.8644
Epoch 16 Global_step 1307000	Train_loss: 0.2841	Eval_AUC: 0.8641
Epoch 16 Global_step 1308000	Train_loss: 0.2812	Eval_AUC: 0.8640
Epoch 16 Global_step 1309000	Train_loss: 0.2835	Eval_AUC: 0.8619
Epoch 16 Global_step 1310000	Train_loss: 0.2847	Eval_AUC: 0.8635
Epoch 16 Global_step 1311000	Train_loss: 0.2876	Eval_AUC: 0.8631
Epoch 16 Global_step 1312000	Train_loss: 0.2875	Eval_AUC: 0.8600
Epoch 16 Global_step 1313000	Train_loss: 0.2863	Eval_AUC: 0.8623
Epoch 16 Global_step 1314000	Train_loss: 0.2880	Eval_AUC: 0.8611
Epoch 16 Global_step 1315000	Train_loss: 0.2888	Eval_AUC: 0.8616
Epoch 16 Global_step 1316000	Train_loss: 0.2890	Eval_AUC: 0.8605
Epoch 16 Global_step 1317000	Train_loss: 0.2917	Eval_AUC: 0.8628
Epoch 16 Global_step 1318000	Train_loss: 0.2897	Eval_AUC: 0.8623
Epoch 16 Global_step 1319000	Train_loss: 0.2922	Eval_AUC: 0.8625
Epoch 16 Global_step 1320000	Train_loss: 0.2966	Eval_AUC: 0.8608
Epoch 16 Global_step 1321000	Train_loss: 0.2925	Eval_AUC: 0.8608
Epoch 16 Global_step 1322000	Train_loss: 0.2969	Eval_AUC: 0.8628
Epoch 16 Global_step 1323000	Train_loss: 0.2985	Eval_AUC: 0.8609
Epoch 16 Global_step 1324000	Train_loss: 0.2952	Eval_AUC: 0.8635
Epoch 16 Global_step 1325000	Train_loss: 0.2954	Eval_AUC: 0.8594
Epoch 16 Global_step 1326000	Train_loss: 0.2952	Eval_AUC: 0.8612
Epoch 16 Global_step 1327000	Train_loss: 0.3005	Eval_AUC: 0.8576
Epoch 16 Global_step 1328000	Train_loss: 0.3039	Eval_AUC: 0.8583
Epoch 16 Global_step 1329000	Train_loss: 0.2998	Eval_AUC: 0.8615
Epoch 16 Global_step 1330000	Train_loss: 0.2987	Eval_AUC: 0.8632
Epoch 16 Global_step 1331000	Train_loss: 0.2979	Eval_AUC: 0.8600
Epoch 16 Global_step 1332000	Train_loss: 0.3027	Eval_AUC: 0.8591
Epoch 16 Global_step 1333000	Train_loss: 0.2972	Eval_AUC: 0.8614
Epoch 16 Global_step 1334000	Train_loss: 0.3057	Eval_AUC: 0.8615
Epoch 16 Global_step 1335000	Train_loss: 0.3046	Eval_AUC: 0.8630
Epoch 16 Global_step 1336000	Train_loss: 0.3029	Eval_AUC: 0.8639
Epoch 16 Global_step 1337000	Train_loss: 0.3028	Eval_AUC: 0.8588
Epoch 16 Global_step 1338000	Train_loss: 0.3073	Eval_AUC: 0.8607
Epoch 16 Global_step 1339000	Train_loss: 0.3022	Eval_AUC: 0.8630
Epoch 16 Global_step 1340000	Train_loss: 0.3051	Eval_AUC: 0.8619
Epoch 16 Global_step 1341000	Train_loss: 0.3043	Eval_AUC: 0.8612
Epoch 16 Global_step 1342000	Train_loss: 0.3094	Eval_AUC: 0.8622
Epoch 16 Global_step 1343000	Train_loss: 0.3082	Eval_AUC: 0.8619
Epoch 16 Global_step 1344000	Train_loss: 0.3016	Eval_AUC: 0.8598
Epoch 16 Global_step 1345000	Train_loss: 0.3098	Eval_AUC: 0.8610
Epoch 16 Global_step 1346000	Train_loss: 0.3088	Eval_AUC: 0.8589
Epoch 16 Global_step 1347000	Train_loss: 0.3052	Eval_AUC: 0.8609
Epoch 16 Global_step 1348000	Train_loss: 0.3120	Eval_AUC: 0.8641
Epoch 16 Global_step 1349000	Train_loss: 0.3110	Eval_AUC: 0.8631
Epoch 16 Global_step 1350000	Train_loss: 0.3099	Eval_AUC: 0.8647
Epoch 16 Global_step 1351000	Train_loss: 0.3090	Eval_AUC: 0.8621
Epoch 16 Global_step 1352000	Train_loss: 0.3075	Eval_AUC: 0.8599
Epoch 16 Global_step 1353000	Train_loss: 0.3167	Eval_AUC: 0.8616
Epoch 16 Global_step 1354000	Train_loss: 0.3107	Eval_AUC: 0.8604
Epoch 16 Global_step 1355000	Train_loss: 0.3100	Eval_AUC: 0.8641
Epoch 16 Global_step 1356000	Train_loss: 0.3113	Eval_AUC: 0.8634
Epoch 16 Global_step 1357000	Train_loss: 0.3132	Eval_AUC: 0.8638
Epoch 16 Global_step 1358000	Train_loss: 0.3123	Eval_AUC: 0.8618
Epoch 16 Global_step 1359000	Train_loss: 0.3163	Eval_AUC: 0.8618
Epoch 16 Global_step 1360000	Train_loss: 0.3163	Eval_AUC: 0.8618
Epoch 16 Global_step 1361000	Train_loss: 0.3095	Eval_AUC: 0.8631
Epoch 16 Global_step 1362000	Train_loss: 0.3184	Eval_AUC: 0.8612
Epoch 16 Global_step 1363000	Train_loss: 0.3096	Eval_AUC: 0.8644
Epoch 16 Global_step 1364000	Train_loss: 0.3122	Eval_AUC: 0.8653
Epoch 16 Global_step 1365000	Train_loss: 0.3177	Eval_AUC: 0.8622
Epoch 16 Global_step 1366000	Train_loss: 0.3167	Eval_AUC: 0.8634
Epoch 16 Global_step 1367000	Train_loss: 0.3180	Eval_AUC: 0.8616
Epoch 16 Global_step 1368000	Train_loss: 0.3183	Eval_AUC: 0.8628
Epoch 16 Global_step 1369000	Train_loss: 0.3151	Eval_AUC: 0.8629
Epoch 16 Global_step 1370000	Train_loss: 0.3234	Eval_AUC: 0.8626
Epoch 16 Global_step 1371000	Train_loss: 0.3209	Eval_AUC: 0.8635
Epoch 16 Global_step 1372000	Train_loss: 0.3217	Eval_AUC: 0.8616
Epoch 16 Global_step 1373000	Train_loss: 0.3236	Eval_AUC: 0.8630
Epoch 16 Global_step 1374000	Train_loss: 0.3155	Eval_AUC: 0.8639
Epoch 16 Global_step 1375000	Train_loss: 0.3159	Eval_AUC: 0.8609
Epoch 16 Global_step 1376000	Train_loss: 0.3228	Eval_AUC: 0.8599
Epoch 16 Global_step 1377000	Train_loss: 0.3211	Eval_AUC: 0.8636
Epoch 16 Global_step 1378000	Train_loss: 0.3179	Eval_AUC: 0.8637
Epoch 16 Global_step 1379000	Train_loss: 0.3188	Eval_AUC: 0.8624
Epoch 16 Global_step 1380000	Train_loss: 0.3157	Eval_AUC: 0.8632
Epoch 16 Global_step 1381000	Train_loss: 0.3211	Eval_AUC: 0.8632
Epoch 16 Global_step 1382000	Train_loss: 0.3239	Eval_AUC: 0.8621
Epoch 16 Global_step 1383000	Train_loss: 0.3212	Eval_AUC: 0.8618
Epoch 16 Global_step 1384000	Train_loss: 0.3204	Eval_AUC: 0.8626
Epoch 16 Global_step 1385000	Train_loss: 0.3191	Eval_AUC: 0.8657
Epoch 16 DONE	Cost time: 15278.47
Epoch 17 Global_step 1386000	Train_loss: 0.0257	Eval_AUC: 0.8632
Epoch 17 Global_step 1387000	Train_loss: 0.2782	Eval_AUC: 0.8623
Epoch 17 Global_step 1388000	Train_loss: 0.2753	Eval_AUC: 0.8606
Epoch 17 Global_step 1389000	Train_loss: 0.2736	Eval_AUC: 0.8621
Epoch 17 Global_step 1390000	Train_loss: 0.2758	Eval_AUC: 0.8595
Epoch 17 Global_step 1391000	Train_loss: 0.2828	Eval_AUC: 0.8606
Epoch 17 Global_step 1392000	Train_loss: 0.2789	Eval_AUC: 0.8588
Epoch 17 Global_step 1393000	Train_loss: 0.2700	Eval_AUC: 0.8607
Epoch 17 Global_step 1394000	Train_loss: 0.2803	Eval_AUC: 0.8599
Epoch 17 Global_step 1395000	Train_loss: 0.2799	Eval_AUC: 0.8608
Epoch 17 Global_step 1396000	Train_loss: 0.2872	Eval_AUC: 0.8618
Epoch 17 Global_step 1397000	Train_loss: 0.2819	Eval_AUC: 0.8601
Epoch 17 Global_step 1398000	Train_loss: 0.2851	Eval_AUC: 0.8583
Epoch 17 Global_step 1399000	Train_loss: 0.2843	Eval_AUC: 0.8591
Epoch 17 Global_step 1400000	Train_loss: 0.2882	Eval_AUC: 0.8597
Epoch 17 Global_step 1401000	Train_loss: 0.2848	Eval_AUC: 0.8596
Epoch 17 Global_step 1402000	Train_loss: 0.2850	Eval_AUC: 0.8574
Epoch 17 Global_step 1403000	Train_loss: 0.2917	Eval_AUC: 0.8603
Epoch 17 Global_step 1404000	Train_loss: 0.2929	Eval_AUC: 0.8588
Epoch 17 Global_step 1405000	Train_loss: 0.2914	Eval_AUC: 0.8590
Epoch 17 Global_step 1406000	Train_loss: 0.2943	Eval_AUC: 0.8576
Epoch 17 Global_step 1407000	Train_loss: 0.2882	Eval_AUC: 0.8602
Epoch 17 Global_step 1408000	Train_loss: 0.2897	Eval_AUC: 0.8599
Epoch 17 Global_step 1409000	Train_loss: 0.2899	Eval_AUC: 0.8617
Epoch 17 Global_step 1410000	Train_loss: 0.2945	Eval_AUC: 0.8564
Epoch 17 Global_step 1411000	Train_loss: 0.2905	Eval_AUC: 0.8609
Epoch 17 Global_step 1412000	Train_loss: 0.2923	Eval_AUC: 0.8591
Epoch 17 Global_step 1413000	Train_loss: 0.2966	Eval_AUC: 0.8598
Epoch 17 Global_step 1414000	Train_loss: 0.2945	Eval_AUC: 0.8576
Epoch 17 Global_step 1415000	Train_loss: 0.2929	Eval_AUC: 0.8598
Epoch 17 Global_step 1416000	Train_loss: 0.2956	Eval_AUC: 0.8612
Epoch 17 Global_step 1417000	Train_loss: 0.2975	Eval_AUC: 0.8605
Epoch 17 Global_step 1418000	Train_loss: 0.3010	Eval_AUC: 0.8573
Epoch 17 Global_step 1419000	Train_loss: 0.2991	Eval_AUC: 0.8607
Epoch 17 Global_step 1420000	Train_loss: 0.3017	Eval_AUC: 0.8605
Epoch 17 Global_step 1421000	Train_loss: 0.3024	Eval_AUC: 0.8601
Epoch 17 Global_step 1422000	Train_loss: 0.2979	Eval_AUC: 0.8610
Epoch 17 Global_step 1423000	Train_loss: 0.2951	Eval_AUC: 0.8618
Epoch 17 Global_step 1424000	Train_loss: 0.3013	Eval_AUC: 0.8615
Epoch 17 Global_step 1425000	Train_loss: 0.2970	Eval_AUC: 0.8607
Epoch 17 Global_step 1426000	Train_loss: 0.3046	Eval_AUC: 0.8604
Epoch 17 Global_step 1427000	Train_loss: 0.3013	Eval_AUC: 0.8600
Epoch 17 Global_step 1428000	Train_loss: 0.2950	Eval_AUC: 0.8563
Epoch 17 Global_step 1429000	Train_loss: 0.3039	Eval_AUC: 0.8625
Epoch 17 Global_step 1430000	Train_loss: 0.3024	Eval_AUC: 0.8596
Epoch 17 Global_step 1431000	Train_loss: 0.3002	Eval_AUC: 0.8605
Epoch 17 Global_step 1432000	Train_loss: 0.3024	Eval_AUC: 0.8591
Epoch 17 Global_step 1433000	Train_loss: 0.3040	Eval_AUC: 0.8613
Epoch 17 Global_step 1434000	Train_loss: 0.3044	Eval_AUC: 0.8601
Epoch 17 Global_step 1435000	Train_loss: 0.3054	Eval_AUC: 0.8617
Epoch 17 Global_step 1436000	Train_loss: 0.3045	Eval_AUC: 0.8609
Epoch 17 Global_step 1437000	Train_loss: 0.3058	Eval_AUC: 0.8584
Epoch 17 Global_step 1438000	Train_loss: 0.3061	Eval_AUC: 0.8598
Epoch 17 Global_step 1439000	Train_loss: 0.3018	Eval_AUC: 0.8620
Epoch 17 Global_step 1440000	Train_loss: 0.3101	Eval_AUC: 0.8585
Epoch 17 Global_step 1441000	Train_loss: 0.3045	Eval_AUC: 0.8615
Epoch 17 Global_step 1442000	Train_loss: 0.3068	Eval_AUC: 0.8593
Epoch 17 Global_step 1443000	Train_loss: 0.3121	Eval_AUC: 0.8585
Epoch 17 Global_step 1444000	Train_loss: 0.3090	Eval_AUC: 0.8579
Epoch 17 Global_step 1445000	Train_loss: 0.3088	Eval_AUC: 0.8575
Epoch 17 Global_step 1446000	Train_loss: 0.3085	Eval_AUC: 0.8589
Epoch 17 Global_step 1447000	Train_loss: 0.3085	Eval_AUC: 0.8598
Epoch 17 Global_step 1448000	Train_loss: 0.3102	Eval_AUC: 0.8596
Epoch 17 Global_step 1449000	Train_loss: 0.3072	Eval_AUC: 0.8607
Epoch 17 Global_step 1450000	Train_loss: 0.3123	Eval_AUC: 0.8603
Epoch 17 Global_step 1451000	Train_loss: 0.3128	Eval_AUC: 0.8610
Epoch 17 Global_step 1452000	Train_loss: 0.3098	Eval_AUC: 0.8612
Epoch 17 Global_step 1453000	Train_loss: 0.3072	Eval_AUC: 0.8603
Epoch 17 Global_step 1454000	Train_loss: 0.3110	Eval_AUC: 0.8592
Epoch 17 Global_step 1455000	Train_loss: 0.3087	Eval_AUC: 0.8597
Epoch 17 Global_step 1456000	Train_loss: 0.3073	Eval_AUC: 0.8617
Epoch 17 Global_step 1457000	Train_loss: 0.3153	Eval_AUC: 0.8590
Epoch 17 Global_step 1458000	Train_loss: 0.3128	Eval_AUC: 0.8593
Epoch 17 Global_step 1459000	Train_loss: 0.3128	Eval_AUC: 0.8606
Epoch 17 Global_step 1460000	Train_loss: 0.3123	Eval_AUC: 0.8621
Epoch 17 Global_step 1461000	Train_loss: 0.3103	Eval_AUC: 0.8601
Epoch 17 Global_step 1462000	Train_loss: 0.3093	Eval_AUC: 0.8620
Epoch 17 Global_step 1463000	Train_loss: 0.3153	Eval_AUC: 0.8621
Epoch 17 Global_step 1464000	Train_loss: 0.3152	Eval_AUC: 0.8614
Epoch 17 Global_step 1465000	Train_loss: 0.3127	Eval_AUC: 0.8597
Epoch 17 Global_step 1466000	Train_loss: 0.3145	Eval_AUC: 0.8623
Epoch 17 Global_step 1467000	Train_loss: 0.3099	Eval_AUC: 0.8629
Epoch 17 DONE	Cost time: 16106.29
Epoch 18 Global_step 1468000	Train_loss: 0.1549	Eval_AUC: 0.8596
Epoch 18 Global_step 1469000	Train_loss: 0.2673	Eval_AUC: 0.8613
Epoch 18 Global_step 1470000	Train_loss: 0.2678	Eval_AUC: 0.8596
Epoch 18 Global_step 1471000	Train_loss: 0.2649	Eval_AUC: 0.8545
Epoch 18 Global_step 1472000	Train_loss: 0.2729	Eval_AUC: 0.8589
Epoch 18 Global_step 1473000	Train_loss: 0.2692	Eval_AUC: 0.8592
Epoch 18 Global_step 1474000	Train_loss: 0.2660	Eval_AUC: 0.8587
Epoch 18 Global_step 1475000	Train_loss: 0.2680	Eval_AUC: 0.8554
Epoch 18 Global_step 1476000	Train_loss: 0.2749	Eval_AUC: 0.8553
Epoch 18 Global_step 1477000	Train_loss: 0.2727	Eval_AUC: 0.8545
Epoch 18 Global_step 1478000	Train_loss: 0.2756	Eval_AUC: 0.8540
Epoch 18 Global_step 1479000	Train_loss: 0.2770	Eval_AUC: 0.8575
Epoch 18 Global_step 1480000	Train_loss: 0.2741	Eval_AUC: 0.8591
Epoch 18 Global_step 1481000	Train_loss: 0.2748	Eval_AUC: 0.8577
Epoch 18 Global_step 1482000	Train_loss: 0.2752	Eval_AUC: 0.8573
Epoch 18 Global_step 1483000	Train_loss: 0.2831	Eval_AUC: 0.8558
Epoch 18 Global_step 1484000	Train_loss: 0.2780	Eval_AUC: 0.8573
Epoch 18 Global_step 1485000	Train_loss: 0.2786	Eval_AUC: 0.8579
Epoch 18 Global_step 1486000	Train_loss: 0.2802	Eval_AUC: 0.8556
Epoch 18 Global_step 1487000	Train_loss: 0.2824	Eval_AUC: 0.8570
Epoch 18 Global_step 1488000	Train_loss: 0.2866	Eval_AUC: 0.8557
Epoch 18 Global_step 1489000	Train_loss: 0.2788	Eval_AUC: 0.8560
Epoch 18 Global_step 1490000	Train_loss: 0.2799	Eval_AUC: 0.8566
Epoch 18 Global_step 1491000	Train_loss: 0.2838	Eval_AUC: 0.8575
Epoch 18 Global_step 1492000	Train_loss: 0.2825	Eval_AUC: 0.8571
Epoch 18 Global_step 1493000	Train_loss: 0.2878	Eval_AUC: 0.8577
Epoch 18 Global_step 1494000	Train_loss: 0.2887	Eval_AUC: 0.8548
Epoch 18 Global_step 1495000	Train_loss: 0.2870	Eval_AUC: 0.8575
Epoch 18 Global_step 1496000	Train_loss: 0.2801	Eval_AUC: 0.8560
Epoch 18 Global_step 1497000	Train_loss: 0.2908	Eval_AUC: 0.8588
Epoch 18 Global_step 1498000	Train_loss: 0.2831	Eval_AUC: 0.8576
Epoch 18 Global_step 1499000	Train_loss: 0.2898	Eval_AUC: 0.8545
Epoch 18 Global_step 1500000	Train_loss: 0.2918	Eval_AUC: 0.8558
Epoch 18 Global_step 1501000	Train_loss: 0.2897	Eval_AUC: 0.8564
Epoch 18 Global_step 1502000	Train_loss: 0.2885	Eval_AUC: 0.8554
Epoch 18 Global_step 1503000	Train_loss: 0.2942	Eval_AUC: 0.8590
Epoch 18 Global_step 1504000	Train_loss: 0.2925	Eval_AUC: 0.8549
Epoch 18 Global_step 1505000	Train_loss: 0.2881	Eval_AUC: 0.8576
Epoch 18 Global_step 1506000	Train_loss: 0.2878	Eval_AUC: 0.8563
Epoch 18 Global_step 1507000	Train_loss: 0.2909	Eval_AUC: 0.8601
Epoch 18 Global_step 1508000	Train_loss: 0.2945	Eval_AUC: 0.8584
Epoch 18 Global_step 1509000	Train_loss: 0.2905	Eval_AUC: 0.8561
Epoch 18 Global_step 1510000	Train_loss: 0.2942	Eval_AUC: 0.8594
Epoch 18 Global_step 1511000	Train_loss: 0.2962	Eval_AUC: 0.8570
Epoch 18 Global_step 1512000	Train_loss: 0.2955	Eval_AUC: 0.8604
Epoch 18 Global_step 1513000	Train_loss: 0.2968	Eval_AUC: 0.8571
Epoch 18 Global_step 1514000	Train_loss: 0.2893	Eval_AUC: 0.8596
Epoch 18 Global_step 1515000	Train_loss: 0.2940	Eval_AUC: 0.8589
Epoch 18 Global_step 1516000	Train_loss: 0.2957	Eval_AUC: 0.8585
Epoch 18 Global_step 1517000	Train_loss: 0.3023	Eval_AUC: 0.8577
Epoch 18 Global_step 1518000	Train_loss: 0.2970	Eval_AUC: 0.8544
Epoch 18 Global_step 1519000	Train_loss: 0.2923	Eval_AUC: 0.8578
Epoch 18 Global_step 1520000	Train_loss: 0.2999	Eval_AUC: 0.8583
Epoch 18 Global_step 1521000	Train_loss: 0.3063	Eval_AUC: 0.8557
Epoch 18 Global_step 1522000	Train_loss: 0.2968	Eval_AUC: 0.8537
Epoch 18 Global_step 1523000	Train_loss: 0.3003	Eval_AUC: 0.8578
Epoch 18 Global_step 1524000	Train_loss: 0.3009	Eval_AUC: 0.8570
Epoch 18 Global_step 1525000	Train_loss: 0.3024	Eval_AUC: 0.8590
Epoch 18 Global_step 1526000	Train_loss: 0.3023	Eval_AUC: 0.8585
Epoch 18 Global_step 1527000	Train_loss: 0.3043	Eval_AUC: 0.8614
Epoch 18 Global_step 1528000	Train_loss: 0.3061	Eval_AUC: 0.8576
Epoch 18 Global_step 1529000	Train_loss: 0.3035	Eval_AUC: 0.8584
Epoch 18 Global_step 1530000	Train_loss: 0.3058	Eval_AUC: 0.8603
Epoch 18 Global_step 1531000	Train_loss: 0.2998	Eval_AUC: 0.8577
Epoch 18 Global_step 1532000	Train_loss: 0.2999	Eval_AUC: 0.8563
Epoch 18 Global_step 1533000	Train_loss: 0.3067	Eval_AUC: 0.8614
Epoch 18 Global_step 1534000	Train_loss: 0.3043	Eval_AUC: 0.8592
Epoch 18 Global_step 1535000	Train_loss: 0.3031	Eval_AUC: 0.8613
Epoch 18 Global_step 1536000	Train_loss: 0.3014	Eval_AUC: 0.8576
Epoch 18 Global_step 1537000	Train_loss: 0.3065	Eval_AUC: 0.8603
Epoch 18 Global_step 1538000	Train_loss: 0.3047	Eval_AUC: 0.8585
Epoch 18 Global_step 1539000	Train_loss: 0.3031	Eval_AUC: 0.8599
Epoch 18 Global_step 1540000	Train_loss: 0.3121	Eval_AUC: 0.8597
Epoch 18 Global_step 1541000	Train_loss: 0.3159	Eval_AUC: 0.8605
Epoch 18 Global_step 1542000	Train_loss: 0.3040	Eval_AUC: 0.8610
Epoch 18 Global_step 1543000	Train_loss: 0.3069	Eval_AUC: 0.8615
Epoch 18 Global_step 1544000	Train_loss: 0.3038	Eval_AUC: 0.8605
Epoch 18 Global_step 1545000	Train_loss: 0.3117	Eval_AUC: 0.8579
Epoch 18 Global_step 1546000	Train_loss: 0.3091	Eval_AUC: 0.8590
Epoch 18 Global_step 1547000	Train_loss: 0.3050	Eval_AUC: 0.8588
Epoch 18 Global_step 1548000	Train_loss: 0.3055	Eval_AUC: 0.8573
Epoch 18 DONE	Cost time: 16930.63
Epoch 19 Global_step 1549000	Train_loss: 0.0112	Eval_AUC: 0.8590
Epoch 19 Global_step 1550000	Train_loss: 0.2670	Eval_AUC: 0.8582
Epoch 19 Global_step 1551000	Train_loss: 0.2654	Eval_AUC: 0.8577
Epoch 19 Global_step 1552000	Train_loss: 0.2571	Eval_AUC: 0.8577
Epoch 19 Global_step 1553000	Train_loss: 0.2602	Eval_AUC: 0.8574
Epoch 19 Global_step 1554000	Train_loss: 0.2617	Eval_AUC: 0.8576
Epoch 19 Global_step 1555000	Train_loss: 0.2643	Eval_AUC: 0.8560
Epoch 19 Global_step 1556000	Train_loss: 0.2607	Eval_AUC: 0.8562
Epoch 19 Global_step 1557000	Train_loss: 0.2645	Eval_AUC: 0.8561
Epoch 19 Global_step 1558000	Train_loss: 0.2664	Eval_AUC: 0.8544
Epoch 19 Global_step 1559000	Train_loss: 0.2638	Eval_AUC: 0.8562
Epoch 19 Global_step 1560000	Train_loss: 0.2727	Eval_AUC: 0.8540
Epoch 19 Global_step 1561000	Train_loss: 0.2654	Eval_AUC: 0.8546
Epoch 19 Global_step 1562000	Train_loss: 0.2621	Eval_AUC: 0.8561
Epoch 19 Global_step 1563000	Train_loss: 0.2706	Eval_AUC: 0.8543
Epoch 19 Global_step 1564000	Train_loss: 0.2695	Eval_AUC: 0.8546
Epoch 19 Global_step 1565000	Train_loss: 0.2721	Eval_AUC: 0.8549
Epoch 19 Global_step 1566000	Train_loss: 0.2710	Eval_AUC: 0.8572
Epoch 19 Global_step 1567000	Train_loss: 0.2734	Eval_AUC: 0.8545
Epoch 19 Global_step 1568000	Train_loss: 0.2718	Eval_AUC: 0.8529
Epoch 19 Global_step 1569000	Train_loss: 0.2732	Eval_AUC: 0.8517
Epoch 19 Global_step 1570000	Train_loss: 0.2766	Eval_AUC: 0.8544
Epoch 19 Global_step 1571000	Train_loss: 0.2780	Eval_AUC: 0.8528
Epoch 19 Global_step 1572000	Train_loss: 0.2791	Eval_AUC: 0.8539
Epoch 19 Global_step 1573000	Train_loss: 0.2756	Eval_AUC: 0.8553
Epoch 19 Global_step 1574000	Train_loss: 0.2782	Eval_AUC: 0.8561
Epoch 19 Global_step 1575000	Train_loss: 0.2762	Eval_AUC: 0.8554
Epoch 19 Global_step 1576000	Train_loss: 0.2784	Eval_AUC: 0.8552
Epoch 19 Global_step 1577000	Train_loss: 0.2779	Eval_AUC: 0.8537
Epoch 19 Global_step 1578000	Train_loss: 0.2774	Eval_AUC: 0.8551
Epoch 19 Global_step 1579000	Train_loss: 0.2783	Eval_AUC: 0.8546
Epoch 19 Global_step 1580000	Train_loss: 0.2862	Eval_AUC: 0.8555
Epoch 19 Global_step 1581000	Train_loss: 0.2796	Eval_AUC: 0.8559
Epoch 19 Global_step 1582000	Train_loss: 0.2818	Eval_AUC: 0.8549
Epoch 19 Global_step 1583000	Train_loss: 0.2809	Eval_AUC: 0.8566
Epoch 19 Global_step 1584000	Train_loss: 0.2907	Eval_AUC: 0.8548
Epoch 19 Global_step 1585000	Train_loss: 0.2871	Eval_AUC: 0.8544
Epoch 19 Global_step 1586000	Train_loss: 0.2870	Eval_AUC: 0.8534
Epoch 19 Global_step 1587000	Train_loss: 0.2850	Eval_AUC: 0.8557
Epoch 19 Global_step 1588000	Train_loss: 0.2824	Eval_AUC: 0.8576
Epoch 19 Global_step 1589000	Train_loss: 0.2791	Eval_AUC: 0.8574
Epoch 19 Global_step 1590000	Train_loss: 0.2883	Eval_AUC: 0.8566
Epoch 19 Global_step 1591000	Train_loss: 0.2954	Eval_AUC: 0.8544
Epoch 19 Global_step 1592000	Train_loss: 0.2862	Eval_AUC: 0.8555
Epoch 19 Global_step 1593000	Train_loss: 0.2867	Eval_AUC: 0.8564
Epoch 19 Global_step 1594000	Train_loss: 0.2894	Eval_AUC: 0.8558
Epoch 19 Global_step 1595000	Train_loss: 0.2865	Eval_AUC: 0.8559
Epoch 19 Global_step 1596000	Train_loss: 0.2909	Eval_AUC: 0.8549
Epoch 19 Global_step 1597000	Train_loss: 0.2863	Eval_AUC: 0.8568
Epoch 19 Global_step 1598000	Train_loss: 0.2910	Eval_AUC: 0.8570
Epoch 19 Global_step 1599000	Train_loss: 0.2899	Eval_AUC: 0.8565
Epoch 19 Global_step 1600000	Train_loss: 0.2882	Eval_AUC: 0.8543
Epoch 19 Global_step 1601000	Train_loss: 0.2896	Eval_AUC: 0.8574
Epoch 19 Global_step 1602000	Train_loss: 0.2888	Eval_AUC: 0.8556
Epoch 19 Global_step 1603000	Train_loss: 0.2926	Eval_AUC: 0.8572
Epoch 19 Global_step 1604000	Train_loss: 0.2928	Eval_AUC: 0.8566
Epoch 19 Global_step 1605000	Train_loss: 0.2965	Eval_AUC: 0.8539
Epoch 19 Global_step 1606000	Train_loss: 0.2937	Eval_AUC: 0.8572
Epoch 19 Global_step 1607000	Train_loss: 0.2916	Eval_AUC: 0.8583
Epoch 19 Global_step 1608000	Train_loss: 0.2943	Eval_AUC: 0.8572
Epoch 19 Global_step 1609000	Train_loss: 0.2970	Eval_AUC: 0.8562
Epoch 19 Global_step 1610000	Train_loss: 0.2936	Eval_AUC: 0.8585
Epoch 19 Global_step 1611000	Train_loss: 0.2942	Eval_AUC: 0.8588
Epoch 19 Global_step 1612000	Train_loss: 0.2947	Eval_AUC: 0.8582
Epoch 19 Global_step 1613000	Train_loss: 0.2984	Eval_AUC: 0.8585
Epoch 19 Global_step 1614000	Train_loss: 0.2972	Eval_AUC: 0.8565
Epoch 19 Global_step 1615000	Train_loss: 0.2952	Eval_AUC: 0.8559
Epoch 19 Global_step 1616000	Train_loss: 0.2929	Eval_AUC: 0.8558
Epoch 19 Global_step 1617000	Train_loss: 0.2992	Eval_AUC: 0.8577
Epoch 19 Global_step 1618000	Train_loss: 0.2975	Eval_AUC: 0.8579
Epoch 19 Global_step 1619000	Train_loss: 0.2988	Eval_AUC: 0.8584
Epoch 19 Global_step 1620000	Train_loss: 0.3008	Eval_AUC: 0.8592
Epoch 19 Global_step 1621000	Train_loss: 0.3022	Eval_AUC: 0.8579
Epoch 19 Global_step 1622000	Train_loss: 0.2996	Eval_AUC: 0.8582
Epoch 19 Global_step 1623000	Train_loss: 0.2996	Eval_AUC: 0.8591
Epoch 19 Global_step 1624000	Train_loss: 0.2959	Eval_AUC: 0.8565
Epoch 19 Global_step 1625000	Train_loss: 0.2973	Eval_AUC: 0.8559
Epoch 19 Global_step 1626000	Train_loss: 0.2993	Eval_AUC: 0.8556
Epoch 19 Global_step 1627000	Train_loss: 0.3026	Eval_AUC: 0.8603
Epoch 19 Global_step 1628000	Train_loss: 0.2998	Eval_AUC: 0.8579
Epoch 19 Global_step 1629000	Train_loss: 0.2984	Eval_AUC: 0.8592
Epoch 19 Global_step 1630000	Train_loss: 0.3049	Eval_AUC: 0.8571
Epoch 19 DONE	Cost time: 17762.43
Epoch 20 Global_step 1631000	Train_loss: 0.1292	Eval_AUC: 0.8582
Epoch 20 Global_step 1632000	Train_loss: 0.2527	Eval_AUC: 0.8592
Epoch 20 Global_step 1633000	Train_loss: 0.2519	Eval_AUC: 0.8579
Epoch 20 Global_step 1634000	Train_loss: 0.2510	Eval_AUC: 0.8552
Epoch 20 Global_step 1635000	Train_loss: 0.2504	Eval_AUC: 0.8553
Epoch 20 Global_step 1636000	Train_loss: 0.2613	Eval_AUC: 0.8545
Epoch 20 Global_step 1637000	Train_loss: 0.2517	Eval_AUC: 0.8517
Epoch 20 Global_step 1638000	Train_loss: 0.2540	Eval_AUC: 0.8553
Epoch 20 Global_step 1639000	Train_loss: 0.2605	Eval_AUC: 0.8529
Epoch 20 Global_step 1640000	Train_loss: 0.2619	Eval_AUC: 0.8535
Epoch 20 Global_step 1641000	Train_loss: 0.2599	Eval_AUC: 0.8533
Epoch 20 Global_step 1642000	Train_loss: 0.2600	Eval_AUC: 0.8514
Epoch 20 Global_step 1643000	Train_loss: 0.2625	Eval_AUC: 0.8535
Epoch 20 Global_step 1644000	Train_loss: 0.2612	Eval_AUC: 0.8532
Epoch 20 Global_step 1645000	Train_loss: 0.2639	Eval_AUC: 0.8539
Epoch 20 Global_step 1646000	Train_loss: 0.2577	Eval_AUC: 0.8539
Epoch 20 Global_step 1647000	Train_loss: 0.2674	Eval_AUC: 0.8544
Epoch 20 Global_step 1648000	Train_loss: 0.2596	Eval_AUC: 0.8531
Epoch 20 Global_step 1649000	Train_loss: 0.2627	Eval_AUC: 0.8517
Epoch 20 Global_step 1650000	Train_loss: 0.2639	Eval_AUC: 0.8552
Epoch 20 Global_step 1651000	Train_loss: 0.2677	Eval_AUC: 0.8529
Epoch 20 Global_step 1652000	Train_loss: 0.2705	Eval_AUC: 0.8539
Epoch 20 Global_step 1653000	Train_loss: 0.2693	Eval_AUC: 0.8548
Epoch 20 Global_step 1654000	Train_loss: 0.2720	Eval_AUC: 0.8515
Epoch 20 Global_step 1655000	Train_loss: 0.2701	Eval_AUC: 0.8543
Epoch 20 Global_step 1656000	Train_loss: 0.2712	Eval_AUC: 0.8538
Epoch 20 Global_step 1657000	Train_loss: 0.2696	Eval_AUC: 0.8519
Epoch 20 Global_step 1658000	Train_loss: 0.2747	Eval_AUC: 0.8517
Epoch 20 Global_step 1659000	Train_loss: 0.2736	Eval_AUC: 0.8541
Epoch 20 Global_step 1660000	Train_loss: 0.2708	Eval_AUC: 0.8525
Epoch 20 Global_step 1661000	Train_loss: 0.2712	Eval_AUC: 0.8538
Epoch 20 Global_step 1662000	Train_loss: 0.2763	Eval_AUC: 0.8554
Epoch 20 Global_step 1663000	Train_loss: 0.2731	Eval_AUC: 0.8538
Epoch 20 Global_step 1664000	Train_loss: 0.2734	Eval_AUC: 0.8534
Epoch 20 Global_step 1665000	Train_loss: 0.2728	Eval_AUC: 0.8564
Epoch 20 Global_step 1666000	Train_loss: 0.2732	Eval_AUC: 0.8543
Epoch 20 Global_step 1667000	Train_loss: 0.2818	Eval_AUC: 0.8534
Epoch 20 Global_step 1668000	Train_loss: 0.2752	Eval_AUC: 0.8543
Epoch 20 Global_step 1669000	Train_loss: 0.2793	Eval_AUC: 0.8543
Epoch 20 Global_step 1670000	Train_loss: 0.2746	Eval_AUC: 0.8531
Epoch 20 Global_step 1671000	Train_loss: 0.2824	Eval_AUC: 0.8525
Epoch 20 Global_step 1672000	Train_loss: 0.2895	Eval_AUC: 0.8567
Epoch 20 Global_step 1673000	Train_loss: 0.2815	Eval_AUC: 0.8540
Epoch 20 Global_step 1674000	Train_loss: 0.2749	Eval_AUC: 0.8544
Epoch 20 Global_step 1675000	Train_loss: 0.2765	Eval_AUC: 0.8559
Epoch 20 Global_step 1676000	Train_loss: 0.2819	Eval_AUC: 0.8562
Epoch 20 Global_step 1677000	Train_loss: 0.2858	Eval_AUC: 0.8566
Epoch 20 Global_step 1678000	Train_loss: 0.2820	Eval_AUC: 0.8552
Epoch 20 Global_step 1679000	Train_loss: 0.2884	Eval_AUC: 0.8535
Epoch 20 Global_step 1680000	Train_loss: 0.2833	Eval_AUC: 0.8543
Epoch 20 Global_step 1681000	Train_loss: 0.2854	Eval_AUC: 0.8564
Epoch 20 Global_step 1682000	Train_loss: 0.2849	Eval_AUC: 0.8535
Epoch 20 Global_step 1683000	Train_loss: 0.2876	Eval_AUC: 0.8556
Epoch 20 Global_step 1684000	Train_loss: 0.2839	Eval_AUC: 0.8530
Epoch 20 Global_step 1685000	Train_loss: 0.2782	Eval_AUC: 0.8540
Epoch 20 Global_step 1686000	Train_loss: 0.2849	Eval_AUC: 0.8554
Epoch 20 Global_step 1687000	Train_loss: 0.2873	Eval_AUC: 0.8557
Epoch 20 Global_step 1688000	Train_loss: 0.2859	Eval_AUC: 0.8546
Epoch 20 Global_step 1689000	Train_loss: 0.2862	Eval_AUC: 0.8551
Epoch 20 Global_step 1690000	Train_loss: 0.2873	Eval_AUC: 0.8526
Epoch 20 Global_step 1691000	Train_loss: 0.2893	Eval_AUC: 0.8522
Epoch 20 Global_step 1692000	Train_loss: 0.2902	Eval_AUC: 0.8534
Epoch 20 Global_step 1693000	Train_loss: 0.2858	Eval_AUC: 0.8566
Epoch 20 Global_step 1694000	Train_loss: 0.2873	Eval_AUC: 0.8546
Epoch 20 Global_step 1695000	Train_loss: 0.2856	Eval_AUC: 0.8551
Epoch 20 Global_step 1696000	Train_loss: 0.2859	Eval_AUC: 0.8555
Epoch 20 Global_step 1697000	Train_loss: 0.2931	Eval_AUC: 0.8553
Epoch 20 Global_step 1698000	Train_loss: 0.2945	Eval_AUC: 0.8577
Epoch 20 Global_step 1699000	Train_loss: 0.2974	Eval_AUC: 0.8555
Epoch 20 Global_step 1700000	Train_loss: 0.2873	Eval_AUC: 0.8566
Epoch 20 Global_step 1701000	Train_loss: 0.2916	Eval_AUC: 0.8575
Epoch 20 Global_step 1702000	Train_loss: 0.2962	Eval_AUC: 0.8570
Epoch 20 Global_step 1703000	Train_loss: 0.2874	Eval_AUC: 0.8571
Epoch 20 Global_step 1704000	Train_loss: 0.2955	Eval_AUC: 0.8551
Epoch 20 Global_step 1705000	Train_loss: 0.2898	Eval_AUC: 0.8582
Epoch 20 Global_step 1706000	Train_loss: 0.2913	Eval_AUC: 0.8567
Epoch 20 Global_step 1707000	Train_loss: 0.2866	Eval_AUC: 0.8563
Epoch 20 Global_step 1708000	Train_loss: 0.2914	Eval_AUC: 0.8562
Epoch 20 Global_step 1709000	Train_loss: 0.2991	Eval_AUC: 0.8552
Epoch 20 Global_step 1710000	Train_loss: 0.2875	Eval_AUC: 0.8566
Epoch 20 Global_step 1711000	Train_loss: 0.2938	Eval_AUC: 0.8549
Epoch 20 Global_step 1712000	Train_loss: 0.2920	Eval_AUC: 0.8576
Epoch 20 DONE	Cost time: 18611.03
Epoch 21 Global_step 1713000	Train_loss: 0.2462	Eval_AUC: 0.8550
Epoch 21 Global_step 1714000	Train_loss: 0.2478	Eval_AUC: 0.8555
Epoch 21 Global_step 1715000	Train_loss: 0.2422	Eval_AUC: 0.8533
Epoch 21 Global_step 1716000	Train_loss: 0.2444	Eval_AUC: 0.8560
Epoch 21 Global_step 1717000	Train_loss: 0.2394	Eval_AUC: 0.8552
Epoch 21 Global_step 1718000	Train_loss: 0.2505	Eval_AUC: 0.8542
Epoch 21 Global_step 1719000	Train_loss: 0.2472	Eval_AUC: 0.8534
Epoch 21 Global_step 1720000	Train_loss: 0.2513	Eval_AUC: 0.8499
Epoch 21 Global_step 1721000	Train_loss: 0.2443	Eval_AUC: 0.8532
Epoch 21 Global_step 1722000	Train_loss: 0.2479	Eval_AUC: 0.8506
Epoch 21 Global_step 1723000	Train_loss: 0.2498	Eval_AUC: 0.8518
Epoch 21 Global_step 1724000	Train_loss: 0.2479	Eval_AUC: 0.8511
Epoch 21 Global_step 1725000	Train_loss: 0.2496	Eval_AUC: 0.8540
Epoch 21 Global_step 1726000	Train_loss: 0.2563	Eval_AUC: 0.8528
Epoch 21 Global_step 1727000	Train_loss: 0.2556	Eval_AUC: 0.8532
Epoch 21 Global_step 1728000	Train_loss: 0.2563	Eval_AUC: 0.8524
Epoch 21 Global_step 1729000	Train_loss: 0.2548	Eval_AUC: 0.8532
Epoch 21 Global_step 1730000	Train_loss: 0.2576	Eval_AUC: 0.8523
Epoch 21 Global_step 1731000	Train_loss: 0.2597	Eval_AUC: 0.8518
Epoch 21 Global_step 1732000	Train_loss: 0.2552	Eval_AUC: 0.8546
Epoch 21 Global_step 1733000	Train_loss: 0.2592	Eval_AUC: 0.8511
Epoch 21 Global_step 1734000	Train_loss: 0.2649	Eval_AUC: 0.8531
Epoch 21 Global_step 1735000	Train_loss: 0.2587	Eval_AUC: 0.8511
Epoch 21 Global_step 1736000	Train_loss: 0.2557	Eval_AUC: 0.8526
Epoch 21 Global_step 1737000	Train_loss: 0.2608	Eval_AUC: 0.8520
Epoch 21 Global_step 1738000	Train_loss: 0.2607	Eval_AUC: 0.8520
Epoch 21 Global_step 1739000	Train_loss: 0.2672	Eval_AUC: 0.8518
Epoch 21 Global_step 1740000	Train_loss: 0.2653	Eval_AUC: 0.8529
Epoch 21 Global_step 1741000	Train_loss: 0.2705	Eval_AUC: 0.8513
Epoch 21 Global_step 1742000	Train_loss: 0.2607	Eval_AUC: 0.8530
Epoch 21 Global_step 1743000	Train_loss: 0.2645	Eval_AUC: 0.8526
Epoch 21 Global_step 1744000	Train_loss: 0.2669	Eval_AUC: 0.8510
Epoch 21 Global_step 1745000	Train_loss: 0.2651	Eval_AUC: 0.8536
Epoch 21 Global_step 1746000	Train_loss: 0.2638	Eval_AUC: 0.8534
Epoch 21 Global_step 1747000	Train_loss: 0.2702	Eval_AUC: 0.8520
Epoch 21 Global_step 1748000	Train_loss: 0.2705	Eval_AUC: 0.8538
Epoch 21 Global_step 1749000	Train_loss: 0.2692	Eval_AUC: 0.8513
Epoch 21 Global_step 1750000	Train_loss: 0.2699	Eval_AUC: 0.8542
Epoch 21 Global_step 1751000	Train_loss: 0.2703	Eval_AUC: 0.8501
Epoch 21 Global_step 1752000	Train_loss: 0.2693	Eval_AUC: 0.8518
Epoch 21 Global_step 1753000	Train_loss: 0.2728	Eval_AUC: 0.8519
Epoch 21 Global_step 1754000	Train_loss: 0.2701	Eval_AUC: 0.8507
Epoch 21 Global_step 1755000	Train_loss: 0.2725	Eval_AUC: 0.8521
Epoch 21 Global_step 1756000	Train_loss: 0.2799	Eval_AUC: 0.8512
Epoch 21 Global_step 1757000	Train_loss: 0.2761	Eval_AUC: 0.8534
Epoch 21 Global_step 1758000	Train_loss: 0.2768	Eval_AUC: 0.8517
Epoch 21 Global_step 1759000	Train_loss: 0.2717	Eval_AUC: 0.8514
Epoch 21 Global_step 1760000	Train_loss: 0.2748	Eval_AUC: 0.8523
Epoch 21 Global_step 1761000	Train_loss: 0.2766	Eval_AUC: 0.8514
Epoch 21 Global_step 1762000	Train_loss: 0.2761	Eval_AUC: 0.8532
Epoch 21 Global_step 1763000	Train_loss: 0.2852	Eval_AUC: 0.8539
Epoch 21 Global_step 1764000	Train_loss: 0.2778	Eval_AUC: 0.8517
Epoch 21 Global_step 1765000	Train_loss: 0.2800	Eval_AUC: 0.8523
Epoch 21 Global_step 1766000	Train_loss: 0.2822	Eval_AUC: 0.8541
Epoch 21 Global_step 1767000	Train_loss: 0.2792	Eval_AUC: 0.8522
Epoch 21 Global_step 1768000	Train_loss: 0.2800	Eval_AUC: 0.8545
Epoch 21 Global_step 1769000	Train_loss: 0.2857	Eval_AUC: 0.8546
Epoch 21 Global_step 1770000	Train_loss: 0.2807	Eval_AUC: 0.8530
Epoch 21 Global_step 1771000	Train_loss: 0.2758	Eval_AUC: 0.8553
Epoch 21 Global_step 1772000	Train_loss: 0.2814	Eval_AUC: 0.8526
Epoch 21 Global_step 1773000	Train_loss: 0.2843	Eval_AUC: 0.8537
Epoch 21 Global_step 1774000	Train_loss: 0.2826	Eval_AUC: 0.8548
Epoch 21 Global_step 1775000	Train_loss: 0.2816	Eval_AUC: 0.8535
Epoch 21 Global_step 1776000	Train_loss: 0.2836	Eval_AUC: 0.8524
Epoch 21 Global_step 1777000	Train_loss: 0.2854	Eval_AUC: 0.8536
Epoch 21 Global_step 1778000	Train_loss: 0.2838	Eval_AUC: 0.8537
Epoch 21 Global_step 1779000	Train_loss: 0.2786	Eval_AUC: 0.8539
Epoch 21 Global_step 1780000	Train_loss: 0.2863	Eval_AUC: 0.8509
Epoch 21 Global_step 1781000	Train_loss: 0.2843	Eval_AUC: 0.8536
Epoch 21 Global_step 1782000	Train_loss: 0.2833	Eval_AUC: 0.8534
Epoch 21 Global_step 1783000	Train_loss: 0.2865	Eval_AUC: 0.8538
Epoch 21 Global_step 1784000	Train_loss: 0.2837	Eval_AUC: 0.8550
Epoch 21 Global_step 1785000	Train_loss: 0.2827	Eval_AUC: 0.8544
Epoch 21 Global_step 1786000	Train_loss: 0.2891	Eval_AUC: 0.8520
Epoch 21 Global_step 1787000	Train_loss: 0.2896	Eval_AUC: 0.8550
Epoch 21 Global_step 1788000	Train_loss: 0.2900	Eval_AUC: 0.8538
Epoch 21 Global_step 1789000	Train_loss: 0.2822	Eval_AUC: 0.8514
Epoch 21 Global_step 1790000	Train_loss: 0.2920	Eval_AUC: 0.8548
Epoch 21 Global_step 1791000	Train_loss: 0.2863	Eval_AUC: 0.8572
Epoch 21 Global_step 1792000	Train_loss: 0.2857	Eval_AUC: 0.8530
Epoch 21 Global_step 1793000	Train_loss: 0.2872	Eval_AUC: 0.8555
Epoch 21 DONE	Cost time: 19436.41
Epoch 22 Global_step 1794000	Train_loss: 0.1094	Eval_AUC: 0.8550
Epoch 22 Global_step 1795000	Train_loss: 0.2359	Eval_AUC: 0.8546
Epoch 22 Global_step 1796000	Train_loss: 0.2367	Eval_AUC: 0.8536
Epoch 22 Global_step 1797000	Train_loss: 0.2413	Eval_AUC: 0.8524
Epoch 22 Global_step 1798000	Train_loss: 0.2376	Eval_AUC: 0.8514
Epoch 22 Global_step 1799000	Train_loss: 0.2403	Eval_AUC: 0.8530
Epoch 22 Global_step 1800000	Train_loss: 0.2430	Eval_AUC: 0.8514
Epoch 22 Global_step 1801000	Train_loss: 0.2425	Eval_AUC: 0.8529
Epoch 22 Global_step 1802000	Train_loss: 0.2423	Eval_AUC: 0.8511
Epoch 22 Global_step 1803000	Train_loss: 0.2510	Eval_AUC: 0.8517
Epoch 22 Global_step 1804000	Train_loss: 0.2378	Eval_AUC: 0.8511
Epoch 22 Global_step 1805000	Train_loss: 0.2427	Eval_AUC: 0.8504
Epoch 22 Global_step 1806000	Train_loss: 0.2502	Eval_AUC: 0.8510
Epoch 22 Global_step 1807000	Train_loss: 0.2460	Eval_AUC: 0.8500
Epoch 22 Global_step 1808000	Train_loss: 0.2464	Eval_AUC: 0.8508
Epoch 22 Global_step 1809000	Train_loss: 0.2515	Eval_AUC: 0.8503
Epoch 22 Global_step 1810000	Train_loss: 0.2498	Eval_AUC: 0.8493
Epoch 22 Global_step 1811000	Train_loss: 0.2540	Eval_AUC: 0.8513
Epoch 22 Global_step 1812000	Train_loss: 0.2503	Eval_AUC: 0.8502
Epoch 22 Global_step 1813000	Train_loss: 0.2547	Eval_AUC: 0.8493
Epoch 22 Global_step 1814000	Train_loss: 0.2489	Eval_AUC: 0.8520
Epoch 22 Global_step 1815000	Train_loss: 0.2558	Eval_AUC: 0.8496
Epoch 22 Global_step 1816000	Train_loss: 0.2501	Eval_AUC: 0.8495
Epoch 22 Global_step 1817000	Train_loss: 0.2553	Eval_AUC: 0.8511
Epoch 22 Global_step 1818000	Train_loss: 0.2542	Eval_AUC: 0.8494
Epoch 22 Global_step 1819000	Train_loss: 0.2527	Eval_AUC: 0.8512
Epoch 22 Global_step 1820000	Train_loss: 0.2590	Eval_AUC: 0.8532
Epoch 22 Global_step 1821000	Train_loss: 0.2577	Eval_AUC: 0.8497
Epoch 22 Global_step 1822000	Train_loss: 0.2554	Eval_AUC: 0.8518
Epoch 22 Global_step 1823000	Train_loss: 0.2613	Eval_AUC: 0.8489
Epoch 22 Global_step 1824000	Train_loss: 0.2549	Eval_AUC: 0.8520
Epoch 22 Global_step 1825000	Train_loss: 0.2683	Eval_AUC: 0.8484
Epoch 22 Global_step 1826000	Train_loss: 0.2551	Eval_AUC: 0.8514
Epoch 22 Global_step 1827000	Train_loss: 0.2577	Eval_AUC: 0.8507
Epoch 22 Global_step 1828000	Train_loss: 0.2606	Eval_AUC: 0.8501
Epoch 22 Global_step 1829000	Train_loss: 0.2631	Eval_AUC: 0.8509
Epoch 22 Global_step 1830000	Train_loss: 0.2600	Eval_AUC: 0.8531
Epoch 22 Global_step 1831000	Train_loss: 0.2637	Eval_AUC: 0.8506
Epoch 22 Global_step 1832000	Train_loss: 0.2687	Eval_AUC: 0.8494
Epoch 22 Global_step 1833000	Train_loss: 0.2707	Eval_AUC: 0.8518
Epoch 22 Global_step 1834000	Train_loss: 0.2664	Eval_AUC: 0.8515
Epoch 22 Global_step 1835000	Train_loss: 0.2720	Eval_AUC: 0.8498
Epoch 22 Global_step 1836000	Train_loss: 0.2650	Eval_AUC: 0.8490
Epoch 22 Global_step 1837000	Train_loss: 0.2695	Eval_AUC: 0.8523
Epoch 22 Global_step 1838000	Train_loss: 0.2646	Eval_AUC: 0.8526
Epoch 22 Global_step 1839000	Train_loss: 0.2709	Eval_AUC: 0.8516
Epoch 22 Global_step 1840000	Train_loss: 0.2704	Eval_AUC: 0.8495
Epoch 22 Global_step 1841000	Train_loss: 0.2648	Eval_AUC: 0.8521
Epoch 22 Global_step 1842000	Train_loss: 0.2685	Eval_AUC: 0.8475
Epoch 22 Global_step 1843000	Train_loss: 0.2664	Eval_AUC: 0.8526
Epoch 22 Global_step 1844000	Train_loss: 0.2679	Eval_AUC: 0.8520
Epoch 22 Global_step 1845000	Train_loss: 0.2714	Eval_AUC: 0.8515
Epoch 22 Global_step 1846000	Train_loss: 0.2714	Eval_AUC: 0.8521
Epoch 22 Global_step 1847000	Train_loss: 0.2720	Eval_AUC: 0.8523
Epoch 22 Global_step 1848000	Train_loss: 0.2737	Eval_AUC: 0.8508
Epoch 22 Global_step 1849000	Train_loss: 0.2676	Eval_AUC: 0.8506
Epoch 22 Global_step 1850000	Train_loss: 0.2749	Eval_AUC: 0.8521
Epoch 22 Global_step 1851000	Train_loss: 0.2763	Eval_AUC: 0.8509
Epoch 22 Global_step 1852000	Train_loss: 0.2741	Eval_AUC: 0.8499
Epoch 22 Global_step 1853000	Train_loss: 0.2753	Eval_AUC: 0.8544
Epoch 22 Global_step 1854000	Train_loss: 0.2733	Eval_AUC: 0.8554
Epoch 22 Global_step 1855000	Train_loss: 0.2751	Eval_AUC: 0.8535
Epoch 22 Global_step 1856000	Train_loss: 0.2731	Eval_AUC: 0.8513
Epoch 22 Global_step 1857000	Train_loss: 0.2753	Eval_AUC: 0.8513
Epoch 22 Global_step 1858000	Train_loss: 0.2732	Eval_AUC: 0.8528
Epoch 22 Global_step 1859000	Train_loss: 0.2768	Eval_AUC: 0.8517
Epoch 22 Global_step 1860000	Train_loss: 0.2807	Eval_AUC: 0.8530
Epoch 22 Global_step 1861000	Train_loss: 0.2802	Eval_AUC: 0.8482
Epoch 22 Global_step 1862000	Train_loss: 0.2842	Eval_AUC: 0.8536
Epoch 22 Global_step 1863000	Train_loss: 0.2771	Eval_AUC: 0.8546
Epoch 22 Global_step 1864000	Train_loss: 0.2781	Eval_AUC: 0.8533
Epoch 22 Global_step 1865000	Train_loss: 0.2773	Eval_AUC: 0.8548
Epoch 22 Global_step 1866000	Train_loss: 0.2770	Eval_AUC: 0.8526
Epoch 22 Global_step 1867000	Train_loss: 0.2803	Eval_AUC: 0.8528
Epoch 22 Global_step 1868000	Train_loss: 0.2759	Eval_AUC: 0.8532
Epoch 22 Global_step 1869000	Train_loss: 0.2802	Eval_AUC: 0.8523
Epoch 22 Global_step 1870000	Train_loss: 0.2725	Eval_AUC: 0.8524
Epoch 22 Global_step 1871000	Train_loss: 0.2832	Eval_AUC: 0.8539
Epoch 22 Global_step 1872000	Train_loss: 0.2802	Eval_AUC: 0.8555
Epoch 22 Global_step 1873000	Train_loss: 0.2808	Eval_AUC: 0.8510
Epoch 22 Global_step 1874000	Train_loss: 0.2801	Eval_AUC: 0.8516
Epoch 22 Global_step 1875000	Train_loss: 0.2862	Eval_AUC: 0.8516
Epoch 22 DONE	Cost time: 20263.01
Epoch 23 Global_step 1876000	Train_loss: 0.2261	Eval_AUC: 0.8527
Epoch 23 Global_step 1877000	Train_loss: 0.2330	Eval_AUC: 0.8516
Epoch 23 Global_step 1878000	Train_loss: 0.2288	Eval_AUC: 0.8532
Epoch 23 Global_step 1879000	Train_loss: 0.2314	Eval_AUC: 0.8503
Epoch 23 Global_step 1880000	Train_loss: 0.2303	Eval_AUC: 0.8507
Epoch 23 Global_step 1881000	Train_loss: 0.2328	Eval_AUC: 0.8507
Epoch 23 Global_step 1882000	Train_loss: 0.2373	Eval_AUC: 0.8498
Epoch 23 Global_step 1883000	Train_loss: 0.2351	Eval_AUC: 0.8467
Epoch 23 Global_step 1884000	Train_loss: 0.2386	Eval_AUC: 0.8486
Epoch 23 Global_step 1885000	Train_loss: 0.2379	Eval_AUC: 0.8490
Epoch 23 Global_step 1886000	Train_loss: 0.2403	Eval_AUC: 0.8468
Epoch 23 Global_step 1887000	Train_loss: 0.2378	Eval_AUC: 0.8510
Epoch 23 Global_step 1888000	Train_loss: 0.2375	Eval_AUC: 0.8484
Epoch 23 Global_step 1889000	Train_loss: 0.2402	Eval_AUC: 0.8477
Epoch 23 Global_step 1890000	Train_loss: 0.2419	Eval_AUC: 0.8490
Epoch 23 Global_step 1891000	Train_loss: 0.2421	Eval_AUC: 0.8491
Epoch 23 Global_step 1892000	Train_loss: 0.2419	Eval_AUC: 0.8478
Epoch 23 Global_step 1893000	Train_loss: 0.2490	Eval_AUC: 0.8467
Epoch 23 Global_step 1894000	Train_loss: 0.2455	Eval_AUC: 0.8482
Epoch 23 Global_step 1895000	Train_loss: 0.2461	Eval_AUC: 0.8503
Epoch 23 Global_step 1896000	Train_loss: 0.2456	Eval_AUC: 0.8496
Epoch 23 Global_step 1897000	Train_loss: 0.2421	Eval_AUC: 0.8488
Epoch 23 Global_step 1898000	Train_loss: 0.2522	Eval_AUC: 0.8501
Epoch 23 Global_step 1899000	Train_loss: 0.2481	Eval_AUC: 0.8498
Epoch 23 Global_step 1900000	Train_loss: 0.2485	Eval_AUC: 0.8489
Epoch 23 Global_step 1901000	Train_loss: 0.2482	Eval_AUC: 0.8489
Epoch 23 Global_step 1902000	Train_loss: 0.2499	Eval_AUC: 0.8482
Epoch 23 Global_step 1903000	Train_loss: 0.2517	Eval_AUC: 0.8507
Epoch 23 Global_step 1904000	Train_loss: 0.2525	Eval_AUC: 0.8486
Epoch 23 Global_step 1905000	Train_loss: 0.2524	Eval_AUC: 0.8504
Epoch 23 Global_step 1906000	Train_loss: 0.2549	Eval_AUC: 0.8498
Epoch 23 Global_step 1907000	Train_loss: 0.2562	Eval_AUC: 0.8486
Epoch 23 Global_step 1908000	Train_loss: 0.2556	Eval_AUC: 0.8513
Epoch 23 Global_step 1909000	Train_loss: 0.2574	Eval_AUC: 0.8481
Epoch 23 Global_step 1910000	Train_loss: 0.2560	Eval_AUC: 0.8465
Epoch 23 Global_step 1911000	Train_loss: 0.2592	Eval_AUC: 0.8497
Epoch 23 Global_step 1912000	Train_loss: 0.2536	Eval_AUC: 0.8496
Epoch 23 Global_step 1913000	Train_loss: 0.2583	Eval_AUC: 0.8502
Epoch 23 Global_step 1914000	Train_loss: 0.2593	Eval_AUC: 0.8505
Epoch 23 Global_step 1915000	Train_loss: 0.2577	Eval_AUC: 0.8498
Epoch 23 Global_step 1916000	Train_loss: 0.2583	Eval_AUC: 0.8495
Epoch 23 Global_step 1917000	Train_loss: 0.2606	Eval_AUC: 0.8511
Epoch 23 Global_step 1918000	Train_loss: 0.2656	Eval_AUC: 0.8505
Epoch 23 Global_step 1919000	Train_loss: 0.2543	Eval_AUC: 0.8485
Epoch 23 Global_step 1920000	Train_loss: 0.2588	Eval_AUC: 0.8515
Epoch 23 Global_step 1921000	Train_loss: 0.2577	Eval_AUC: 0.8506
Epoch 23 Global_step 1922000	Train_loss: 0.2620	Eval_AUC: 0.8489
Epoch 23 Global_step 1923000	Train_loss: 0.2631	Eval_AUC: 0.8509
Epoch 23 Global_step 1924000	Train_loss: 0.2652	Eval_AUC: 0.8502
Epoch 23 Global_step 1925000	Train_loss: 0.2662	Eval_AUC: 0.8497
Epoch 23 Global_step 1926000	Train_loss: 0.2602	Eval_AUC: 0.8514
Epoch 23 Global_step 1927000	Train_loss: 0.2676	Eval_AUC: 0.8494
Epoch 23 Global_step 1928000	Train_loss: 0.2713	Eval_AUC: 0.8478
Epoch 23 Global_step 1929000	Train_loss: 0.2631	Eval_AUC: 0.8518
Epoch 23 Global_step 1930000	Train_loss: 0.2635	Eval_AUC: 0.8514
Epoch 23 Global_step 1931000	Train_loss: 0.2686	Eval_AUC: 0.8481
Epoch 23 Global_step 1932000	Train_loss: 0.2623	Eval_AUC: 0.8509
Epoch 23 Global_step 1933000	Train_loss: 0.2667	Eval_AUC: 0.8500
Epoch 23 Global_step 1934000	Train_loss: 0.2719	Eval_AUC: 0.8508
Epoch 23 Global_step 1935000	Train_loss: 0.2669	Eval_AUC: 0.8502
Epoch 23 Global_step 1936000	Train_loss: 0.2716	Eval_AUC: 0.8501
Epoch 23 Global_step 1937000	Train_loss: 0.2657	Eval_AUC: 0.8493
Epoch 23 Global_step 1938000	Train_loss: 0.2701	Eval_AUC: 0.8489
Epoch 23 Global_step 1939000	Train_loss: 0.2700	Eval_AUC: 0.8509
Epoch 23 Global_step 1940000	Train_loss: 0.2677	Eval_AUC: 0.8514
Epoch 23 Global_step 1941000	Train_loss: 0.2663	Eval_AUC: 0.8525
Epoch 23 Global_step 1942000	Train_loss: 0.2694	Eval_AUC: 0.8491
Epoch 23 Global_step 1943000	Train_loss: 0.2737	Eval_AUC: 0.8519
Epoch 23 Global_step 1944000	Train_loss: 0.2671	Eval_AUC: 0.8493
Epoch 23 Global_step 1945000	Train_loss: 0.2654	Eval_AUC: 0.8522
Epoch 23 Global_step 1946000	Train_loss: 0.2718	Eval_AUC: 0.8515
Epoch 23 Global_step 1947000	Train_loss: 0.2714	Eval_AUC: 0.8515
Epoch 23 Global_step 1948000	Train_loss: 0.2727	Eval_AUC: 0.8525
Epoch 23 Global_step 1949000	Train_loss: 0.2735	Eval_AUC: 0.8502
Epoch 23 Global_step 1950000	Train_loss: 0.2661	Eval_AUC: 0.8514
Epoch 23 Global_step 1951000	Train_loss: 0.2737	Eval_AUC: 0.8535
Epoch 23 Global_step 1952000	Train_loss: 0.2703	Eval_AUC: 0.8528
Epoch 23 Global_step 1953000	Train_loss: 0.2766	Eval_AUC: 0.8493
Epoch 23 Global_step 1954000	Train_loss: 0.2711	Eval_AUC: 0.8517
Epoch 23 Global_step 1955000	Train_loss: 0.2658	Eval_AUC: 0.8504
Epoch 23 Global_step 1956000	Train_loss: 0.2750	Eval_AUC: 0.8498
Epoch 23 DONE	Cost time: 21092.36
Epoch 24 Global_step 1957000	Train_loss: 0.0971	Eval_AUC: 0.8498
Epoch 24 Global_step 1958000	Train_loss: 0.2200	Eval_AUC: 0.8498
Epoch 24 Global_step 1959000	Train_loss: 0.2296	Eval_AUC: 0.8491
Epoch 24 Global_step 1960000	Train_loss: 0.2254	Eval_AUC: 0.8481
Epoch 24 Global_step 1961000	Train_loss: 0.2277	Eval_AUC: 0.8482
Epoch 24 Global_step 1962000	Train_loss: 0.2288	Eval_AUC: 0.8499
Epoch 24 Global_step 1963000	Train_loss: 0.2312	Eval_AUC: 0.8490
Epoch 24 Global_step 1964000	Train_loss: 0.2311	Eval_AUC: 0.8497
Epoch 24 Global_step 1965000	Train_loss: 0.2256	Eval_AUC: 0.8480
Epoch 24 Global_step 1966000	Train_loss: 0.2336	Eval_AUC: 0.8481
Epoch 24 Global_step 1967000	Train_loss: 0.2316	Eval_AUC: 0.8480
Epoch 24 Global_step 1968000	Train_loss: 0.2319	Eval_AUC: 0.8505
Epoch 24 Global_step 1969000	Train_loss: 0.2320	Eval_AUC: 0.8479
Epoch 24 Global_step 1970000	Train_loss: 0.2302	Eval_AUC: 0.8475
Epoch 24 Global_step 1971000	Train_loss: 0.2351	Eval_AUC: 0.8478
Epoch 24 Global_step 1972000	Train_loss: 0.2352	Eval_AUC: 0.8495
Epoch 24 Global_step 1973000	Train_loss: 0.2335	Eval_AUC: 0.8479
Epoch 24 Global_step 1974000	Train_loss: 0.2407	Eval_AUC: 0.8501
Epoch 24 Global_step 1975000	Train_loss: 0.2389	Eval_AUC: 0.8461
Epoch 24 Global_step 1976000	Train_loss: 0.2398	Eval_AUC: 0.8491
Epoch 24 Global_step 1977000	Train_loss: 0.2450	Eval_AUC: 0.8495
Epoch 24 Global_step 1978000	Train_loss: 0.2373	Eval_AUC: 0.8477
Epoch 24 Global_step 1979000	Train_loss: 0.2414	Eval_AUC: 0.8468
Epoch 24 Global_step 1980000	Train_loss: 0.2428	Eval_AUC: 0.8481
Epoch 24 Global_step 1981000	Train_loss: 0.2439	Eval_AUC: 0.8484
Epoch 24 Global_step 1982000	Train_loss: 0.2461	Eval_AUC: 0.8474
Epoch 24 Global_step 1983000	Train_loss: 0.2407	Eval_AUC: 0.8477
Epoch 24 Global_step 1984000	Train_loss: 0.2431	Eval_AUC: 0.8516
Epoch 24 Global_step 1985000	Train_loss: 0.2425	Eval_AUC: 0.8491
Epoch 24 Global_step 1986000	Train_loss: 0.2420	Eval_AUC: 0.8475
Epoch 24 Global_step 1987000	Train_loss: 0.2482	Eval_AUC: 0.8477
Epoch 24 Global_step 1988000	Train_loss: 0.2458	Eval_AUC: 0.8463
Epoch 24 Global_step 1989000	Train_loss: 0.2420	Eval_AUC: 0.8478
Epoch 24 Global_step 1990000	Train_loss: 0.2494	Eval_AUC: 0.8510
Epoch 24 Global_step 1991000	Train_loss: 0.2484	Eval_AUC: 0.8500
Epoch 24 Global_step 1992000	Train_loss: 0.2501	Eval_AUC: 0.8492
Epoch 24 Global_step 1993000	Train_loss: 0.2538	Eval_AUC: 0.8489
Epoch 24 Global_step 1994000	Train_loss: 0.2534	Eval_AUC: 0.8484
Epoch 24 Global_step 1995000	Train_loss: 0.2537	Eval_AUC: 0.8449
Epoch 24 Global_step 1996000	Train_loss: 0.2556	Eval_AUC: 0.8479
Epoch 24 Global_step 1997000	Train_loss: 0.2481	Eval_AUC: 0.8494
Epoch 24 Global_step 1998000	Train_loss: 0.2520	Eval_AUC: 0.8488
Epoch 24 Global_step 1999000	Train_loss: 0.2536	Eval_AUC: 0.8475
Epoch 24 Global_step 2000000	Train_loss: 0.2560	Eval_AUC: 0.8485
Epoch 24 Global_step 2001000	Train_loss: 0.2613	Eval_AUC: 0.8484
Epoch 24 Global_step 2002000	Train_loss: 0.2512	Eval_AUC: 0.8519
Epoch 24 Global_step 2003000	Train_loss: 0.2494	Eval_AUC: 0.8482
Epoch 24 Global_step 2004000	Train_loss: 0.2555	Eval_AUC: 0.8477
Epoch 24 Global_step 2005000	Train_loss: 0.2554	Eval_AUC: 0.8473
Epoch 24 Global_step 2006000	Train_loss: 0.2557	Eval_AUC: 0.8495
Epoch 24 Global_step 2007000	Train_loss: 0.2612	Eval_AUC: 0.8498
Epoch 24 Global_step 2008000	Train_loss: 0.2584	Eval_AUC: 0.8482
Epoch 24 Global_step 2009000	Train_loss: 0.2604	Eval_AUC: 0.8502
Epoch 24 Global_step 2010000	Train_loss: 0.2547	Eval_AUC: 0.8488
Epoch 24 Global_step 2011000	Train_loss: 0.2605	Eval_AUC: 0.8493
Epoch 24 Global_step 2012000	Train_loss: 0.2588	Eval_AUC: 0.8483
Epoch 24 Global_step 2013000	Train_loss: 0.2571	Eval_AUC: 0.8477
Epoch 24 Global_step 2014000	Train_loss: 0.2609	Eval_AUC: 0.8481
Epoch 24 Global_step 2015000	Train_loss: 0.2637	Eval_AUC: 0.8507
Epoch 24 Global_step 2016000	Train_loss: 0.2608	Eval_AUC: 0.8507
Epoch 24 Global_step 2017000	Train_loss: 0.2657	Eval_AUC: 0.8506
Epoch 24 Global_step 2018000	Train_loss: 0.2626	Eval_AUC: 0.8482
Epoch 24 Global_step 2019000	Train_loss: 0.2609	Eval_AUC: 0.8501
Epoch 24 Global_step 2020000	Train_loss: 0.2624	Eval_AUC: 0.8504
Epoch 24 Global_step 2021000	Train_loss: 0.2628	Eval_AUC: 0.8501
Epoch 24 Global_step 2022000	Train_loss: 0.2642	Eval_AUC: 0.8506
Epoch 24 Global_step 2023000	Train_loss: 0.2611	Eval_AUC: 0.8498
Epoch 24 Global_step 2024000	Train_loss: 0.2631	Eval_AUC: 0.8526
Epoch 24 Global_step 2025000	Train_loss: 0.2689	Eval_AUC: 0.8490
Epoch 24 Global_step 2026000	Train_loss: 0.2635	Eval_AUC: 0.8505
Epoch 24 Global_step 2027000	Train_loss: 0.2631	Eval_AUC: 0.8498
Epoch 24 Global_step 2028000	Train_loss: 0.2670	Eval_AUC: 0.8496
Epoch 24 Global_step 2029000	Train_loss: 0.2662	Eval_AUC: 0.8494
Epoch 24 Global_step 2030000	Train_loss: 0.2661	Eval_AUC: 0.8483
Epoch 24 Global_step 2031000	Train_loss: 0.2653	Eval_AUC: 0.8465
Epoch 24 Global_step 2032000	Train_loss: 0.2649	Eval_AUC: 0.8492
Epoch 24 Global_step 2033000	Train_loss: 0.2742	Eval_AUC: 0.8491
Epoch 24 Global_step 2034000	Train_loss: 0.2637	Eval_AUC: 0.8471
Epoch 24 Global_step 2035000	Train_loss: 0.2715	Eval_AUC: 0.8474
Epoch 24 Global_step 2036000	Train_loss: 0.2695	Eval_AUC: 0.8483
Epoch 24 Global_step 2037000	Train_loss: 0.2685	Eval_AUC: 0.8485
Epoch 24 Global_step 2038000	Train_loss: 0.2651	Eval_AUC: 0.8493
Epoch 24 DONE	Cost time: 21935.61
Epoch 25 Global_step 2039000	Train_loss: 0.1969	Eval_AUC: 0.8515
Epoch 25 Global_step 2040000	Train_loss: 0.2190	Eval_AUC: 0.8508
Epoch 25 Global_step 2041000	Train_loss: 0.2231	Eval_AUC: 0.8469
Epoch 25 Global_step 2042000	Train_loss: 0.2266	Eval_AUC: 0.8493
Epoch 25 Global_step 2043000	Train_loss: 0.2202	Eval_AUC: 0.8467
Epoch 25 Global_step 2044000	Train_loss: 0.2243	Eval_AUC: 0.8476
Epoch 25 Global_step 2045000	Train_loss: 0.2172	Eval_AUC: 0.8479
Epoch 25 Global_step 2046000	Train_loss: 0.2249	Eval_AUC: 0.8468
Epoch 25 Global_step 2047000	Train_loss: 0.2239	Eval_AUC: 0.8500
Epoch 25 Global_step 2048000	Train_loss: 0.2276	Eval_AUC: 0.8459
Epoch 25 Global_step 2049000	Train_loss: 0.2236	Eval_AUC: 0.8485
Epoch 25 Global_step 2050000	Train_loss: 0.2273	Eval_AUC: 0.8460
Epoch 25 Global_step 2051000	Train_loss: 0.2299	Eval_AUC: 0.8462
Epoch 25 Global_step 2052000	Train_loss: 0.2313	Eval_AUC: 0.8480
Epoch 25 Global_step 2053000	Train_loss: 0.2282	Eval_AUC: 0.8477
Epoch 25 Global_step 2054000	Train_loss: 0.2285	Eval_AUC: 0.8483
Epoch 25 Global_step 2055000	Train_loss: 0.2320	Eval_AUC: 0.8470
Epoch 25 Global_step 2056000	Train_loss: 0.2314	Eval_AUC: 0.8455
Epoch 25 Global_step 2057000	Train_loss: 0.2308	Eval_AUC: 0.8460
Epoch 25 Global_step 2058000	Train_loss: 0.2351	Eval_AUC: 0.8450
Epoch 25 Global_step 2059000	Train_loss: 0.2316	Eval_AUC: 0.8472
Epoch 25 Global_step 2060000	Train_loss: 0.2326	Eval_AUC: 0.8474
Epoch 25 Global_step 2061000	Train_loss: 0.2342	Eval_AUC: 0.8457
Epoch 25 Global_step 2062000	Train_loss: 0.2347	Eval_AUC: 0.8460
Epoch 25 Global_step 2063000	Train_loss: 0.2347	Eval_AUC: 0.8461
Epoch 25 Global_step 2064000	Train_loss: 0.2401	Eval_AUC: 0.8457
Epoch 25 Global_step 2065000	Train_loss: 0.2364	Eval_AUC: 0.8468
Epoch 25 Global_step 2066000	Train_loss: 0.2411	Eval_AUC: 0.8464
Epoch 25 Global_step 2067000	Train_loss: 0.2417	Eval_AUC: 0.8470
Epoch 25 Global_step 2068000	Train_loss: 0.2407	Eval_AUC: 0.8457
Epoch 25 Global_step 2069000	Train_loss: 0.2417	Eval_AUC: 0.8461
Epoch 25 Global_step 2070000	Train_loss: 0.2405	Eval_AUC: 0.8478
Epoch 25 Global_step 2071000	Train_loss: 0.2450	Eval_AUC: 0.8477
Epoch 25 Global_step 2072000	Train_loss: 0.2474	Eval_AUC: 0.8458
Epoch 25 Global_step 2073000	Train_loss: 0.2458	Eval_AUC: 0.8438
Epoch 25 Global_step 2074000	Train_loss: 0.2399	Eval_AUC: 0.8484
Epoch 25 Global_step 2075000	Train_loss: 0.2465	Eval_AUC: 0.8432
Epoch 25 Global_step 2076000	Train_loss: 0.2445	Eval_AUC: 0.8471
Epoch 25 Global_step 2077000	Train_loss: 0.2446	Eval_AUC: 0.8427
Epoch 25 Global_step 2078000	Train_loss: 0.2478	Eval_AUC: 0.8473
Epoch 25 Global_step 2079000	Train_loss: 0.2423	Eval_AUC: 0.8476
Epoch 25 Global_step 2080000	Train_loss: 0.2464	Eval_AUC: 0.8471
Epoch 25 Global_step 2081000	Train_loss: 0.2471	Eval_AUC: 0.8448
Epoch 25 Global_step 2082000	Train_loss: 0.2466	Eval_AUC: 0.8461
Epoch 25 Global_step 2083000	Train_loss: 0.2447	Eval_AUC: 0.8505
Epoch 25 Global_step 2084000	Train_loss: 0.2494	Eval_AUC: 0.8470
Epoch 25 Global_step 2085000	Train_loss: 0.2486	Eval_AUC: 0.8465
Epoch 25 Global_step 2086000	Train_loss: 0.2534	Eval_AUC: 0.8482
Epoch 25 Global_step 2087000	Train_loss: 0.2486	Eval_AUC: 0.8474
Epoch 25 Global_step 2088000	Train_loss: 0.2519	Eval_AUC: 0.8483
Epoch 25 Global_step 2089000	Train_loss: 0.2480	Eval_AUC: 0.8474
Epoch 25 Global_step 2090000	Train_loss: 0.2556	Eval_AUC: 0.8487
Epoch 25 Global_step 2091000	Train_loss: 0.2502	Eval_AUC: 0.8460
Epoch 25 Global_step 2092000	Train_loss: 0.2582	Eval_AUC: 0.8505
Epoch 25 Global_step 2093000	Train_loss: 0.2573	Eval_AUC: 0.8475
Epoch 25 Global_step 2094000	Train_loss: 0.2541	Eval_AUC: 0.8463
Epoch 25 Global_step 2095000	Train_loss: 0.2526	Eval_AUC: 0.8485
Epoch 25 Global_step 2096000	Train_loss: 0.2529	Eval_AUC: 0.8460
Epoch 25 Global_step 2097000	Train_loss: 0.2528	Eval_AUC: 0.8476
Epoch 25 Global_step 2098000	Train_loss: 0.2552	Eval_AUC: 0.8484
Epoch 25 Global_step 2099000	Train_loss: 0.2587	Eval_AUC: 0.8481
Epoch 25 Global_step 2100000	Train_loss: 0.2546	Eval_AUC: 0.8473
Epoch 25 Global_step 2101000	Train_loss: 0.2572	Eval_AUC: 0.8472
Epoch 25 Global_step 2102000	Train_loss: 0.2592	Eval_AUC: 0.8491
Epoch 25 Global_step 2103000	Train_loss: 0.2576	Eval_AUC: 0.8490
Epoch 25 Global_step 2104000	Train_loss: 0.2584	Eval_AUC: 0.8474
Epoch 25 Global_step 2105000	Train_loss: 0.2565	Eval_AUC: 0.8488
Epoch 25 Global_step 2106000	Train_loss: 0.2570	Eval_AUC: 0.8481
Epoch 25 Global_step 2107000	Train_loss: 0.2583	Eval_AUC: 0.8473
Epoch 25 Global_step 2108000	Train_loss: 0.2623	Eval_AUC: 0.8474
Epoch 25 Global_step 2109000	Train_loss: 0.2609	Eval_AUC: 0.8484
Epoch 25 Global_step 2110000	Train_loss: 0.2556	Eval_AUC: 0.8478
Epoch 25 Global_step 2111000	Train_loss: 0.2643	Eval_AUC: 0.8489
Epoch 25 Global_step 2112000	Train_loss: 0.2589	Eval_AUC: 0.8473
Epoch 25 Global_step 2113000	Train_loss: 0.2593	Eval_AUC: 0.8502
Epoch 25 Global_step 2114000	Train_loss: 0.2636	Eval_AUC: 0.8485
Epoch 25 Global_step 2115000	Train_loss: 0.2656	Eval_AUC: 0.8476
Epoch 25 Global_step 2116000	Train_loss: 0.2588	Eval_AUC: 0.8509
Epoch 25 Global_step 2117000	Train_loss: 0.2623	Eval_AUC: 0.8481
Epoch 25 Global_step 2118000	Train_loss: 0.2601	Eval_AUC: 0.8453
Epoch 25 Global_step 2119000	Train_loss: 0.2591	Eval_AUC: 0.8489
Epoch 25 DONE	Cost time: 22761.08
Epoch 26 Global_step 2120000	Train_loss: 0.0830	Eval_AUC: 0.8492
Epoch 26 Global_step 2121000	Train_loss: 0.2192	Eval_AUC: 0.8501
Epoch 26 Global_step 2122000	Train_loss: 0.2150	Eval_AUC: 0.8491
Epoch 26 Global_step 2123000	Train_loss: 0.2167	Eval_AUC: 0.8479
Epoch 26 Global_step 2124000	Train_loss: 0.2154	Eval_AUC: 0.8477
Epoch 26 Global_step 2125000	Train_loss: 0.2176	Eval_AUC: 0.8496
Epoch 26 Global_step 2126000	Train_loss: 0.2171	Eval_AUC: 0.8474
Epoch 26 Global_step 2127000	Train_loss: 0.2190	Eval_AUC: 0.8460
Epoch 26 Global_step 2128000	Train_loss: 0.2248	Eval_AUC: 0.8472
Epoch 26 Global_step 2129000	Train_loss: 0.2204	Eval_AUC: 0.8458
Epoch 26 Global_step 2130000	Train_loss: 0.2209	Eval_AUC: 0.8468
Epoch 26 Global_step 2131000	Train_loss: 0.2250	Eval_AUC: 0.8474
Epoch 26 Global_step 2132000	Train_loss: 0.2197	Eval_AUC: 0.8469
Epoch 26 Global_step 2133000	Train_loss: 0.2221	Eval_AUC: 0.8451
Epoch 26 Global_step 2134000	Train_loss: 0.2227	Eval_AUC: 0.8442
Epoch 26 Global_step 2135000	Train_loss: 0.2233	Eval_AUC: 0.8461
Epoch 26 Global_step 2136000	Train_loss: 0.2215	Eval_AUC: 0.8481
Epoch 26 Global_step 2137000	Train_loss: 0.2247	Eval_AUC: 0.8446
Epoch 26 Global_step 2138000	Train_loss: 0.2310	Eval_AUC: 0.8445
Epoch 26 Global_step 2139000	Train_loss: 0.2263	Eval_AUC: 0.8472
Epoch 26 Global_step 2140000	Train_loss: 0.2264	Eval_AUC: 0.8462
Epoch 26 Global_step 2141000	Train_loss: 0.2300	Eval_AUC: 0.8462
Epoch 26 Global_step 2142000	Train_loss: 0.2314	Eval_AUC: 0.8432
Epoch 26 Global_step 2143000	Train_loss: 0.2299	Eval_AUC: 0.8432
Epoch 26 Global_step 2144000	Train_loss: 0.2315	Eval_AUC: 0.8442
Epoch 26 Global_step 2145000	Train_loss: 0.2325	Eval_AUC: 0.8427
Epoch 26 Global_step 2146000	Train_loss: 0.2302	Eval_AUC: 0.8454
Epoch 26 Global_step 2147000	Train_loss: 0.2282	Eval_AUC: 0.8452
Epoch 26 Global_step 2148000	Train_loss: 0.2307	Eval_AUC: 0.8440
Epoch 26 Global_step 2149000	Train_loss: 0.2372	Eval_AUC: 0.8459
Epoch 26 Global_step 2150000	Train_loss: 0.2333	Eval_AUC: 0.8467
Epoch 26 Global_step 2151000	Train_loss: 0.2387	Eval_AUC: 0.8445
Epoch 26 Global_step 2152000	Train_loss: 0.2383	Eval_AUC: 0.8449
Epoch 26 Global_step 2153000	Train_loss: 0.2397	Eval_AUC: 0.8451
Epoch 26 Global_step 2154000	Train_loss: 0.2352	Eval_AUC: 0.8429
Epoch 26 Global_step 2155000	Train_loss: 0.2319	Eval_AUC: 0.8445
Epoch 26 Global_step 2156000	Train_loss: 0.2360	Eval_AUC: 0.8469
Epoch 26 Global_step 2157000	Train_loss: 0.2386	Eval_AUC: 0.8442
Epoch 26 Global_step 2158000	Train_loss: 0.2435	Eval_AUC: 0.8467
Epoch 26 Global_step 2159000	Train_loss: 0.2463	Eval_AUC: 0.8448
Epoch 26 Global_step 2160000	Train_loss: 0.2378	Eval_AUC: 0.8471
Epoch 26 Global_step 2161000	Train_loss: 0.2400	Eval_AUC: 0.8454
Epoch 26 Global_step 2162000	Train_loss: 0.2453	Eval_AUC: 0.8461
Epoch 26 Global_step 2163000	Train_loss: 0.2414	Eval_AUC: 0.8476
Epoch 26 Global_step 2164000	Train_loss: 0.2487	Eval_AUC: 0.8445
Epoch 26 Global_step 2165000	Train_loss: 0.2451	Eval_AUC: 0.8462
Epoch 26 Global_step 2166000	Train_loss: 0.2464	Eval_AUC: 0.8433
Epoch 26 Global_step 2167000	Train_loss: 0.2456	Eval_AUC: 0.8458
Epoch 26 Global_step 2168000	Train_loss: 0.2408	Eval_AUC: 0.8472
Epoch 26 Global_step 2169000	Train_loss: 0.2428	Eval_AUC: 0.8441
Epoch 26 Global_step 2170000	Train_loss: 0.2430	Eval_AUC: 0.8463
Epoch 26 Global_step 2171000	Train_loss: 0.2441	Eval_AUC: 0.8465
Epoch 26 Global_step 2172000	Train_loss: 0.2426	Eval_AUC: 0.8460
Epoch 26 Global_step 2173000	Train_loss: 0.2460	Eval_AUC: 0.8471
Epoch 26 Global_step 2174000	Train_loss: 0.2409	Eval_AUC: 0.8440
Epoch 26 Global_step 2175000	Train_loss: 0.2504	Eval_AUC: 0.8461
Epoch 26 Global_step 2176000	Train_loss: 0.2488	Eval_AUC: 0.8463
Epoch 26 Global_step 2177000	Train_loss: 0.2477	Eval_AUC: 0.8478
Epoch 26 Global_step 2178000	Train_loss: 0.2461	Eval_AUC: 0.8437
Epoch 26 Global_step 2179000	Train_loss: 0.2537	Eval_AUC: 0.8472
Epoch 26 Global_step 2180000	Train_loss: 0.2473	Eval_AUC: 0.8478
Epoch 26 Global_step 2181000	Train_loss: 0.2502	Eval_AUC: 0.8465
Epoch 26 Global_step 2182000	Train_loss: 0.2435	Eval_AUC: 0.8466
Epoch 26 Global_step 2183000	Train_loss: 0.2503	Eval_AUC: 0.8444
Epoch 26 Global_step 2184000	Train_loss: 0.2494	Eval_AUC: 0.8467
Epoch 26 Global_step 2185000	Train_loss: 0.2536	Eval_AUC: 0.8478
Epoch 26 Global_step 2186000	Train_loss: 0.2520	Eval_AUC: 0.8473
Epoch 26 Global_step 2187000	Train_loss: 0.2514	Eval_AUC: 0.8450
Epoch 26 Global_step 2188000	Train_loss: 0.2533	Eval_AUC: 0.8466
Epoch 26 Global_step 2189000	Train_loss: 0.2513	Eval_AUC: 0.8480
Epoch 26 Global_step 2190000	Train_loss: 0.2491	Eval_AUC: 0.8464
Epoch 26 Global_step 2191000	Train_loss: 0.2525	Eval_AUC: 0.8491
Epoch 26 Global_step 2192000	Train_loss: 0.2548	Eval_AUC: 0.8464
Epoch 26 Global_step 2193000	Train_loss: 0.2519	Eval_AUC: 0.8460
Epoch 26 Global_step 2194000	Train_loss: 0.2542	Eval_AUC: 0.8451
Epoch 26 Global_step 2195000	Train_loss: 0.2585	Eval_AUC: 0.8487
Epoch 26 Global_step 2196000	Train_loss: 0.2510	Eval_AUC: 0.8486
Epoch 26 Global_step 2197000	Train_loss: 0.2519	Eval_AUC: 0.8496
Epoch 26 Global_step 2198000	Train_loss: 0.2557	Eval_AUC: 0.8495
Epoch 26 Global_step 2199000	Train_loss: 0.2578	Eval_AUC: 0.8504
Epoch 26 Global_step 2200000	Train_loss: 0.2529	Eval_AUC: 0.8497
Epoch 26 Global_step 2201000	Train_loss: 0.2515	Eval_AUC: 0.8466
Epoch 26 DONE	Cost time: 23587.45
Epoch 27 Global_step 2202000	Train_loss: 0.1809	Eval_AUC: 0.8474
Epoch 27 Global_step 2203000	Train_loss: 0.2106	Eval_AUC: 0.8448
Epoch 27 Global_step 2204000	Train_loss: 0.2086	Eval_AUC: 0.8475
Epoch 27 Global_step 2205000	Train_loss: 0.2102	Eval_AUC: 0.8428
Epoch 27 Global_step 2206000	Train_loss: 0.2083	Eval_AUC: 0.8456
Epoch 27 Global_step 2207000	Train_loss: 0.2099	Eval_AUC: 0.8455
Epoch 27 Global_step 2208000	Train_loss: 0.2062	Eval_AUC: 0.8441
Epoch 27 Global_step 2209000	Train_loss: 0.2105	Eval_AUC: 0.8456
Epoch 27 Global_step 2210000	Train_loss: 0.2103	Eval_AUC: 0.8453
Epoch 27 Global_step 2211000	Train_loss: 0.2135	Eval_AUC: 0.8462
Epoch 27 Global_step 2212000	Train_loss: 0.2127	Eval_AUC: 0.8455
Epoch 27 Global_step 2213000	Train_loss: 0.2141	Eval_AUC: 0.8451
Epoch 27 Global_step 2214000	Train_loss: 0.2177	Eval_AUC: 0.8443
Epoch 27 Global_step 2215000	Train_loss: 0.2157	Eval_AUC: 0.8445
Epoch 27 Global_step 2216000	Train_loss: 0.2179	Eval_AUC: 0.8429
Epoch 27 Global_step 2217000	Train_loss: 0.2145	Eval_AUC: 0.8464
Epoch 27 Global_step 2218000	Train_loss: 0.2204	Eval_AUC: 0.8457
Epoch 27 Global_step 2219000	Train_loss: 0.2222	Eval_AUC: 0.8440
Epoch 27 Global_step 2220000	Train_loss: 0.2214	Eval_AUC: 0.8431
Epoch 27 Global_step 2221000	Train_loss: 0.2185	Eval_AUC: 0.8444
Epoch 27 Global_step 2222000	Train_loss: 0.2261	Eval_AUC: 0.8437
Epoch 27 Global_step 2223000	Train_loss: 0.2226	Eval_AUC: 0.8454
Epoch 27 Global_step 2224000	Train_loss: 0.2225	Eval_AUC: 0.8432
Epoch 27 Global_step 2225000	Train_loss: 0.2251	Eval_AUC: 0.8437
Epoch 27 Global_step 2226000	Train_loss: 0.2226	Eval_AUC: 0.8453
Epoch 27 Global_step 2227000	Train_loss: 0.2299	Eval_AUC: 0.8462
Epoch 27 Global_step 2228000	Train_loss: 0.2317	Eval_AUC: 0.8443
Epoch 27 Global_step 2229000	Train_loss: 0.2251	Eval_AUC: 0.8460
Epoch 27 Global_step 2230000	Train_loss: 0.2296	Eval_AUC: 0.8441
Epoch 27 Global_step 2231000	Train_loss: 0.2267	Eval_AUC: 0.8435
Epoch 27 Global_step 2232000	Train_loss: 0.2271	Eval_AUC: 0.8439
Epoch 27 Global_step 2233000	Train_loss: 0.2275	Eval_AUC: 0.8401
Epoch 27 Global_step 2234000	Train_loss: 0.2352	Eval_AUC: 0.8458
Epoch 27 Global_step 2235000	Train_loss: 0.2263	Eval_AUC: 0.8432
Epoch 27 Global_step 2236000	Train_loss: 0.2304	Eval_AUC: 0.8429
Epoch 27 Global_step 2237000	Train_loss: 0.2306	Eval_AUC: 0.8451
Epoch 27 Global_step 2238000	Train_loss: 0.2304	Eval_AUC: 0.8432
Epoch 27 Global_step 2239000	Train_loss: 0.2363	Eval_AUC: 0.8453
Epoch 27 Global_step 2240000	Train_loss: 0.2346	Eval_AUC: 0.8439
Epoch 27 Global_step 2241000	Train_loss: 0.2317	Eval_AUC: 0.8461
Epoch 27 Global_step 2242000	Train_loss: 0.2387	Eval_AUC: 0.8444
Epoch 27 Global_step 2243000	Train_loss: 0.2335	Eval_AUC: 0.8451
Epoch 27 Global_step 2244000	Train_loss: 0.2368	Eval_AUC: 0.8451
Epoch 27 Global_step 2245000	Train_loss: 0.2377	Eval_AUC: 0.8460
Epoch 27 Global_step 2246000	Train_loss: 0.2330	Eval_AUC: 0.8459
Epoch 27 Global_step 2247000	Train_loss: 0.2338	Eval_AUC: 0.8424
Epoch 27 Global_step 2248000	Train_loss: 0.2423	Eval_AUC: 0.8448
Epoch 27 Global_step 2249000	Train_loss: 0.2390	Eval_AUC: 0.8436
Epoch 27 Global_step 2250000	Train_loss: 0.2394	Eval_AUC: 0.8446
Epoch 27 Global_step 2251000	Train_loss: 0.2389	Eval_AUC: 0.8468
Epoch 27 Global_step 2252000	Train_loss: 0.2357	Eval_AUC: 0.8468
Epoch 27 Global_step 2253000	Train_loss: 0.2406	Eval_AUC: 0.8457
Epoch 27 Global_step 2254000	Train_loss: 0.2426	Eval_AUC: 0.8465
Epoch 27 Global_step 2255000	Train_loss: 0.2444	Eval_AUC: 0.8482
Epoch 27 Global_step 2256000	Train_loss: 0.2439	Eval_AUC: 0.8444
Epoch 27 Global_step 2257000	Train_loss: 0.2367	Eval_AUC: 0.8456
Epoch 27 Global_step 2258000	Train_loss: 0.2451	Eval_AUC: 0.8445
Epoch 27 Global_step 2259000	Train_loss: 0.2406	Eval_AUC: 0.8472
Epoch 27 Global_step 2260000	Train_loss: 0.2438	Eval_AUC: 0.8467
Epoch 27 Global_step 2261000	Train_loss: 0.2440	Eval_AUC: 0.8440
Epoch 27 Global_step 2262000	Train_loss: 0.2529	Eval_AUC: 0.8471
Epoch 27 Global_step 2263000	Train_loss: 0.2441	Eval_AUC: 0.8453
Epoch 27 Global_step 2264000	Train_loss: 0.2468	Eval_AUC: 0.8463
Epoch 27 Global_step 2265000	Train_loss: 0.2437	Eval_AUC: 0.8468
Epoch 27 Global_step 2266000	Train_loss: 0.2424	Eval_AUC: 0.8452
Epoch 27 Global_step 2267000	Train_loss: 0.2476	Eval_AUC: 0.8468
Epoch 27 Global_step 2268000	Train_loss: 0.2512	Eval_AUC: 0.8462
Epoch 27 Global_step 2269000	Train_loss: 0.2442	Eval_AUC: 0.8467
Epoch 27 Global_step 2270000	Train_loss: 0.2446	Eval_AUC: 0.8469
Epoch 27 Global_step 2271000	Train_loss: 0.2441	Eval_AUC: 0.8475
Epoch 27 Global_step 2272000	Train_loss: 0.2466	Eval_AUC: 0.8456
Epoch 27 Global_step 2273000	Train_loss: 0.2494	Eval_AUC: 0.8467
Epoch 27 Global_step 2274000	Train_loss: 0.2510	Eval_AUC: 0.8462
Epoch 27 Global_step 2275000	Train_loss: 0.2460	Eval_AUC: 0.8458
Epoch 27 Global_step 2276000	Train_loss: 0.2483	Eval_AUC: 0.8471
Epoch 27 Global_step 2277000	Train_loss: 0.2468	Eval_AUC: 0.8459
Epoch 27 Global_step 2278000	Train_loss: 0.2500	Eval_AUC: 0.8457
Epoch 27 Global_step 2279000	Train_loss: 0.2540	Eval_AUC: 0.8461
Epoch 27 Global_step 2280000	Train_loss: 0.2498	Eval_AUC: 0.8462
Epoch 27 Global_step 2281000	Train_loss: 0.2512	Eval_AUC: 0.8455
Epoch 27 Global_step 2282000	Train_loss: 0.2535	Eval_AUC: 0.8471
Epoch 27 DONE	Cost time: 24418.15
Epoch 28 Global_step 2283000	Train_loss: 0.0685	Eval_AUC: 0.8457
Epoch 28 Global_step 2284000	Train_loss: 0.2027	Eval_AUC: 0.8479
Epoch 28 Global_step 2285000	Train_loss: 0.2074	Eval_AUC: 0.8463
Epoch 28 Global_step 2286000	Train_loss: 0.2016	Eval_AUC: 0.8458
Epoch 28 Global_step 2287000	Train_loss: 0.2102	Eval_AUC: 0.8474
Epoch 28 Global_step 2288000	Train_loss: 0.2039	Eval_AUC: 0.8441
Epoch 28 Global_step 2289000	Train_loss: 0.2049	Eval_AUC: 0.8479
Epoch 28 Global_step 2290000	Train_loss: 0.2086	Eval_AUC: 0.8430
Epoch 28 Global_step 2291000	Train_loss: 0.2056	Eval_AUC: 0.8437
Epoch 28 Global_step 2292000	Train_loss: 0.2076	Eval_AUC: 0.8443
Epoch 28 Global_step 2293000	Train_loss: 0.2135	Eval_AUC: 0.8435
Epoch 28 Global_step 2294000	Train_loss: 0.2084	Eval_AUC: 0.8453
Epoch 28 Global_step 2295000	Train_loss: 0.2068	Eval_AUC: 0.8442
Epoch 28 Global_step 2296000	Train_loss: 0.2128	Eval_AUC: 0.8430
Epoch 28 Global_step 2297000	Train_loss: 0.2082	Eval_AUC: 0.8450
Epoch 28 Global_step 2298000	Train_loss: 0.2126	Eval_AUC: 0.8428
Epoch 28 Global_step 2299000	Train_loss: 0.2197	Eval_AUC: 0.8436
Epoch 28 Global_step 2300000	Train_loss: 0.2135	Eval_AUC: 0.8438
Epoch 28 Global_step 2301000	Train_loss: 0.2146	Eval_AUC: 0.8443
Epoch 28 Global_step 2302000	Train_loss: 0.2159	Eval_AUC: 0.8436
Epoch 28 Global_step 2303000	Train_loss: 0.2221	Eval_AUC: 0.8455
Epoch 28 Global_step 2304000	Train_loss: 0.2183	Eval_AUC: 0.8450
Epoch 28 Global_step 2305000	Train_loss: 0.2193	Eval_AUC: 0.8447
Epoch 28 Global_step 2306000	Train_loss: 0.2213	Eval_AUC: 0.8447
Epoch 28 Global_step 2307000	Train_loss: 0.2226	Eval_AUC: 0.8434
Epoch 28 Global_step 2308000	Train_loss: 0.2220	Eval_AUC: 0.8440
Epoch 28 Global_step 2309000	Train_loss: 0.2212	Eval_AUC: 0.8432
Epoch 28 Global_step 2310000	Train_loss: 0.2209	Eval_AUC: 0.8448
Epoch 28 Global_step 2311000	Train_loss: 0.2247	Eval_AUC: 0.8430
Epoch 28 Global_step 2312000	Train_loss: 0.2227	Eval_AUC: 0.8446
Epoch 28 Global_step 2313000	Train_loss: 0.2245	Eval_AUC: 0.8438
Epoch 28 Global_step 2314000	Train_loss: 0.2259	Eval_AUC: 0.8457
Epoch 28 Global_step 2315000	Train_loss: 0.2273	Eval_AUC: 0.8435
Epoch 28 Global_step 2316000	Train_loss: 0.2216	Eval_AUC: 0.8441
Epoch 28 Global_step 2317000	Train_loss: 0.2273	Eval_AUC: 0.8430
Epoch 28 Global_step 2318000	Train_loss: 0.2294	Eval_AUC: 0.8440
Epoch 28 Global_step 2319000	Train_loss: 0.2308	Eval_AUC: 0.8411
Epoch 28 Global_step 2320000	Train_loss: 0.2222	Eval_AUC: 0.8428
Epoch 28 Global_step 2321000	Train_loss: 0.2295	Eval_AUC: 0.8475
Epoch 28 Global_step 2322000	Train_loss: 0.2312	Eval_AUC: 0.8430
Epoch 28 Global_step 2323000	Train_loss: 0.2295	Eval_AUC: 0.8438
Epoch 28 Global_step 2324000	Train_loss: 0.2284	Eval_AUC: 0.8425
Epoch 28 Global_step 2325000	Train_loss: 0.2295	Eval_AUC: 0.8409
Epoch 28 Global_step 2326000	Train_loss: 0.2322	Eval_AUC: 0.8451
Epoch 28 Global_step 2327000	Train_loss: 0.2296	Eval_AUC: 0.8437
Epoch 28 Global_step 2328000	Train_loss: 0.2315	Eval_AUC: 0.8438
Epoch 28 Global_step 2329000	Train_loss: 0.2314	Eval_AUC: 0.8463
Epoch 28 Global_step 2330000	Train_loss: 0.2307	Eval_AUC: 0.8463
Epoch 28 Global_step 2331000	Train_loss: 0.2328	Eval_AUC: 0.8450
Epoch 28 Global_step 2332000	Train_loss: 0.2381	Eval_AUC: 0.8447
Epoch 28 Global_step 2333000	Train_loss: 0.2335	Eval_AUC: 0.8416
Epoch 28 Global_step 2334000	Train_loss: 0.2302	Eval_AUC: 0.8462
Epoch 28 Global_step 2335000	Train_loss: 0.2384	Eval_AUC: 0.8463
Epoch 28 Global_step 2336000	Train_loss: 0.2301	Eval_AUC: 0.8455
Epoch 28 Global_step 2337000	Train_loss: 0.2369	Eval_AUC: 0.8444
Epoch 28 Global_step 2338000	Train_loss: 0.2410	Eval_AUC: 0.8436
Epoch 28 Global_step 2339000	Train_loss: 0.2333	Eval_AUC: 0.8439
Epoch 28 Global_step 2340000	Train_loss: 0.2359	Eval_AUC: 0.8455
Epoch 28 Global_step 2341000	Train_loss: 0.2379	Eval_AUC: 0.8438
Epoch 28 Global_step 2342000	Train_loss: 0.2327	Eval_AUC: 0.8441
Epoch 28 Global_step 2343000	Train_loss: 0.2399	Eval_AUC: 0.8449
Epoch 28 Global_step 2344000	Train_loss: 0.2389	Eval_AUC: 0.8450
Epoch 28 Global_step 2345000	Train_loss: 0.2389	Eval_AUC: 0.8448
Epoch 28 Global_step 2346000	Train_loss: 0.2399	Eval_AUC: 0.8421
Epoch 28 Global_step 2347000	Train_loss: 0.2394	Eval_AUC: 0.8462
Epoch 28 Global_step 2348000	Train_loss: 0.2422	Eval_AUC: 0.8442
Epoch 28 Global_step 2349000	Train_loss: 0.2422	Eval_AUC: 0.8466
Epoch 28 Global_step 2350000	Train_loss: 0.2439	Eval_AUC: 0.8445
Epoch 28 Global_step 2351000	Train_loss: 0.2442	Eval_AUC: 0.8461
Epoch 28 Global_step 2352000	Train_loss: 0.2451	Eval_AUC: 0.8453
Epoch 28 Global_step 2353000	Train_loss: 0.2388	Eval_AUC: 0.8458
Epoch 28 Global_step 2354000	Train_loss: 0.2430	Eval_AUC: 0.8436
Epoch 28 Global_step 2355000	Train_loss: 0.2332	Eval_AUC: 0.8451
Epoch 28 Global_step 2356000	Train_loss: 0.2423	Eval_AUC: 0.8447
Epoch 28 Global_step 2357000	Train_loss: 0.2410	Eval_AUC: 0.8438
Epoch 28 Global_step 2358000	Train_loss: 0.2447	Eval_AUC: 0.8452
Epoch 28 Global_step 2359000	Train_loss: 0.2429	Eval_AUC: 0.8459
Epoch 28 Global_step 2360000	Train_loss: 0.2413	Eval_AUC: 0.8454
Epoch 28 Global_step 2361000	Train_loss: 0.2437	Eval_AUC: 0.8459
Epoch 28 Global_step 2362000	Train_loss: 0.2417	Eval_AUC: 0.8445
Epoch 28 Global_step 2363000	Train_loss: 0.2427	Eval_AUC: 0.8451
Epoch 28 Global_step 2364000	Train_loss: 0.2482	Eval_AUC: 0.8444
Epoch 28 DONE	Cost time: 25260.20
Epoch 29 Global_step 2365000	Train_loss: 0.1591	Eval_AUC: 0.8450
Epoch 29 Global_step 2366000	Train_loss: 0.1954	Eval_AUC: 0.8442
Epoch 29 Global_step 2367000	Train_loss: 0.1999	Eval_AUC: 0.8439
Epoch 29 Global_step 2368000	Train_loss: 0.2038	Eval_AUC: 0.8441
Epoch 29 Global_step 2369000	Train_loss: 0.2045	Eval_AUC: 0.8446
Epoch 29 Global_step 2370000	Train_loss: 0.2002	Eval_AUC: 0.8420
Epoch 29 Global_step 2371000	Train_loss: 0.2007	Eval_AUC: 0.8432
Epoch 29 Global_step 2372000	Train_loss: 0.2029	Eval_AUC: 0.8415
Epoch 29 Global_step 2373000	Train_loss: 0.2035	Eval_AUC: 0.8426
Epoch 29 Global_step 2374000	Train_loss: 0.2049	Eval_AUC: 0.8423
Epoch 29 Global_step 2375000	Train_loss: 0.2047	Eval_AUC: 0.8433
Epoch 29 Global_step 2376000	Train_loss: 0.2029	Eval_AUC: 0.8416
Epoch 29 Global_step 2377000	Train_loss: 0.2015	Eval_AUC: 0.8411
Epoch 29 Global_step 2378000	Train_loss: 0.2054	Eval_AUC: 0.8440
Epoch 29 Global_step 2379000	Train_loss: 0.2090	Eval_AUC: 0.8412
Epoch 29 Global_step 2380000	Train_loss: 0.2087	Eval_AUC: 0.8410
Epoch 29 Global_step 2381000	Train_loss: 0.2104	Eval_AUC: 0.8445
Epoch 29 Global_step 2382000	Train_loss: 0.2063	Eval_AUC: 0.8421
Epoch 29 Global_step 2383000	Train_loss: 0.2110	Eval_AUC: 0.8437
Epoch 29 Global_step 2384000	Train_loss: 0.2114	Eval_AUC: 0.8418
Epoch 29 Global_step 2385000	Train_loss: 0.2102	Eval_AUC: 0.8430
Epoch 29 Global_step 2386000	Train_loss: 0.2086	Eval_AUC: 0.8432
Epoch 29 Global_step 2387000	Train_loss: 0.2133	Eval_AUC: 0.8406
Epoch 29 Global_step 2388000	Train_loss: 0.2133	Eval_AUC: 0.8432
Epoch 29 Global_step 2389000	Train_loss: 0.2151	Eval_AUC: 0.8450
Epoch 29 Global_step 2390000	Train_loss: 0.2131	Eval_AUC: 0.8414
Epoch 29 Global_step 2391000	Train_loss: 0.2130	Eval_AUC: 0.8441
Epoch 29 Global_step 2392000	Train_loss: 0.2173	Eval_AUC: 0.8406
Epoch 29 Global_step 2393000	Train_loss: 0.2195	Eval_AUC: 0.8440
Epoch 29 Global_step 2394000	Train_loss: 0.2213	Eval_AUC: 0.8404
Epoch 29 Global_step 2395000	Train_loss: 0.2194	Eval_AUC: 0.8427
Epoch 29 Global_step 2396000	Train_loss: 0.2186	Eval_AUC: 0.8412
Epoch 29 Global_step 2397000	Train_loss: 0.2186	Eval_AUC: 0.8454
Epoch 29 Global_step 2398000	Train_loss: 0.2213	Eval_AUC: 0.8439
Epoch 29 Global_step 2399000	Train_loss: 0.2236	Eval_AUC: 0.8432
Epoch 29 Global_step 2400000	Train_loss: 0.2203	Eval_AUC: 0.8442
Epoch 29 Global_step 2401000	Train_loss: 0.2202	Eval_AUC: 0.8446
Epoch 29 Global_step 2402000	Train_loss: 0.2231	Eval_AUC: 0.8422
Epoch 29 Global_step 2403000	Train_loss: 0.2259	Eval_AUC: 0.8440
Epoch 29 Global_step 2404000	Train_loss: 0.2205	Eval_AUC: 0.8408
Epoch 29 Global_step 2405000	Train_loss: 0.2221	Eval_AUC: 0.8452
Epoch 29 Global_step 2406000	Train_loss: 0.2277	Eval_AUC: 0.8440
Epoch 29 Global_step 2407000	Train_loss: 0.2224	Eval_AUC: 0.8448
Epoch 29 Global_step 2408000	Train_loss: 0.2242	Eval_AUC: 0.8434
Epoch 29 Global_step 2409000	Train_loss: 0.2205	Eval_AUC: 0.8391
Epoch 29 Global_step 2410000	Train_loss: 0.2253	Eval_AUC: 0.8429
Epoch 29 Global_step 2411000	Train_loss: 0.2253	Eval_AUC: 0.8436
Epoch 29 Global_step 2412000	Train_loss: 0.2309	Eval_AUC: 0.8444
Epoch 29 Global_step 2413000	Train_loss: 0.2241	Eval_AUC: 0.8406
Epoch 29 Global_step 2414000	Train_loss: 0.2273	Eval_AUC: 0.8416
Epoch 29 Global_step 2415000	Train_loss: 0.2252	Eval_AUC: 0.8441
Epoch 29 Global_step 2416000	Train_loss: 0.2284	Eval_AUC: 0.8433
Epoch 29 Global_step 2417000	Train_loss: 0.2253	Eval_AUC: 0.8430
Epoch 29 Global_step 2418000	Train_loss: 0.2312	Eval_AUC: 0.8421
Epoch 29 Global_step 2419000	Train_loss: 0.2286	Eval_AUC: 0.8452
Epoch 29 Global_step 2420000	Train_loss: 0.2384	Eval_AUC: 0.8413
Epoch 29 Global_step 2421000	Train_loss: 0.2314	Eval_AUC: 0.8435
Epoch 29 Global_step 2422000	Train_loss: 0.2283	Eval_AUC: 0.8434
Epoch 29 Global_step 2423000	Train_loss: 0.2296	Eval_AUC: 0.8433
Epoch 29 Global_step 2424000	Train_loss: 0.2335	Eval_AUC: 0.8427
Epoch 29 Global_step 2425000	Train_loss: 0.2333	Eval_AUC: 0.8446
Epoch 29 Global_step 2426000	Train_loss: 0.2327	Eval_AUC: 0.8429
Epoch 29 Global_step 2427000	Train_loss: 0.2308	Eval_AUC: 0.8447
Epoch 29 Global_step 2428000	Train_loss: 0.2323	Eval_AUC: 0.8443
Epoch 29 Global_step 2429000	Train_loss: 0.2338	Eval_AUC: 0.8451
Epoch 29 Global_step 2430000	Train_loss: 0.2355	Eval_AUC: 0.8404
Epoch 29 Global_step 2431000	Train_loss: 0.2332	Eval_AUC: 0.8440
Epoch 29 Global_step 2432000	Train_loss: 0.2338	Eval_AUC: 0.8419
Epoch 29 Global_step 2433000	Train_loss: 0.2404	Eval_AUC: 0.8445
Epoch 29 Global_step 2434000	Train_loss: 0.2371	Eval_AUC: 0.8441
Epoch 29 Global_step 2435000	Train_loss: 0.2404	Eval_AUC: 0.8422
Epoch 29 Global_step 2436000	Train_loss: 0.2401	Eval_AUC: 0.8434
Epoch 29 Global_step 2437000	Train_loss: 0.2355	Eval_AUC: 0.8424
Epoch 29 Global_step 2438000	Train_loss: 0.2383	Eval_AUC: 0.8424
Epoch 29 Global_step 2439000	Train_loss: 0.2399	Eval_AUC: 0.8445
Epoch 29 Global_step 2440000	Train_loss: 0.2376	Eval_AUC: 0.8429
Epoch 29 Global_step 2441000	Train_loss: 0.2390	Eval_AUC: 0.8458
Epoch 29 Global_step 2442000	Train_loss: 0.2426	Eval_AUC: 0.8423
Epoch 29 Global_step 2443000	Train_loss: 0.2394	Eval_AUC: 0.8458
Epoch 29 Global_step 2444000	Train_loss: 0.2365	Eval_AUC: 0.8455
Epoch 29 Global_step 2445000	Train_loss: 0.2414	Eval_AUC: 0.8438
Epoch 29 DONE	Cost time: 26084.54
Epoch 30 Global_step 2446000	Train_loss: 0.0553	Eval_AUC: 0.8453
Epoch 30 Global_step 2447000	Train_loss: 0.1972	Eval_AUC: 0.8448
Epoch 30 Global_step 2448000	Train_loss: 0.1960	Eval_AUC: 0.8434
Epoch 30 Global_step 2449000	Train_loss: 0.1953	Eval_AUC: 0.8430
Epoch 30 Global_step 2450000	Train_loss: 0.1953	Eval_AUC: 0.8426
Epoch 30 Global_step 2451000	Train_loss: 0.1944	Eval_AUC: 0.8417
Epoch 30 Global_step 2452000	Train_loss: 0.1904	Eval_AUC: 0.8428
Epoch 30 Global_step 2453000	Train_loss: 0.1990	Eval_AUC: 0.8433
Epoch 30 Global_step 2454000	Train_loss: 0.1990	Eval_AUC: 0.8422
Epoch 30 Global_step 2455000	Train_loss: 0.1954	Eval_AUC: 0.8404
Epoch 30 Global_step 2456000	Train_loss: 0.1985	Eval_AUC: 0.8415
Epoch 30 Global_step 2457000	Train_loss: 0.2027	Eval_AUC: 0.8409
Epoch 30 Global_step 2458000	Train_loss: 0.2045	Eval_AUC: 0.8415
Epoch 30 Global_step 2459000	Train_loss: 0.2023	Eval_AUC: 0.8433
Epoch 30 Global_step 2460000	Train_loss: 0.2008	Eval_AUC: 0.8393
Epoch 30 Global_step 2461000	Train_loss: 0.2005	Eval_AUC: 0.8411
Epoch 30 Global_step 2462000	Train_loss: 0.1987	Eval_AUC: 0.8429
Epoch 30 Global_step 2463000	Train_loss: 0.2012	Eval_AUC: 0.8444
Epoch 30 Global_step 2464000	Train_loss: 0.2080	Eval_AUC: 0.8436
Epoch 30 Global_step 2465000	Train_loss: 0.2036	Eval_AUC: 0.8401
Epoch 30 Global_step 2466000	Train_loss: 0.2073	Eval_AUC: 0.8421
Epoch 30 Global_step 2467000	Train_loss: 0.2112	Eval_AUC: 0.8431
Epoch 30 Global_step 2468000	Train_loss: 0.2079	Eval_AUC: 0.8403
Epoch 30 Global_step 2469000	Train_loss: 0.2083	Eval_AUC: 0.8388
Epoch 30 Global_step 2470000	Train_loss: 0.2057	Eval_AUC: 0.8430
Epoch 30 Global_step 2471000	Train_loss: 0.2054	Eval_AUC: 0.8415
Epoch 30 Global_step 2472000	Train_loss: 0.2111	Eval_AUC: 0.8436
Epoch 30 Global_step 2473000	Train_loss: 0.2130	Eval_AUC: 0.8416
Epoch 30 Global_step 2474000	Train_loss: 0.2046	Eval_AUC: 0.8418
Epoch 30 Global_step 2475000	Train_loss: 0.2151	Eval_AUC: 0.8401
Epoch 30 Global_step 2476000	Train_loss: 0.2142	Eval_AUC: 0.8424
Epoch 30 Global_step 2477000	Train_loss: 0.2108	Eval_AUC: 0.8422
Epoch 30 Global_step 2478000	Train_loss: 0.2126	Eval_AUC: 0.8392
Epoch 30 Global_step 2479000	Train_loss: 0.2139	Eval_AUC: 0.8414
Epoch 30 Global_step 2480000	Train_loss: 0.2165	Eval_AUC: 0.8419
Epoch 30 Global_step 2481000	Train_loss: 0.2151	Eval_AUC: 0.8434
Epoch 30 Global_step 2482000	Train_loss: 0.2167	Eval_AUC: 0.8407
Epoch 30 Global_step 2483000	Train_loss: 0.2145	Eval_AUC: 0.8417
Epoch 30 Global_step 2484000	Train_loss: 0.2150	Eval_AUC: 0.8398
Epoch 30 Global_step 2485000	Train_loss: 0.2167	Eval_AUC: 0.8400
Epoch 30 Global_step 2486000	Train_loss: 0.2162	Eval_AUC: 0.8428
Epoch 30 Global_step 2487000	Train_loss: 0.2225	Eval_AUC: 0.8414
Epoch 30 Global_step 2488000	Train_loss: 0.2227	Eval_AUC: 0.8408
Epoch 30 Global_step 2489000	Train_loss: 0.2248	Eval_AUC: 0.8421
Epoch 30 Global_step 2490000	Train_loss: 0.2222	Eval_AUC: 0.8438
Epoch 30 Global_step 2491000	Train_loss: 0.2228	Eval_AUC: 0.8434
Epoch 30 Global_step 2492000	Train_loss: 0.2209	Eval_AUC: 0.8433
Epoch 30 Global_step 2493000	Train_loss: 0.2205	Eval_AUC: 0.8423
Epoch 30 Global_step 2494000	Train_loss: 0.2230	Eval_AUC: 0.8426
Epoch 30 Global_step 2495000	Train_loss: 0.2240	Eval_AUC: 0.8423
Epoch 30 Global_step 2496000	Train_loss: 0.2237	Eval_AUC: 0.8415
Epoch 30 Global_step 2497000	Train_loss: 0.2215	Eval_AUC: 0.8437
Epoch 30 Global_step 2498000	Train_loss: 0.2294	Eval_AUC: 0.8414
Epoch 30 Global_step 2499000	Train_loss: 0.2245	Eval_AUC: 0.8418
Epoch 30 Global_step 2500000	Train_loss: 0.2202	Eval_AUC: 0.8436
Epoch 30 Global_step 2501000	Train_loss: 0.2222	Eval_AUC: 0.8433
Epoch 30 Global_step 2502000	Train_loss: 0.2277	Eval_AUC: 0.8423
Epoch 30 Global_step 2503000	Train_loss: 0.2245	Eval_AUC: 0.8432
Epoch 30 Global_step 2504000	Train_loss: 0.2274	Eval_AUC: 0.8412
Epoch 30 Global_step 2505000	Train_loss: 0.2246	Eval_AUC: 0.8419
Epoch 30 Global_step 2506000	Train_loss: 0.2302	Eval_AUC: 0.8441
Epoch 30 Global_step 2507000	Train_loss: 0.2249	Eval_AUC: 0.8428
Epoch 30 Global_step 2508000	Train_loss: 0.2324	Eval_AUC: 0.8413
Epoch 30 Global_step 2509000	Train_loss: 0.2239	Eval_AUC: 0.8444
Epoch 30 Global_step 2510000	Train_loss: 0.2284	Eval_AUC: 0.8415
Epoch 30 Global_step 2511000	Train_loss: 0.2308	Eval_AUC: 0.8437
Epoch 30 Global_step 2512000	Train_loss: 0.2267	Eval_AUC: 0.8438
Epoch 30 Global_step 2513000	Train_loss: 0.2262	Eval_AUC: 0.8432
Epoch 30 Global_step 2514000	Train_loss: 0.2303	Eval_AUC: 0.8444
Epoch 30 Global_step 2515000	Train_loss: 0.2325	Eval_AUC: 0.8431
Epoch 30 Global_step 2516000	Train_loss: 0.2327	Eval_AUC: 0.8446
Epoch 30 Global_step 2517000	Train_loss: 0.2309	Eval_AUC: 0.8429
Epoch 30 Global_step 2518000	Train_loss: 0.2303	Eval_AUC: 0.8435
Epoch 30 Global_step 2519000	Train_loss: 0.2317	Eval_AUC: 0.8425
Epoch 30 Global_step 2520000	Train_loss: 0.2333	Eval_AUC: 0.8421
Epoch 30 Global_step 2521000	Train_loss: 0.2336	Eval_AUC: 0.8428
Epoch 30 Global_step 2522000	Train_loss: 0.2318	Eval_AUC: 0.8429
Epoch 30 Global_step 2523000	Train_loss: 0.2334	Eval_AUC: 0.8426
Epoch 30 Global_step 2524000	Train_loss: 0.2352	Eval_AUC: 0.8423
Epoch 30 Global_step 2525000	Train_loss: 0.2331	Eval_AUC: 0.8435
Epoch 30 Global_step 2526000	Train_loss: 0.2321	Eval_AUC: 0.8451
Epoch 30 Global_step 2527000	Train_loss: 0.2382	Eval_AUC: 0.8412
Epoch 30 DONE	Cost time: 26913.90
Epoch 31 Global_step 2528000	Train_loss: 0.1462	Eval_AUC: 0.8421
Epoch 31 Global_step 2529000	Train_loss: 0.1881	Eval_AUC: 0.8433
Epoch 31 Global_step 2530000	Train_loss: 0.1885	Eval_AUC: 0.8437
Epoch 31 Global_step 2531000	Train_loss: 0.1856	Eval_AUC: 0.8443
Epoch 31 Global_step 2532000	Train_loss: 0.1914	Eval_AUC: 0.8406
Epoch 31 Global_step 2533000	Train_loss: 0.1884	Eval_AUC: 0.8438
Epoch 31 Global_step 2534000	Train_loss: 0.1899	Eval_AUC: 0.8431
Epoch 31 Global_step 2535000	Train_loss: 0.1928	Eval_AUC: 0.8428
Epoch 31 Global_step 2536000	Train_loss: 0.1918	Eval_AUC: 0.8417
Epoch 31 Global_step 2537000	Train_loss: 0.1898	Eval_AUC: 0.8427
Epoch 31 Global_step 2538000	Train_loss: 0.1910	Eval_AUC: 0.8412
Epoch 31 Global_step 2539000	Train_loss: 0.1916	Eval_AUC: 0.8410
Epoch 31 Global_step 2540000	Train_loss: 0.1971	Eval_AUC: 0.8407
Epoch 31 Global_step 2541000	Train_loss: 0.1954	Eval_AUC: 0.8430
Epoch 31 Global_step 2542000	Train_loss: 0.1948	Eval_AUC: 0.8394
Epoch 31 Global_step 2543000	Train_loss: 0.1986	Eval_AUC: 0.8412
Epoch 31 Global_step 2544000	Train_loss: 0.1950	Eval_AUC: 0.8408
Epoch 31 Global_step 2545000	Train_loss: 0.1992	Eval_AUC: 0.8407
Epoch 31 Global_step 2546000	Train_loss: 0.1984	Eval_AUC: 0.8414
Epoch 31 Global_step 2547000	Train_loss: 0.1995	Eval_AUC: 0.8402
Epoch 31 Global_step 2548000	Train_loss: 0.2045	Eval_AUC: 0.8423
Epoch 31 Global_step 2549000	Train_loss: 0.1948	Eval_AUC: 0.8404
Epoch 31 Global_step 2550000	Train_loss: 0.2050	Eval_AUC: 0.8404
Epoch 31 Global_step 2551000	Train_loss: 0.2097	Eval_AUC: 0.8396
Epoch 31 Global_step 2552000	Train_loss: 0.2033	Eval_AUC: 0.8386
Epoch 31 Global_step 2553000	Train_loss: 0.2040	Eval_AUC: 0.8402
Epoch 31 Global_step 2554000	Train_loss: 0.2064	Eval_AUC: 0.8400
Epoch 31 Global_step 2555000	Train_loss: 0.2022	Eval_AUC: 0.8408
Epoch 31 Global_step 2556000	Train_loss: 0.2114	Eval_AUC: 0.8427
Epoch 31 Global_step 2557000	Train_loss: 0.2100	Eval_AUC: 0.8425
Epoch 31 Global_step 2558000	Train_loss: 0.2102	Eval_AUC: 0.8386
Epoch 31 Global_step 2559000	Train_loss: 0.2070	Eval_AUC: 0.8399
Epoch 31 Global_step 2560000	Train_loss: 0.2096	Eval_AUC: 0.8410
Epoch 31 Global_step 2561000	Train_loss: 0.2072	Eval_AUC: 0.8403
Epoch 31 Global_step 2562000	Train_loss: 0.2113	Eval_AUC: 0.8408
Epoch 31 Global_step 2563000	Train_loss: 0.2135	Eval_AUC: 0.8404
Epoch 31 Global_step 2564000	Train_loss: 0.2108	Eval_AUC: 0.8413
Epoch 31 Global_step 2565000	Train_loss: 0.2131	Eval_AUC: 0.8417
Epoch 31 Global_step 2566000	Train_loss: 0.2104	Eval_AUC: 0.8399
Epoch 31 Global_step 2567000	Train_loss: 0.2066	Eval_AUC: 0.8422
Epoch 31 Global_step 2568000	Train_loss: 0.2125	Eval_AUC: 0.8420
Epoch 31 Global_step 2569000	Train_loss: 0.2124	Eval_AUC: 0.8420
Epoch 31 Global_step 2570000	Train_loss: 0.2120	Eval_AUC: 0.8389
Epoch 31 Global_step 2571000	Train_loss: 0.2197	Eval_AUC: 0.8425
Epoch 31 Global_step 2572000	Train_loss: 0.2157	Eval_AUC: 0.8402
Epoch 31 Global_step 2573000	Train_loss: 0.2121	Eval_AUC: 0.8423
Epoch 31 Global_step 2574000	Train_loss: 0.2172	Eval_AUC: 0.8411
Epoch 31 Global_step 2575000	Train_loss: 0.2113	Eval_AUC: 0.8425
Epoch 31 Global_step 2576000	Train_loss: 0.2161	Eval_AUC: 0.8414
Epoch 31 Global_step 2577000	Train_loss: 0.2214	Eval_AUC: 0.8433
Epoch 31 Global_step 2578000	Train_loss: 0.2226	Eval_AUC: 0.8418
Epoch 31 Global_step 2579000	Train_loss: 0.2167	Eval_AUC: 0.8430
Epoch 31 Global_step 2580000	Train_loss: 0.2206	Eval_AUC: 0.8416
Epoch 31 Global_step 2581000	Train_loss: 0.2175	Eval_AUC: 0.8400
Epoch 31 Global_step 2582000	Train_loss: 0.2238	Eval_AUC: 0.8424
Epoch 31 Global_step 2583000	Train_loss: 0.2200	Eval_AUC: 0.8428
Epoch 31 Global_step 2584000	Train_loss: 0.2249	Eval_AUC: 0.8432
Epoch 31 Global_step 2585000	Train_loss: 0.2226	Eval_AUC: 0.8429
Epoch 31 Global_step 2586000	Train_loss: 0.2238	Eval_AUC: 0.8424
Epoch 31 Global_step 2587000	Train_loss: 0.2269	Eval_AUC: 0.8412
Epoch 31 Global_step 2588000	Train_loss: 0.2251	Eval_AUC: 0.8411
Epoch 31 Global_step 2589000	Train_loss: 0.2280	Eval_AUC: 0.8428
Epoch 31 Global_step 2590000	Train_loss: 0.2268	Eval_AUC: 0.8431
Epoch 31 Global_step 2591000	Train_loss: 0.2263	Eval_AUC: 0.8444
Epoch 31 Global_step 2592000	Train_loss: 0.2260	Eval_AUC: 0.8448
Epoch 31 Global_step 2593000	Train_loss: 0.2248	Eval_AUC: 0.8442
Epoch 31 Global_step 2594000	Train_loss: 0.2221	Eval_AUC: 0.8429
Epoch 31 Global_step 2595000	Train_loss: 0.2234	Eval_AUC: 0.8431
Epoch 31 Global_step 2596000	Train_loss: 0.2193	Eval_AUC: 0.8429
Epoch 31 Global_step 2597000	Train_loss: 0.2260	Eval_AUC: 0.8414
Epoch 31 Global_step 2598000	Train_loss: 0.2225	Eval_AUC: 0.8433
Epoch 31 Global_step 2599000	Train_loss: 0.2266	Eval_AUC: 0.8433
Epoch 31 Global_step 2600000	Train_loss: 0.2239	Eval_AUC: 0.8431
Epoch 31 Global_step 2601000	Train_loss: 0.2308	Eval_AUC: 0.8441
Epoch 31 Global_step 2602000	Train_loss: 0.2262	Eval_AUC: 0.8425
Epoch 31 Global_step 2603000	Train_loss: 0.2288	Eval_AUC: 0.8423
Epoch 31 Global_step 2604000	Train_loss: 0.2229	Eval_AUC: 0.8433
Epoch 31 Global_step 2605000	Train_loss: 0.2257	Eval_AUC: 0.8437
Epoch 31 Global_step 2606000	Train_loss: 0.2282	Eval_AUC: 0.8417
Epoch 31 Global_step 2607000	Train_loss: 0.2286	Eval_AUC: 0.8411
Epoch 31 Global_step 2608000	Train_loss: 0.2257	Eval_AUC: 0.8425
Epoch 31 DONE	Cost time: 27755.45
Epoch 32 Global_step 2609000	Train_loss: 0.0425	Eval_AUC: 0.8450
Epoch 32 Global_step 2610000	Train_loss: 0.1871	Eval_AUC: 0.8439
Epoch 32 Global_step 2611000	Train_loss: 0.1841	Eval_AUC: 0.8432
Epoch 32 Global_step 2612000	Train_loss: 0.1826	Eval_AUC: 0.8422
Epoch 32 Global_step 2613000	Train_loss: 0.1873	Eval_AUC: 0.8406
Epoch 32 Global_step 2614000	Train_loss: 0.1875	Eval_AUC: 0.8424
Epoch 32 Global_step 2615000	Train_loss: 0.1843	Eval_AUC: 0.8407
Epoch 32 Global_step 2616000	Train_loss: 0.1876	Eval_AUC: 0.8414
Epoch 32 Global_step 2617000	Train_loss: 0.1830	Eval_AUC: 0.8401
Epoch 32 Global_step 2618000	Train_loss: 0.1873	Eval_AUC: 0.8408
Epoch 32 Global_step 2619000	Train_loss: 0.1938	Eval_AUC: 0.8376
Epoch 32 Global_step 2620000	Train_loss: 0.1884	Eval_AUC: 0.8411
Epoch 32 Global_step 2621000	Train_loss: 0.1902	Eval_AUC: 0.8412
Epoch 32 Global_step 2622000	Train_loss: 0.1890	Eval_AUC: 0.8410
Epoch 32 Global_step 2623000	Train_loss: 0.1952	Eval_AUC: 0.8420
Epoch 32 Global_step 2624000	Train_loss: 0.1942	Eval_AUC: 0.8403
Epoch 32 Global_step 2625000	Train_loss: 0.1902	Eval_AUC: 0.8397
Epoch 32 Global_step 2626000	Train_loss: 0.1914	Eval_AUC: 0.8405
Epoch 32 Global_step 2627000	Train_loss: 0.1978	Eval_AUC: 0.8393
Epoch 32 Global_step 2628000	Train_loss: 0.1934	Eval_AUC: 0.8399
Epoch 32 Global_step 2629000	Train_loss: 0.1913	Eval_AUC: 0.8393
Epoch 32 Global_step 2630000	Train_loss: 0.1960	Eval_AUC: 0.8409
Epoch 32 Global_step 2631000	Train_loss: 0.1963	Eval_AUC: 0.8411
Epoch 32 Global_step 2632000	Train_loss: 0.1995	Eval_AUC: 0.8395
Epoch 32 Global_step 2633000	Train_loss: 0.1975	Eval_AUC: 0.8421
Epoch 32 Global_step 2634000	Train_loss: 0.1976	Eval_AUC: 0.8422
Epoch 32 Global_step 2635000	Train_loss: 0.1992	Eval_AUC: 0.8417
Epoch 32 Global_step 2636000	Train_loss: 0.2043	Eval_AUC: 0.8394
Epoch 32 Global_step 2637000	Train_loss: 0.1954	Eval_AUC: 0.8406
Epoch 32 Global_step 2638000	Train_loss: 0.1999	Eval_AUC: 0.8404
Epoch 32 Global_step 2639000	Train_loss: 0.2030	Eval_AUC: 0.8429
Epoch 32 Global_step 2640000	Train_loss: 0.2026	Eval_AUC: 0.8403
Epoch 32 Global_step 2641000	Train_loss: 0.2011	Eval_AUC: 0.8429
Epoch 32 Global_step 2642000	Train_loss: 0.2045	Eval_AUC: 0.8411
Epoch 32 Global_step 2643000	Train_loss: 0.2056	Eval_AUC: 0.8398
Epoch 32 Global_step 2644000	Train_loss: 0.2025	Eval_AUC: 0.8399
Epoch 32 Global_step 2645000	Train_loss: 0.2026	Eval_AUC: 0.8397
Epoch 32 Global_step 2646000	Train_loss: 0.2052	Eval_AUC: 0.8433
Epoch 32 Global_step 2647000	Train_loss: 0.2113	Eval_AUC: 0.8402
Epoch 32 Global_step 2648000	Train_loss: 0.2037	Eval_AUC: 0.8402
Epoch 32 Global_step 2649000	Train_loss: 0.2097	Eval_AUC: 0.8406
Epoch 32 Global_step 2650000	Train_loss: 0.2058	Eval_AUC: 0.8414
Epoch 32 Global_step 2651000	Train_loss: 0.2037	Eval_AUC: 0.8407
Epoch 32 Global_step 2652000	Train_loss: 0.2100	Eval_AUC: 0.8389
Epoch 32 Global_step 2653000	Train_loss: 0.2168	Eval_AUC: 0.8417
Epoch 32 Global_step 2654000	Train_loss: 0.2129	Eval_AUC: 0.8409
Epoch 32 Global_step 2655000	Train_loss: 0.2107	Eval_AUC: 0.8422
Epoch 32 Global_step 2656000	Train_loss: 0.2114	Eval_AUC: 0.8422
Epoch 32 Global_step 2657000	Train_loss: 0.2100	Eval_AUC: 0.8413
Epoch 32 Global_step 2658000	Train_loss: 0.2105	Eval_AUC: 0.8409
Epoch 32 Global_step 2659000	Train_loss: 0.2107	Eval_AUC: 0.8424
Epoch 32 Global_step 2660000	Train_loss: 0.2092	Eval_AUC: 0.8412
Epoch 32 Global_step 2661000	Train_loss: 0.2102	Eval_AUC: 0.8418
Epoch 32 Global_step 2662000	Train_loss: 0.2117	Eval_AUC: 0.8418
Epoch 32 Global_step 2663000	Train_loss: 0.2109	Eval_AUC: 0.8446
Epoch 32 Global_step 2664000	Train_loss: 0.2145	Eval_AUC: 0.8412
Epoch 32 Global_step 2665000	Train_loss: 0.2158	Eval_AUC: 0.8410
Epoch 32 Global_step 2666000	Train_loss: 0.2153	Eval_AUC: 0.8406
Epoch 32 Global_step 2667000	Train_loss: 0.2154	Eval_AUC: 0.8409
Epoch 32 Global_step 2668000	Train_loss: 0.2189	Eval_AUC: 0.8441
Epoch 32 Global_step 2669000	Train_loss: 0.2172	Eval_AUC: 0.8415
Epoch 32 Global_step 2670000	Train_loss: 0.2188	Eval_AUC: 0.8401
Epoch 32 Global_step 2671000	Train_loss: 0.2175	Eval_AUC: 0.8415
Epoch 32 Global_step 2672000	Train_loss: 0.2202	Eval_AUC: 0.8407
Epoch 32 Global_step 2673000	Train_loss: 0.2160	Eval_AUC: 0.8417
Epoch 32 Global_step 2674000	Train_loss: 0.2210	Eval_AUC: 0.8401
Epoch 32 Global_step 2675000	Train_loss: 0.2200	Eval_AUC: 0.8410
Epoch 32 Global_step 2676000	Train_loss: 0.2247	Eval_AUC: 0.8423
Epoch 32 Global_step 2677000	Train_loss: 0.2168	Eval_AUC: 0.8434
Epoch 32 Global_step 2678000	Train_loss: 0.2154	Eval_AUC: 0.8422
Epoch 32 Global_step 2679000	Train_loss: 0.2206	Eval_AUC: 0.8440
Epoch 32 Global_step 2680000	Train_loss: 0.2187	Eval_AUC: 0.8404
Epoch 32 Global_step 2681000	Train_loss: 0.2254	Eval_AUC: 0.8425
Epoch 32 Global_step 2682000	Train_loss: 0.2209	Eval_AUC: 0.8426
Epoch 32 Global_step 2683000	Train_loss: 0.2222	Eval_AUC: 0.8421
Epoch 32 Global_step 2684000	Train_loss: 0.2216	Eval_AUC: 0.8414
Epoch 32 Global_step 2685000	Train_loss: 0.2216	Eval_AUC: 0.8424
Epoch 32 Global_step 2686000	Train_loss: 0.2250	Eval_AUC: 0.8424
Epoch 32 Global_step 2687000	Train_loss: 0.2199	Eval_AUC: 0.8427
Epoch 32 Global_step 2688000	Train_loss: 0.2145	Eval_AUC: 0.8425
Epoch 32 Global_step 2689000	Train_loss: 0.2257	Eval_AUC: 0.8435
Epoch 32 Global_step 2690000	Train_loss: 0.2240	Eval_AUC: 0.8414
Epoch 32 DONE	Cost time: 28588.73
Epoch 33 Global_step 2691000	Train_loss: 0.1341	Eval_AUC: 0.8396
Epoch 33 Global_step 2692000	Train_loss: 0.1829	Eval_AUC: 0.8422
Epoch 33 Global_step 2693000	Train_loss: 0.1824	Eval_AUC: 0.8417
Epoch 33 Global_step 2694000	Train_loss: 0.1769	Eval_AUC: 0.8410
Epoch 33 Global_step 2695000	Train_loss: 0.1877	Eval_AUC: 0.8400
Epoch 33 Global_step 2696000	Train_loss: 0.1819	Eval_AUC: 0.8386
Epoch 33 Global_step 2697000	Train_loss: 0.1805	Eval_AUC: 0.8399
Epoch 33 Global_step 2698000	Train_loss: 0.1833	Eval_AUC: 0.8410
Epoch 33 Global_step 2699000	Train_loss: 0.1821	Eval_AUC: 0.8399
Epoch 33 Global_step 2700000	Train_loss: 0.1872	Eval_AUC: 0.8392
Epoch 33 Global_step 2701000	Train_loss: 0.1854	Eval_AUC: 0.8401
Epoch 33 Global_step 2702000	Train_loss: 0.1856	Eval_AUC: 0.8395
Epoch 33 Global_step 2703000	Train_loss: 0.1838	Eval_AUC: 0.8385
Epoch 33 Global_step 2704000	Train_loss: 0.1907	Eval_AUC: 0.8387
Epoch 33 Global_step 2705000	Train_loss: 0.1843	Eval_AUC: 0.8376
Epoch 33 Global_step 2706000	Train_loss: 0.1918	Eval_AUC: 0.8392
Epoch 33 Global_step 2707000	Train_loss: 0.1908	Eval_AUC: 0.8380
Epoch 33 Global_step 2708000	Train_loss: 0.1895	Eval_AUC: 0.8394
Epoch 33 Global_step 2709000	Train_loss: 0.1929	Eval_AUC: 0.8407
Epoch 33 Global_step 2710000	Train_loss: 0.1870	Eval_AUC: 0.8373
Epoch 33 Global_step 2711000	Train_loss: 0.1906	Eval_AUC: 0.8407
Epoch 33 Global_step 2712000	Train_loss: 0.1910	Eval_AUC: 0.8410
Epoch 33 Global_step 2713000	Train_loss: 0.1926	Eval_AUC: 0.8409
Epoch 33 Global_step 2714000	Train_loss: 0.1934	Eval_AUC: 0.8399
Epoch 33 Global_step 2715000	Train_loss: 0.1876	Eval_AUC: 0.8400
Epoch 33 Global_step 2716000	Train_loss: 0.2000	Eval_AUC: 0.8403
Epoch 33 Global_step 2717000	Train_loss: 0.2016	Eval_AUC: 0.8400
Epoch 33 Global_step 2718000	Train_loss: 0.1920	Eval_AUC: 0.8370
Epoch 33 Global_step 2719000	Train_loss: 0.1981	Eval_AUC: 0.8361
Epoch 33 Global_step 2720000	Train_loss: 0.2008	Eval_AUC: 0.8371
Epoch 33 Global_step 2721000	Train_loss: 0.1981	Eval_AUC: 0.8377
Epoch 33 Global_step 2722000	Train_loss: 0.1967	Eval_AUC: 0.8375
Epoch 33 Global_step 2723000	Train_loss: 0.1955	Eval_AUC: 0.8393
Epoch 33 Global_step 2724000	Train_loss: 0.2035	Eval_AUC: 0.8392
Epoch 33 Global_step 2725000	Train_loss: 0.1964	Eval_AUC: 0.8396
Epoch 33 Global_step 2726000	Train_loss: 0.2029	Eval_AUC: 0.8380
Epoch 33 Global_step 2727000	Train_loss: 0.2039	Eval_AUC: 0.8397
Epoch 33 Global_step 2728000	Train_loss: 0.2033	Eval_AUC: 0.8386
Epoch 33 Global_step 2729000	Train_loss: 0.1991	Eval_AUC: 0.8395
Epoch 33 Global_step 2730000	Train_loss: 0.2022	Eval_AUC: 0.8394
Epoch 33 Global_step 2731000	Train_loss: 0.2031	Eval_AUC: 0.8395
Epoch 33 Global_step 2732000	Train_loss: 0.2005	Eval_AUC: 0.8408
Epoch 33 Global_step 2733000	Train_loss: 0.2030	Eval_AUC: 0.8382
Epoch 33 Global_step 2734000	Train_loss: 0.2051	Eval_AUC: 0.8403
Epoch 33 Global_step 2735000	Train_loss: 0.1964	Eval_AUC: 0.8395
Epoch 33 Global_step 2736000	Train_loss: 0.1993	Eval_AUC: 0.8405
Epoch 33 Global_step 2737000	Train_loss: 0.2026	Eval_AUC: 0.8399
Epoch 33 Global_step 2738000	Train_loss: 0.2077	Eval_AUC: 0.8393
Epoch 33 Global_step 2739000	Train_loss: 0.2026	Eval_AUC: 0.8381
Epoch 33 Global_step 2740000	Train_loss: 0.2043	Eval_AUC: 0.8396
Epoch 33 Global_step 2741000	Train_loss: 0.2037	Eval_AUC: 0.8416
Epoch 33 Global_step 2742000	Train_loss: 0.2073	Eval_AUC: 0.8393
Epoch 33 Global_step 2743000	Train_loss: 0.2013	Eval_AUC: 0.8397
Epoch 33 Global_step 2744000	Train_loss: 0.2144	Eval_AUC: 0.8403
Epoch 33 Global_step 2745000	Train_loss: 0.2070	Eval_AUC: 0.8407
Epoch 33 Global_step 2746000	Train_loss: 0.2053	Eval_AUC: 0.8381
Epoch 33 Global_step 2747000	Train_loss: 0.2060	Eval_AUC: 0.8395
Epoch 33 Global_step 2748000	Train_loss: 0.2076	Eval_AUC: 0.8423
Epoch 33 Global_step 2749000	Train_loss: 0.2099	Eval_AUC: 0.8395
Epoch 33 Global_step 2750000	Train_loss: 0.2092	Eval_AUC: 0.8404
Epoch 33 Global_step 2751000	Train_loss: 0.2169	Eval_AUC: 0.8404
Epoch 33 Global_step 2752000	Train_loss: 0.2145	Eval_AUC: 0.8391
Epoch 33 Global_step 2753000	Train_loss: 0.2148	Eval_AUC: 0.8429
Epoch 33 Global_step 2754000	Train_loss: 0.2148	Eval_AUC: 0.8374
Epoch 33 Global_step 2755000	Train_loss: 0.2077	Eval_AUC: 0.8404
Epoch 33 Global_step 2756000	Train_loss: 0.2096	Eval_AUC: 0.8418
Epoch 33 Global_step 2757000	Train_loss: 0.2145	Eval_AUC: 0.8414
Epoch 33 Global_step 2758000	Train_loss: 0.2107	Eval_AUC: 0.8405
Epoch 33 Global_step 2759000	Train_loss: 0.2169	Eval_AUC: 0.8406
Epoch 33 Global_step 2760000	Train_loss: 0.2086	Eval_AUC: 0.8408
Epoch 33 Global_step 2761000	Train_loss: 0.2168	Eval_AUC: 0.8402
Epoch 33 Global_step 2762000	Train_loss: 0.2133	Eval_AUC: 0.8406
Epoch 33 Global_step 2763000	Train_loss: 0.2172	Eval_AUC: 0.8404
Epoch 33 Global_step 2764000	Train_loss: 0.2153	Eval_AUC: 0.8396
Epoch 33 Global_step 2765000	Train_loss: 0.2179	Eval_AUC: 0.8386
Epoch 33 Global_step 2766000	Train_loss: 0.2171	Eval_AUC: 0.8420
Epoch 33 Global_step 2767000	Train_loss: 0.2175	Eval_AUC: 0.8405
Epoch 33 Global_step 2768000	Train_loss: 0.2161	Eval_AUC: 0.8439
Epoch 33 Global_step 2769000	Train_loss: 0.2209	Eval_AUC: 0.8419
Epoch 33 Global_step 2770000	Train_loss: 0.2218	Eval_AUC: 0.8406
Epoch 33 Global_step 2771000	Train_loss: 0.2189	Eval_AUC: 0.8404
Epoch 33 DONE	Cost time: 29413.36
Epoch 34 Global_step 2772000	Train_loss: 0.0313	Eval_AUC: 0.8417
Epoch 34 Global_step 2773000	Train_loss: 0.1717	Eval_AUC: 0.8418
Epoch 34 Global_step 2774000	Train_loss: 0.1721	Eval_AUC: 0.8411
Epoch 34 Global_step 2775000	Train_loss: 0.1749	Eval_AUC: 0.8405
Epoch 34 Global_step 2776000	Train_loss: 0.1750	Eval_AUC: 0.8400
Epoch 34 Global_step 2777000	Train_loss: 0.1781	Eval_AUC: 0.8413
Epoch 34 Global_step 2778000	Train_loss: 0.1719	Eval_AUC: 0.8372
Epoch 34 Global_step 2779000	Train_loss: 0.1764	Eval_AUC: 0.8392
Epoch 34 Global_step 2780000	Train_loss: 0.1786	Eval_AUC: 0.8401
Epoch 34 Global_step 2781000	Train_loss: 0.1815	Eval_AUC: 0.8408
Epoch 34 Global_step 2782000	Train_loss: 0.1783	Eval_AUC: 0.8377
Epoch 34 Global_step 2783000	Train_loss: 0.1794	Eval_AUC: 0.8387
Epoch 34 Global_step 2784000	Train_loss: 0.1808	Eval_AUC: 0.8403
Epoch 34 Global_step 2785000	Train_loss: 0.1821	Eval_AUC: 0.8395
Epoch 34 Global_step 2786000	Train_loss: 0.1765	Eval_AUC: 0.8389
Epoch 34 Global_step 2787000	Train_loss: 0.1798	Eval_AUC: 0.8384
Epoch 34 Global_step 2788000	Train_loss: 0.1813	Eval_AUC: 0.8389
Epoch 34 Global_step 2789000	Train_loss: 0.1843	Eval_AUC: 0.8394
Epoch 34 Global_step 2790000	Train_loss: 0.1813	Eval_AUC: 0.8394
Epoch 34 Global_step 2791000	Train_loss: 0.1886	Eval_AUC: 0.8371
Epoch 34 Global_step 2792000	Train_loss: 0.1902	Eval_AUC: 0.8385
Epoch 34 Global_step 2793000	Train_loss: 0.1805	Eval_AUC: 0.8382
Epoch 34 Global_step 2794000	Train_loss: 0.1886	Eval_AUC: 0.8391
Epoch 34 Global_step 2795000	Train_loss: 0.1863	Eval_AUC: 0.8391
Epoch 34 Global_step 2796000	Train_loss: 0.1888	Eval_AUC: 0.8411
Epoch 34 Global_step 2797000	Train_loss: 0.1870	Eval_AUC: 0.8387
Epoch 34 Global_step 2798000	Train_loss: 0.1945	Eval_AUC: 0.8401
Epoch 34 Global_step 2799000	Train_loss: 0.1895	Eval_AUC: 0.8399
Epoch 34 Global_step 2800000	Train_loss: 0.1924	Eval_AUC: 0.8371
Epoch 34 Global_step 2801000	Train_loss: 0.1861	Eval_AUC: 0.8368
Epoch 34 Global_step 2802000	Train_loss: 0.1946	Eval_AUC: 0.8381
Epoch 34 Global_step 2803000	Train_loss: 0.1974	Eval_AUC: 0.8412
Epoch 34 Global_step 2804000	Train_loss: 0.1940	Eval_AUC: 0.8373
Epoch 34 Global_step 2805000	Train_loss: 0.1981	Eval_AUC: 0.8392
Epoch 34 Global_step 2806000	Train_loss: 0.2008	Eval_AUC: 0.8388
Epoch 34 Global_step 2807000	Train_loss: 0.1966	Eval_AUC: 0.8377
Epoch 34 Global_step 2808000	Train_loss: 0.1961	Eval_AUC: 0.8364
Epoch 34 Global_step 2809000	Train_loss: 0.2000	Eval_AUC: 0.8349
Epoch 34 Global_step 2810000	Train_loss: 0.1967	Eval_AUC: 0.8384
Epoch 34 Global_step 2811000	Train_loss: 0.1968	Eval_AUC: 0.8393
Epoch 34 Global_step 2812000	Train_loss: 0.1969	Eval_AUC: 0.8381
Epoch 34 Global_step 2813000	Train_loss: 0.2001	Eval_AUC: 0.8390
Epoch 34 Global_step 2814000	Train_loss: 0.1979	Eval_AUC: 0.8374
Epoch 34 Global_step 2815000	Train_loss: 0.1970	Eval_AUC: 0.8391
Epoch 34 Global_step 2816000	Train_loss: 0.2039	Eval_AUC: 0.8371
Epoch 34 Global_step 2817000	Train_loss: 0.2067	Eval_AUC: 0.8391
Epoch 34 Global_step 2818000	Train_loss: 0.2022	Eval_AUC: 0.8391
Epoch 34 Global_step 2819000	Train_loss: 0.2015	Eval_AUC: 0.8399
Epoch 34 Global_step 2820000	Train_loss: 0.2035	Eval_AUC: 0.8406
Epoch 34 Global_step 2821000	Train_loss: 0.1999	Eval_AUC: 0.8400
Epoch 34 Global_step 2822000	Train_loss: 0.2083	Eval_AUC: 0.8374
Epoch 34 Global_step 2823000	Train_loss: 0.2054	Eval_AUC: 0.8388
Epoch 34 Global_step 2824000	Train_loss: 0.2014	Eval_AUC: 0.8395
Epoch 34 Global_step 2825000	Train_loss: 0.2071	Eval_AUC: 0.8407
Epoch 34 Global_step 2826000	Train_loss: 0.2077	Eval_AUC: 0.8405
Epoch 34 Global_step 2827000	Train_loss: 0.2009	Eval_AUC: 0.8413
Epoch 34 Global_step 2828000	Train_loss: 0.2044	Eval_AUC: 0.8406
Epoch 34 Global_step 2829000	Train_loss: 0.2064	Eval_AUC: 0.8387
Epoch 34 Global_step 2830000	Train_loss: 0.2042	Eval_AUC: 0.8387
Epoch 34 Global_step 2831000	Train_loss: 0.2132	Eval_AUC: 0.8383
Epoch 34 Global_step 2832000	Train_loss: 0.2081	Eval_AUC: 0.8381
Epoch 34 Global_step 2833000	Train_loss: 0.2091	Eval_AUC: 0.8398
Epoch 34 Global_step 2834000	Train_loss: 0.2064	Eval_AUC: 0.8393
Epoch 34 Global_step 2835000	Train_loss: 0.2040	Eval_AUC: 0.8403
Epoch 34 Global_step 2836000	Train_loss: 0.2125	Eval_AUC: 0.8421
Epoch 34 Global_step 2837000	Train_loss: 0.2077	Eval_AUC: 0.8398
Epoch 34 Global_step 2838000	Train_loss: 0.2063	Eval_AUC: 0.8410
Epoch 34 Global_step 2839000	Train_loss: 0.2084	Eval_AUC: 0.8401
Epoch 34 Global_step 2840000	Train_loss: 0.2147	Eval_AUC: 0.8372
Epoch 34 Global_step 2841000	Train_loss: 0.2158	Eval_AUC: 0.8406
Epoch 34 Global_step 2842000	Train_loss: 0.2105	Eval_AUC: 0.8392
Epoch 34 Global_step 2843000	Train_loss: 0.2164	Eval_AUC: 0.8386
Epoch 34 Global_step 2844000	Train_loss: 0.2130	Eval_AUC: 0.8386
Epoch 34 Global_step 2845000	Train_loss: 0.2095	Eval_AUC: 0.8377
Epoch 34 Global_step 2846000	Train_loss: 0.2145	Eval_AUC: 0.8392
Epoch 34 Global_step 2847000	Train_loss: 0.2121	Eval_AUC: 0.8383
Epoch 34 Global_step 2848000	Train_loss: 0.2119	Eval_AUC: 0.8384
Epoch 34 Global_step 2849000	Train_loss: 0.2120	Eval_AUC: 0.8385
Epoch 34 Global_step 2850000	Train_loss: 0.2158	Eval_AUC: 0.8384
Epoch 34 Global_step 2851000	Train_loss: 0.2142	Eval_AUC: 0.8402
Epoch 34 Global_step 2852000	Train_loss: 0.2090	Eval_AUC: 0.8382
Epoch 34 Global_step 2853000	Train_loss: 0.2120	Eval_AUC: 0.8390
Epoch 34 DONE	Cost time: 30245.18
Epoch 35 Global_step 2854000	Train_loss: 0.1188	Eval_AUC: 0.8394
Epoch 35 Global_step 2855000	Train_loss: 0.1693	Eval_AUC: 0.8393
Epoch 35 Global_step 2856000	Train_loss: 0.1683	Eval_AUC: 0.8413
Epoch 35 Global_step 2857000	Train_loss: 0.1677	Eval_AUC: 0.8400
Epoch 35 Global_step 2858000	Train_loss: 0.1731	Eval_AUC: 0.8391
Epoch 35 Global_step 2859000	Train_loss: 0.1731	Eval_AUC: 0.8374
Epoch 35 Global_step 2860000	Train_loss: 0.1722	Eval_AUC: 0.8393
Epoch 35 Global_step 2861000	Train_loss: 0.1749	Eval_AUC: 0.8381
Epoch 35 Global_step 2862000	Train_loss: 0.1759	Eval_AUC: 0.8362
Epoch 35 Global_step 2863000	Train_loss: 0.1705	Eval_AUC: 0.8365
Epoch 35 Global_step 2864000	Train_loss: 0.1744	Eval_AUC: 0.8399
Epoch 35 Global_step 2865000	Train_loss: 0.1687	Eval_AUC: 0.8375
Epoch 35 Global_step 2866000	Train_loss: 0.1697	Eval_AUC: 0.8357
Epoch 35 Global_step 2867000	Train_loss: 0.1721	Eval_AUC: 0.8399
Epoch 35 Global_step 2868000	Train_loss: 0.1776	Eval_AUC: 0.8356
Epoch 35 Global_step 2869000	Train_loss: 0.1799	Eval_AUC: 0.8357
Epoch 35 Global_step 2870000	Train_loss: 0.1757	Eval_AUC: 0.8350
Epoch 35 Global_step 2871000	Train_loss: 0.1755	Eval_AUC: 0.8358
Epoch 35 Global_step 2872000	Train_loss: 0.1803	Eval_AUC: 0.8360
Epoch 35 Global_step 2873000	Train_loss: 0.1824	Eval_AUC: 0.8384
Epoch 35 Global_step 2874000	Train_loss: 0.1773	Eval_AUC: 0.8363
Epoch 35 Global_step 2875000	Train_loss: 0.1849	Eval_AUC: 0.8398
Epoch 35 Global_step 2876000	Train_loss: 0.1842	Eval_AUC: 0.8381
Epoch 35 Global_step 2877000	Train_loss: 0.1811	Eval_AUC: 0.8358
Epoch 35 Global_step 2878000	Train_loss: 0.1824	Eval_AUC: 0.8381
Epoch 35 Global_step 2879000	Train_loss: 0.1888	Eval_AUC: 0.8365
Epoch 35 Global_step 2880000	Train_loss: 0.1928	Eval_AUC: 0.8360
Epoch 35 Global_step 2881000	Train_loss: 0.1830	Eval_AUC: 0.8389
Epoch 35 Global_step 2882000	Train_loss: 0.1918	Eval_AUC: 0.8382
Epoch 35 Global_step 2883000	Train_loss: 0.1900	Eval_AUC: 0.8373
Epoch 35 Global_step 2884000	Train_loss: 0.1879	Eval_AUC: 0.8373
Epoch 35 Global_step 2885000	Train_loss: 0.1984	Eval_AUC: 0.8371
Epoch 35 Global_step 2886000	Train_loss: 0.1878	Eval_AUC: 0.8353
Epoch 35 Global_step 2887000	Train_loss: 0.1908	Eval_AUC: 0.8379
Epoch 35 Global_step 2888000	Train_loss: 0.1916	Eval_AUC: 0.8387
Epoch 35 Global_step 2889000	Train_loss: 0.1942	Eval_AUC: 0.8370
Epoch 35 Global_step 2890000	Train_loss: 0.1939	Eval_AUC: 0.8364
Epoch 35 Global_step 2891000	Train_loss: 0.1902	Eval_AUC: 0.8373
Epoch 35 Global_step 2892000	Train_loss: 0.1957	Eval_AUC: 0.8386
Epoch 35 Global_step 2893000	Train_loss: 0.1870	Eval_AUC: 0.8356
Epoch 35 Global_step 2894000	Train_loss: 0.1961	Eval_AUC: 0.8363
Epoch 35 Global_step 2895000	Train_loss: 0.1956	Eval_AUC: 0.8366
Epoch 35 Global_step 2896000	Train_loss: 0.1934	Eval_AUC: 0.8358
Epoch 35 Global_step 2897000	Train_loss: 0.1973	Eval_AUC: 0.8368
Epoch 35 Global_step 2898000	Train_loss: 0.1927	Eval_AUC: 0.8363
Epoch 35 Global_step 2899000	Train_loss: 0.1921	Eval_AUC: 0.8383
Epoch 35 Global_step 2900000	Train_loss: 0.1981	Eval_AUC: 0.8374
Epoch 35 Global_step 2901000	Train_loss: 0.1966	Eval_AUC: 0.8381
Epoch 35 Global_step 2902000	Train_loss: 0.1954	Eval_AUC: 0.8379
Epoch 35 Global_step 2903000	Train_loss: 0.1959	Eval_AUC: 0.8391
Epoch 35 Global_step 2904000	Train_loss: 0.1976	Eval_AUC: 0.8370
Epoch 35 Global_step 2905000	Train_loss: 0.2009	Eval_AUC: 0.8371
Epoch 35 Global_step 2906000	Train_loss: 0.2021	Eval_AUC: 0.8405
Epoch 35 Global_step 2907000	Train_loss: 0.2035	Eval_AUC: 0.8375
Epoch 35 Global_step 2908000	Train_loss: 0.2021	Eval_AUC: 0.8398
Epoch 35 Global_step 2909000	Train_loss: 0.1976	Eval_AUC: 0.8392
Epoch 35 Global_step 2910000	Train_loss: 0.1963	Eval_AUC: 0.8436
Epoch 35 Global_step 2911000	Train_loss: 0.1991	Eval_AUC: 0.8415
Epoch 35 Global_step 2912000	Train_loss: 0.2007	Eval_AUC: 0.8391
Epoch 35 Global_step 2913000	Train_loss: 0.2083	Eval_AUC: 0.8385
Epoch 35 Global_step 2914000	Train_loss: 0.1998	Eval_AUC: 0.8399
Epoch 35 Global_step 2915000	Train_loss: 0.2105	Eval_AUC: 0.8375
Epoch 35 Global_step 2916000	Train_loss: 0.2076	Eval_AUC: 0.8397
Epoch 35 Global_step 2917000	Train_loss: 0.2047	Eval_AUC: 0.8408
Epoch 35 Global_step 2918000	Train_loss: 0.2100	Eval_AUC: 0.8399
Epoch 35 Global_step 2919000	Train_loss: 0.2042	Eval_AUC: 0.8399
Epoch 35 Global_step 2920000	Train_loss: 0.2058	Eval_AUC: 0.8385
Epoch 35 Global_step 2921000	Train_loss: 0.2024	Eval_AUC: 0.8399
Epoch 35 Global_step 2922000	Train_loss: 0.1992	Eval_AUC: 0.8399
Epoch 35 Global_step 2923000	Train_loss: 0.2021	Eval_AUC: 0.8396
Epoch 35 Global_step 2924000	Train_loss: 0.2045	Eval_AUC: 0.8416
Epoch 35 Global_step 2925000	Train_loss: 0.2068	Eval_AUC: 0.8379
Epoch 35 Global_step 2926000	Train_loss: 0.2075	Eval_AUC: 0.8389
Epoch 35 Global_step 2927000	Train_loss: 0.2074	Eval_AUC: 0.8401
Epoch 35 Global_step 2928000	Train_loss: 0.2087	Eval_AUC: 0.8391
Epoch 35 Global_step 2929000	Train_loss: 0.2079	Eval_AUC: 0.8390
Epoch 35 Global_step 2930000	Train_loss: 0.2067	Eval_AUC: 0.8390
Epoch 35 Global_step 2931000	Train_loss: 0.2050	Eval_AUC: 0.8378
Epoch 35 Global_step 2932000	Train_loss: 0.2092	Eval_AUC: 0.8384
Epoch 35 Global_step 2933000	Train_loss: 0.2060	Eval_AUC: 0.8413
Epoch 35 Global_step 2934000	Train_loss: 0.2084	Eval_AUC: 0.8400
Epoch 35 DONE	Cost time: 31090.22
Epoch 36 Global_step 2935000	Train_loss: 0.0241	Eval_AUC: 0.8398
Epoch 36 Global_step 2936000	Train_loss: 0.1631	Eval_AUC: 0.8410
Epoch 36 Global_step 2937000	Train_loss: 0.1720	Eval_AUC: 0.8387
Epoch 36 Global_step 2938000	Train_loss: 0.1637	Eval_AUC: 0.8389
Epoch 36 Global_step 2939000	Train_loss: 0.1634	Eval_AUC: 0.8380
Epoch 36 Global_step 2940000	Train_loss: 0.1645	Eval_AUC: 0.8386
Epoch 36 Global_step 2941000	Train_loss: 0.1674	Eval_AUC: 0.8398
Epoch 36 Global_step 2942000	Train_loss: 0.1690	Eval_AUC: 0.8389
Epoch 36 Global_step 2943000	Train_loss: 0.1709	Eval_AUC: 0.8375
Epoch 36 Global_step 2944000	Train_loss: 0.1755	Eval_AUC: 0.8387
Epoch 36 Global_step 2945000	Train_loss: 0.1712	Eval_AUC: 0.8393
Epoch 36 Global_step 2946000	Train_loss: 0.1747	Eval_AUC: 0.8375
Epoch 36 Global_step 2947000	Train_loss: 0.1698	Eval_AUC: 0.8354
Epoch 36 Global_step 2948000	Train_loss: 0.1706	Eval_AUC: 0.8380
Epoch 36 Global_step 2949000	Train_loss: 0.1711	Eval_AUC: 0.8368
Epoch 36 Global_step 2950000	Train_loss: 0.1728	Eval_AUC: 0.8388
Epoch 36 Global_step 2951000	Train_loss: 0.1718	Eval_AUC: 0.8373
Epoch 36 Global_step 2952000	Train_loss: 0.1748	Eval_AUC: 0.8376
Epoch 36 Global_step 2953000	Train_loss: 0.1746	Eval_AUC: 0.8366
Epoch 36 Global_step 2954000	Train_loss: 0.1759	Eval_AUC: 0.8369
Epoch 36 Global_step 2955000	Train_loss: 0.1777	Eval_AUC: 0.8373
Epoch 36 Global_step 2956000	Train_loss: 0.1775	Eval_AUC: 0.8386
Epoch 36 Global_step 2957000	Train_loss: 0.1808	Eval_AUC: 0.8368
Epoch 36 Global_step 2958000	Train_loss: 0.1783	Eval_AUC: 0.8347
Epoch 36 Global_step 2959000	Train_loss: 0.1813	Eval_AUC: 0.8370
Epoch 36 Global_step 2960000	Train_loss: 0.1821	Eval_AUC: 0.8377
Epoch 36 Global_step 2961000	Train_loss: 0.1841	Eval_AUC: 0.8379
Epoch 36 Global_step 2962000	Train_loss: 0.1813	Eval_AUC: 0.8379
Epoch 36 Global_step 2963000	Train_loss: 0.1780	Eval_AUC: 0.8380
Epoch 36 Global_step 2964000	Train_loss: 0.1844	Eval_AUC: 0.8387
Epoch 36 Global_step 2965000	Train_loss: 0.1880	Eval_AUC: 0.8385
Epoch 36 Global_step 2966000	Train_loss: 0.1840	Eval_AUC: 0.8386
Epoch 36 Global_step 2967000	Train_loss: 0.1798	Eval_AUC: 0.8369
Epoch 36 Global_step 2968000	Train_loss: 0.1832	Eval_AUC: 0.8378
Epoch 36 Global_step 2969000	Train_loss: 0.1815	Eval_AUC: 0.8365
Epoch 36 Global_step 2970000	Train_loss: 0.1860	Eval_AUC: 0.8384
Epoch 36 Global_step 2971000	Train_loss: 0.1884	Eval_AUC: 0.8371
Epoch 36 Global_step 2972000	Train_loss: 0.1858	Eval_AUC: 0.8374
Epoch 36 Global_step 2973000	Train_loss: 0.1860	Eval_AUC: 0.8380
Epoch 36 Global_step 2974000	Train_loss: 0.1868	Eval_AUC: 0.8368
Epoch 36 Global_step 2975000	Train_loss: 0.1850	Eval_AUC: 0.8368
Epoch 36 Global_step 2976000	Train_loss: 0.1872	Eval_AUC: 0.8371
Epoch 36 Global_step 2977000	Train_loss: 0.1861	Eval_AUC: 0.8370
Epoch 36 Global_step 2978000	Train_loss: 0.1866	Eval_AUC: 0.8384
Epoch 36 Global_step 2979000	Train_loss: 0.1898	Eval_AUC: 0.8377
Epoch 36 Global_step 2980000	Train_loss: 0.1932	Eval_AUC: 0.8408
Epoch 36 Global_step 2981000	Train_loss: 0.1970	Eval_AUC: 0.8384
Epoch 36 Global_step 2982000	Train_loss: 0.1879	Eval_AUC: 0.8380
Epoch 36 Global_step 2983000	Train_loss: 0.1925	Eval_AUC: 0.8360
Epoch 36 Global_step 2984000	Train_loss: 0.1907	Eval_AUC: 0.8381
Epoch 36 Global_step 2985000	Train_loss: 0.1896	Eval_AUC: 0.8363
Epoch 36 Global_step 2986000	Train_loss: 0.1940	Eval_AUC: 0.8380
Epoch 36 Global_step 2987000	Train_loss: 0.1930	Eval_AUC: 0.8383
Epoch 36 Global_step 2988000	Train_loss: 0.1959	Eval_AUC: 0.8351
Epoch 36 Global_step 2989000	Train_loss: 0.1945	Eval_AUC: 0.8360
Epoch 36 Global_step 2990000	Train_loss: 0.1988	Eval_AUC: 0.8374
Epoch 36 Global_step 2991000	Train_loss: 0.2039	Eval_AUC: 0.8383
Epoch 36 Global_step 2992000	Train_loss: 0.1973	Eval_AUC: 0.8371
Epoch 36 Global_step 2993000	Train_loss: 0.1982	Eval_AUC: 0.8394
Epoch 36 Global_step 2994000	Train_loss: 0.1975	Eval_AUC: 0.8368
Epoch 36 Global_step 2995000	Train_loss: 0.1984	Eval_AUC: 0.8379
Epoch 36 Global_step 2996000	Train_loss: 0.1992	Eval_AUC: 0.8387
Epoch 36 Global_step 2997000	Train_loss: 0.1991	Eval_AUC: 0.8375
Epoch 36 Global_step 2998000	Train_loss: 0.2005	Eval_AUC: 0.8358
Epoch 36 Global_step 2999000	Train_loss: 0.2056	Eval_AUC: 0.8383
Epoch 36 Global_step 3000000	Train_loss: 0.2013	Eval_AUC: 0.8380
Epoch 36 Global_step 3001000	Train_loss: 0.1964	Eval_AUC: 0.8381
Epoch 36 Global_step 3002000	Train_loss: 0.1985	Eval_AUC: 0.8407
Epoch 36 Global_step 3003000	Train_loss: 0.2064	Eval_AUC: 0.8378
Epoch 36 Global_step 3004000	Train_loss: 0.2025	Eval_AUC: 0.8399
Epoch 36 Global_step 3005000	Train_loss: 0.2017	Eval_AUC: 0.8374
Epoch 36 Global_step 3006000	Train_loss: 0.2025	Eval_AUC: 0.8381
Epoch 36 Global_step 3007000	Train_loss: 0.2046	Eval_AUC: 0.8374
Epoch 36 Global_step 3008000	Train_loss: 0.2008	Eval_AUC: 0.8378
Epoch 36 Global_step 3009000	Train_loss: 0.2048	Eval_AUC: 0.8405
Epoch 36 Global_step 3010000	Train_loss: 0.2027	Eval_AUC: 0.8393
Epoch 36 Global_step 3011000	Train_loss: 0.2028	Eval_AUC: 0.8383
Epoch 36 Global_step 3012000	Train_loss: 0.2068	Eval_AUC: 0.8382
Epoch 36 Global_step 3013000	Train_loss: 0.2037	Eval_AUC: 0.8392
Epoch 36 Global_step 3014000	Train_loss: 0.2035	Eval_AUC: 0.8405
Epoch 36 Global_step 3015000	Train_loss: 0.2098	Eval_AUC: 0.8356
Epoch 36 Global_step 3016000	Train_loss: 0.2033	Eval_AUC: 0.8385
Epoch 36 DONE	Cost time: 31918.29
Epoch 37 Global_step 3017000	Train_loss: 0.1012	Eval_AUC: 0.8395
Epoch 37 Global_step 3018000	Train_loss: 0.1616	Eval_AUC: 0.8386
Epoch 37 Global_step 3019000	Train_loss: 0.1626	Eval_AUC: 0.8379
Epoch 37 Global_step 3020000	Train_loss: 0.1639	Eval_AUC: 0.8365
Epoch 37 Global_step 3021000	Train_loss: 0.1658	Eval_AUC: 0.8370
Epoch 37 Global_step 3022000	Train_loss: 0.1576	Eval_AUC: 0.8388
Epoch 37 Global_step 3023000	Train_loss: 0.1652	Eval_AUC: 0.8367
Epoch 37 Global_step 3024000	Train_loss: 0.1647	Eval_AUC: 0.8354
Epoch 37 Global_step 3025000	Train_loss: 0.1663	Eval_AUC: 0.8375
Epoch 37 Global_step 3026000	Train_loss: 0.1646	Eval_AUC: 0.8371
Epoch 37 Global_step 3027000	Train_loss: 0.1707	Eval_AUC: 0.8358
Epoch 37 Global_step 3028000	Train_loss: 0.1691	Eval_AUC: 0.8381
Epoch 37 Global_step 3029000	Train_loss: 0.1678	Eval_AUC: 0.8365
Epoch 37 Global_step 3030000	Train_loss: 0.1641	Eval_AUC: 0.8367
Epoch 37 Global_step 3031000	Train_loss: 0.1684	Eval_AUC: 0.8364
Epoch 37 Global_step 3032000	Train_loss: 0.1731	Eval_AUC: 0.8387
Epoch 37 Global_step 3033000	Train_loss: 0.1694	Eval_AUC: 0.8361
Epoch 37 Global_step 3034000	Train_loss: 0.1674	Eval_AUC: 0.8373
Epoch 37 Global_step 3035000	Train_loss: 0.1740	Eval_AUC: 0.8360
Epoch 37 Global_step 3036000	Train_loss: 0.1677	Eval_AUC: 0.8329
Epoch 37 Global_step 3037000	Train_loss: 0.1735	Eval_AUC: 0.8362
Epoch 37 Global_step 3038000	Train_loss: 0.1776	Eval_AUC: 0.8347
Epoch 37 Global_step 3039000	Train_loss: 0.1718	Eval_AUC: 0.8379
Epoch 37 Global_step 3040000	Train_loss: 0.1727	Eval_AUC: 0.8381
Epoch 37 Global_step 3041000	Train_loss: 0.1727	Eval_AUC: 0.8357
Epoch 37 Global_step 3042000	Train_loss: 0.1800	Eval_AUC: 0.8330
Epoch 37 Global_step 3043000	Train_loss: 0.1785	Eval_AUC: 0.8369
Epoch 37 Global_step 3044000	Train_loss: 0.1760	Eval_AUC: 0.8354
Epoch 37 Global_step 3045000	Train_loss: 0.1792	Eval_AUC: 0.8373
Epoch 37 Global_step 3046000	Train_loss: 0.1773	Eval_AUC: 0.8378
Epoch 37 Global_step 3047000	Train_loss: 0.1812	Eval_AUC: 0.8382
Epoch 37 Global_step 3048000	Train_loss: 0.1769	Eval_AUC: 0.8352
Epoch 37 Global_step 3049000	Train_loss: 0.1786	Eval_AUC: 0.8357
Epoch 37 Global_step 3050000	Train_loss: 0.1820	Eval_AUC: 0.8358
Epoch 37 Global_step 3051000	Train_loss: 0.1776	Eval_AUC: 0.8352
Epoch 37 Global_step 3052000	Train_loss: 0.1794	Eval_AUC: 0.8347
Epoch 37 Global_step 3053000	Train_loss: 0.1911	Eval_AUC: 0.8361
Epoch 37 Global_step 3054000	Train_loss: 0.1806	Eval_AUC: 0.8385
Epoch 37 Global_step 3055000	Train_loss: 0.1858	Eval_AUC: 0.8367
Epoch 37 Global_step 3056000	Train_loss: 0.1769	Eval_AUC: 0.8359
Epoch 37 Global_step 3057000	Train_loss: 0.1835	Eval_AUC: 0.8372
Epoch 37 Global_step 3058000	Train_loss: 0.1803	Eval_AUC: 0.8356
Epoch 37 Global_step 3059000	Train_loss: 0.1856	Eval_AUC: 0.8387
Epoch 37 Global_step 3060000	Train_loss: 0.1840	Eval_AUC: 0.8377
Epoch 37 Global_step 3061000	Train_loss: 0.1921	Eval_AUC: 0.8363
Epoch 37 Global_step 3062000	Train_loss: 0.1826	Eval_AUC: 0.8366
Epoch 37 Global_step 3063000	Train_loss: 0.1875	Eval_AUC: 0.8375
Epoch 37 Global_step 3064000	Train_loss: 0.1840	Eval_AUC: 0.8368
Epoch 37 Global_step 3065000	Train_loss: 0.1849	Eval_AUC: 0.8365
Epoch 37 Global_step 3066000	Train_loss: 0.1874	Eval_AUC: 0.8381
Epoch 37 Global_step 3067000	Train_loss: 0.1886	Eval_AUC: 0.8371
Epoch 37 Global_step 3068000	Train_loss: 0.1915	Eval_AUC: 0.8368
Epoch 37 Global_step 3069000	Train_loss: 0.1867	Eval_AUC: 0.8352
Epoch 37 Global_step 3070000	Train_loss: 0.1858	Eval_AUC: 0.8358
Epoch 37 Global_step 3071000	Train_loss: 0.1917	Eval_AUC: 0.8364
Epoch 37 Global_step 3072000	Train_loss: 0.1926	Eval_AUC: 0.8363
Epoch 37 Global_step 3073000	Train_loss: 0.1980	Eval_AUC: 0.8357
Epoch 37 Global_step 3074000	Train_loss: 0.1978	Eval_AUC: 0.8361
Epoch 37 Global_step 3075000	Train_loss: 0.1953	Eval_AUC: 0.8382
Epoch 37 Global_step 3076000	Train_loss: 0.1922	Eval_AUC: 0.8379
Epoch 37 Global_step 3077000	Train_loss: 0.1939	Eval_AUC: 0.8378
Epoch 37 Global_step 3078000	Train_loss: 0.1962	Eval_AUC: 0.8376
Epoch 37 Global_step 3079000	Train_loss: 0.1949	Eval_AUC: 0.8358
Epoch 37 Global_step 3080000	Train_loss: 0.1927	Eval_AUC: 0.8360
Epoch 37 Global_step 3081000	Train_loss: 0.1970	Eval_AUC: 0.8381
Epoch 37 Global_step 3082000	Train_loss: 0.1940	Eval_AUC: 0.8357
Epoch 37 Global_step 3083000	Train_loss: 0.1956	Eval_AUC: 0.8358
Epoch 37 Global_step 3084000	Train_loss: 0.1960	Eval_AUC: 0.8338
Epoch 37 Global_step 3085000	Train_loss: 0.1959	Eval_AUC: 0.8387
Epoch 37 Global_step 3086000	Train_loss: 0.1962	Eval_AUC: 0.8347
Epoch 37 Global_step 3087000	Train_loss: 0.1916	Eval_AUC: 0.8371
Epoch 37 Global_step 3088000	Train_loss: 0.1996	Eval_AUC: 0.8357
Epoch 37 Global_step 3089000	Train_loss: 0.1962	Eval_AUC: 0.8381
Epoch 37 Global_step 3090000	Train_loss: 0.1926	Eval_AUC: 0.8399
Epoch 37 Global_step 3091000	Train_loss: 0.2000	Eval_AUC: 0.8384
Epoch 37 Global_step 3092000	Train_loss: 0.1956	Eval_AUC: 0.8375
Epoch 37 Global_step 3093000	Train_loss: 0.2060	Eval_AUC: 0.8358
Epoch 37 Global_step 3094000	Train_loss: 0.2060	Eval_AUC: 0.8379
Epoch 37 Global_step 3095000	Train_loss: 0.2031	Eval_AUC: 0.8367
Epoch 37 Global_step 3096000	Train_loss: 0.1997	Eval_AUC: 0.8369
Epoch 37 Global_step 3097000	Train_loss: 0.2022	Eval_AUC: 0.8387
Epoch 37 DONE	Cost time: 32742.56
Epoch 38 Global_step 3098000	Train_loss: 0.0145	Eval_AUC: 0.8381
Epoch 38 Global_step 3099000	Train_loss: 0.1593	Eval_AUC: 0.8373
Epoch 38 Global_step 3100000	Train_loss: 0.1539	Eval_AUC: 0.8357
Epoch 38 Global_step 3101000	Train_loss: 0.1592	Eval_AUC: 0.8382
Epoch 38 Global_step 3102000	Train_loss: 0.1569	Eval_AUC: 0.8374
Epoch 38 Global_step 3103000	Train_loss: 0.1607	Eval_AUC: 0.8350
Epoch 38 Global_step 3104000	Train_loss: 0.1646	Eval_AUC: 0.8364
Epoch 38 Global_step 3105000	Train_loss: 0.1556	Eval_AUC: 0.8375
Epoch 38 Global_step 3106000	Train_loss: 0.1627	Eval_AUC: 0.8362
Epoch 38 Global_step 3107000	Train_loss: 0.1614	Eval_AUC: 0.8380
Epoch 38 Global_step 3108000	Train_loss: 0.1620	Eval_AUC: 0.8374
Epoch 38 Global_step 3109000	Train_loss: 0.1635	Eval_AUC: 0.8366
Epoch 38 Global_step 3110000	Train_loss: 0.1644	Eval_AUC: 0.8337
Epoch 38 Global_step 3111000	Train_loss: 0.1643	Eval_AUC: 0.8352
Epoch 38 Global_step 3112000	Train_loss: 0.1607	Eval_AUC: 0.8372
Epoch 38 Global_step 3113000	Train_loss: 0.1615	Eval_AUC: 0.8369
Epoch 38 Global_step 3114000	Train_loss: 0.1690	Eval_AUC: 0.8352
Epoch 38 Global_step 3115000	Train_loss: 0.1672	Eval_AUC: 0.8367
Epoch 38 Global_step 3116000	Train_loss: 0.1650	Eval_AUC: 0.8341
Epoch 38 Global_step 3117000	Train_loss: 0.1681	Eval_AUC: 0.8373
Epoch 38 Global_step 3118000	Train_loss: 0.1704	Eval_AUC: 0.8368
Epoch 38 Global_step 3119000	Train_loss: 0.1720	Eval_AUC: 0.8366
Epoch 38 Global_step 3120000	Train_loss: 0.1677	Eval_AUC: 0.8331
Epoch 38 Global_step 3121000	Train_loss: 0.1678	Eval_AUC: 0.8360
Epoch 38 Global_step 3122000	Train_loss: 0.1723	Eval_AUC: 0.8360
Epoch 38 Global_step 3123000	Train_loss: 0.1723	Eval_AUC: 0.8336
Epoch 38 Global_step 3124000	Train_loss: 0.1724	Eval_AUC: 0.8380
Epoch 38 Global_step 3125000	Train_loss: 0.1723	Eval_AUC: 0.8343
Epoch 38 Global_step 3126000	Train_loss: 0.1711	Eval_AUC: 0.8360
Epoch 38 Global_step 3127000	Train_loss: 0.1693	Eval_AUC: 0.8351
Epoch 38 Global_step 3128000	Train_loss: 0.1741	Eval_AUC: 0.8367
Epoch 38 Global_step 3129000	Train_loss: 0.1729	Eval_AUC: 0.8365
Epoch 38 Global_step 3130000	Train_loss: 0.1754	Eval_AUC: 0.8354
Epoch 38 Global_step 3131000	Train_loss: 0.1743	Eval_AUC: 0.8352
Epoch 38 Global_step 3132000	Train_loss: 0.1750	Eval_AUC: 0.8354
Epoch 38 Global_step 3133000	Train_loss: 0.1781	Eval_AUC: 0.8362
Epoch 38 Global_step 3134000	Train_loss: 0.1793	Eval_AUC: 0.8356
Epoch 38 Global_step 3135000	Train_loss: 0.1810	Eval_AUC: 0.8350
Epoch 38 Global_step 3136000	Train_loss: 0.1745	Eval_AUC: 0.8349
Epoch 38 Global_step 3137000	Train_loss: 0.1831	Eval_AUC: 0.8365
Epoch 38 Global_step 3138000	Train_loss: 0.1804	Eval_AUC: 0.8361
Epoch 38 Global_step 3139000	Train_loss: 0.1797	Eval_AUC: 0.8355
Epoch 38 Global_step 3140000	Train_loss: 0.1820	Eval_AUC: 0.8360
Epoch 38 Global_step 3141000	Train_loss: 0.1804	Eval_AUC: 0.8373
Epoch 38 Global_step 3142000	Train_loss: 0.1872	Eval_AUC: 0.8364
Epoch 38 Global_step 3143000	Train_loss: 0.1880	Eval_AUC: 0.8359
Epoch 38 Global_step 3144000	Train_loss: 0.1855	Eval_AUC: 0.8352
Epoch 38 Global_step 3145000	Train_loss: 0.1864	Eval_AUC: 0.8360
Epoch 38 Global_step 3146000	Train_loss: 0.1830	Eval_AUC: 0.8353
Epoch 38 Global_step 3147000	Train_loss: 0.1858	Eval_AUC: 0.8360
Epoch 38 Global_step 3148000	Train_loss: 0.1886	Eval_AUC: 0.8345
Epoch 38 Global_step 3149000	Train_loss: 0.1847	Eval_AUC: 0.8389
Epoch 38 Global_step 3150000	Train_loss: 0.1862	Eval_AUC: 0.8350
Epoch 38 Global_step 3151000	Train_loss: 0.1871	Eval_AUC: 0.8364
Epoch 38 Global_step 3152000	Train_loss: 0.1882	Eval_AUC: 0.8357
Epoch 38 Global_step 3153000	Train_loss: 0.1906	Eval_AUC: 0.8386
Epoch 38 Global_step 3154000	Train_loss: 0.1895	Eval_AUC: 0.8349
Epoch 38 Global_step 3155000	Train_loss: 0.1840	Eval_AUC: 0.8359
Epoch 38 Global_step 3156000	Train_loss: 0.1890	Eval_AUC: 0.8367
Epoch 38 Global_step 3157000	Train_loss: 0.1972	Eval_AUC: 0.8352
Epoch 38 Global_step 3158000	Train_loss: 0.1904	Eval_AUC: 0.8362
Epoch 38 Global_step 3159000	Train_loss: 0.1881	Eval_AUC: 0.8392
Epoch 38 Global_step 3160000	Train_loss: 0.1916	Eval_AUC: 0.8382
Epoch 38 Global_step 3161000	Train_loss: 0.1896	Eval_AUC: 0.8366
Epoch 38 Global_step 3162000	Train_loss: 0.1876	Eval_AUC: 0.8378
Epoch 38 Global_step 3163000	Train_loss: 0.1913	Eval_AUC: 0.8370
Epoch 38 Global_step 3164000	Train_loss: 0.1939	Eval_AUC: 0.8352
Epoch 38 Global_step 3165000	Train_loss: 0.1887	Eval_AUC: 0.8380
Epoch 38 Global_step 3166000	Train_loss: 0.1945	Eval_AUC: 0.8362
Epoch 38 Global_step 3167000	Train_loss: 0.1860	Eval_AUC: 0.8371
Epoch 38 Global_step 3168000	Train_loss: 0.1893	Eval_AUC: 0.8327
Epoch 38 Global_step 3169000	Train_loss: 0.1926	Eval_AUC: 0.8355
Epoch 38 Global_step 3170000	Train_loss: 0.1998	Eval_AUC: 0.8377
Epoch 38 Global_step 3171000	Train_loss: 0.1905	Eval_AUC: 0.8373
Epoch 38 Global_step 3172000	Train_loss: 0.1927	Eval_AUC: 0.8380
Epoch 38 Global_step 3173000	Train_loss: 0.1947	Eval_AUC: 0.8364
Epoch 38 Global_step 3174000	Train_loss: 0.1961	Eval_AUC: 0.8387
Epoch 38 Global_step 3175000	Train_loss: 0.1930	Eval_AUC: 0.8375
Epoch 38 Global_step 3176000	Train_loss: 0.1976	Eval_AUC: 0.8351
Epoch 38 Global_step 3177000	Train_loss: 0.1937	Eval_AUC: 0.8372
Epoch 38 Global_step 3178000	Train_loss: 0.1971	Eval_AUC: 0.8370
Epoch 38 Global_step 3179000	Train_loss: 0.1962	Eval_AUC: 0.8370
Epoch 38 DONE	Cost time: 33574.18
Epoch 39 Global_step 3180000	Train_loss: 0.0872	Eval_AUC: 0.8386
Epoch 39 Global_step 3181000	Train_loss: 0.1530	Eval_AUC: 0.8371
Epoch 39 Global_step 3182000	Train_loss: 0.1601	Eval_AUC: 0.8355
Epoch 39 Global_step 3183000	Train_loss: 0.1522	Eval_AUC: 0.8359
Epoch 39 Global_step 3184000	Train_loss: 0.1557	Eval_AUC: 0.8364
Epoch 39 Global_step 3185000	Train_loss: 0.1577	Eval_AUC: 0.8350
Epoch 39 Global_step 3186000	Train_loss: 0.1505	Eval_AUC: 0.8357
Epoch 39 Global_step 3187000	Train_loss: 0.1575	Eval_AUC: 0.8342
Epoch 39 Global_step 3188000	Train_loss: 0.1614	Eval_AUC: 0.8383
Epoch 39 Global_step 3189000	Train_loss: 0.1562	Eval_AUC: 0.8387
Epoch 39 Global_step 3190000	Train_loss: 0.1618	Eval_AUC: 0.8362
Epoch 39 Global_step 3191000	Train_loss: 0.1603	Eval_AUC: 0.8366
Epoch 39 Global_step 3192000	Train_loss: 0.1613	Eval_AUC: 0.8354
Epoch 39 Global_step 3193000	Train_loss: 0.1641	Eval_AUC: 0.8371
Epoch 39 Global_step 3194000	Train_loss: 0.1621	Eval_AUC: 0.8349
Epoch 39 Global_step 3195000	Train_loss: 0.1592	Eval_AUC: 0.8366
Epoch 39 Global_step 3196000	Train_loss: 0.1655	Eval_AUC: 0.8329
Epoch 39 Global_step 3197000	Train_loss: 0.1607	Eval_AUC: 0.8356
Epoch 39 Global_step 3198000	Train_loss: 0.1666	Eval_AUC: 0.8349
Epoch 39 Global_step 3199000	Train_loss: 0.1645	Eval_AUC: 0.8362
Epoch 39 Global_step 3200000	Train_loss: 0.1659	Eval_AUC: 0.8342
Epoch 39 Global_step 3201000	Train_loss: 0.1690	Eval_AUC: 0.8366
Epoch 39 Global_step 3202000	Train_loss: 0.1686	Eval_AUC: 0.8335
Epoch 39 Global_step 3203000	Train_loss: 0.1635	Eval_AUC: 0.8358
Epoch 39 Global_step 3204000	Train_loss: 0.1634	Eval_AUC: 0.8345
Epoch 39 Global_step 3205000	Train_loss: 0.1724	Eval_AUC: 0.8352
Epoch 39 Global_step 3206000	Train_loss: 0.1669	Eval_AUC: 0.8357
Epoch 39 Global_step 3207000	Train_loss: 0.1673	Eval_AUC: 0.8343
Epoch 39 Global_step 3208000	Train_loss: 0.1710	Eval_AUC: 0.8341
Epoch 39 Global_step 3209000	Train_loss: 0.1715	Eval_AUC: 0.8369
Epoch 39 Global_step 3210000	Train_loss: 0.1719	Eval_AUC: 0.8347
Epoch 39 Global_step 3211000	Train_loss: 0.1710	Eval_AUC: 0.8350
Epoch 39 Global_step 3212000	Train_loss: 0.1718	Eval_AUC: 0.8355
Epoch 39 Global_step 3213000	Train_loss: 0.1701	Eval_AUC: 0.8357
Epoch 39 Global_step 3214000	Train_loss: 0.1733	Eval_AUC: 0.8340
Epoch 39 Global_step 3215000	Train_loss: 0.1745	Eval_AUC: 0.8353
Epoch 39 Global_step 3216000	Train_loss: 0.1733	Eval_AUC: 0.8352
Epoch 39 Global_step 3217000	Train_loss: 0.1732	Eval_AUC: 0.8347
Epoch 39 Global_step 3218000	Train_loss: 0.1791	Eval_AUC: 0.8346
Epoch 39 Global_step 3219000	Train_loss: 0.1767	Eval_AUC: 0.8317
Epoch 39 Global_step 3220000	Train_loss: 0.1803	Eval_AUC: 0.8358
Epoch 39 Global_step 3221000	Train_loss: 0.1774	Eval_AUC: 0.8335
Epoch 39 Global_step 3222000	Train_loss: 0.1745	Eval_AUC: 0.8373
Epoch 39 Global_step 3223000	Train_loss: 0.1759	Eval_AUC: 0.8335
Epoch 39 Global_step 3224000	Train_loss: 0.1774	Eval_AUC: 0.8369
Epoch 39 Global_step 3225000	Train_loss: 0.1786	Eval_AUC: 0.8374
Epoch 39 Global_step 3226000	Train_loss: 0.1815	Eval_AUC: 0.8338
Epoch 39 Global_step 3227000	Train_loss: 0.1830	Eval_AUC: 0.8336
Epoch 39 Global_step 3228000	Train_loss: 0.1819	Eval_AUC: 0.8341
Epoch 39 Global_step 3229000	Train_loss: 0.1840	Eval_AUC: 0.8362
Epoch 39 Global_step 3230000	Train_loss: 0.1849	Eval_AUC: 0.8365
Epoch 39 Global_step 3231000	Train_loss: 0.1799	Eval_AUC: 0.8358
Epoch 39 Global_step 3232000	Train_loss: 0.1846	Eval_AUC: 0.8371
Epoch 39 Global_step 3233000	Train_loss: 0.1895	Eval_AUC: 0.8337
Epoch 39 Global_step 3234000	Train_loss: 0.1841	Eval_AUC: 0.8346
Epoch 39 Global_step 3235000	Train_loss: 0.1812	Eval_AUC: 0.8366
Epoch 39 Global_step 3236000	Train_loss: 0.1774	Eval_AUC: 0.8352
Epoch 39 Global_step 3237000	Train_loss: 0.1828	Eval_AUC: 0.8380
Epoch 39 Global_step 3238000	Train_loss: 0.1848	Eval_AUC: 0.8342
Epoch 39 Global_step 3239000	Train_loss: 0.1864	Eval_AUC: 0.8366
Epoch 39 Global_step 3240000	Train_loss: 0.1832	Eval_AUC: 0.8353
Epoch 39 Global_step 3241000	Train_loss: 0.1836	Eval_AUC: 0.8370
Epoch 39 Global_step 3242000	Train_loss: 0.1801	Eval_AUC: 0.8354
Epoch 39 Global_step 3243000	Train_loss: 0.1856	Eval_AUC: 0.8376
Epoch 39 Global_step 3244000	Train_loss: 0.1882	Eval_AUC: 0.8367
Epoch 39 Global_step 3245000	Train_loss: 0.1900	Eval_AUC: 0.8361
Epoch 39 Global_step 3246000	Train_loss: 0.1862	Eval_AUC: 0.8364
Epoch 39 Global_step 3247000	Train_loss: 0.1866	Eval_AUC: 0.8354
Epoch 39 Global_step 3248000	Train_loss: 0.1899	Eval_AUC: 0.8363
Epoch 39 Global_step 3249000	Train_loss: 0.1893	Eval_AUC: 0.8372
Epoch 39 Global_step 3250000	Train_loss: 0.1803	Eval_AUC: 0.8347
Epoch 39 Global_step 3251000	Train_loss: 0.1861	Eval_AUC: 0.8384
Epoch 39 Global_step 3252000	Train_loss: 0.1840	Eval_AUC: 0.8341
Epoch 39 Global_step 3253000	Train_loss: 0.1870	Eval_AUC: 0.8361
Epoch 39 Global_step 3254000	Train_loss: 0.1893	Eval_AUC: 0.8366
Epoch 39 Global_step 3255000	Train_loss: 0.1915	Eval_AUC: 0.8343
Epoch 39 Global_step 3256000	Train_loss: 0.1906	Eval_AUC: 0.8380
Epoch 39 Global_step 3257000	Train_loss: 0.1895	Eval_AUC: 0.8370
Epoch 39 Global_step 3258000	Train_loss: 0.1925	Eval_AUC: 0.8359
Epoch 39 Global_step 3259000	Train_loss: 0.1888	Eval_AUC: 0.8335
Epoch 39 Global_step 3260000	Train_loss: 0.1936	Eval_AUC: 0.8359
Epoch 39 DONE	Cost time: 34420.37
Epoch 40 Global_step 3261000	Train_loss: 0.0064	Eval_AUC: 0.8365
Epoch 40 Global_step 3262000	Train_loss: 0.1511	Eval_AUC: 0.8374
Epoch 40 Global_step 3263000	Train_loss: 0.1530	Eval_AUC: 0.8364
Epoch 40 Global_step 3264000	Train_loss: 0.1547	Eval_AUC: 0.8349
Epoch 40 Global_step 3265000	Train_loss: 0.1509	Eval_AUC: 0.8372
Epoch 40 Global_step 3266000	Train_loss: 0.1474	Eval_AUC: 0.8380
Epoch 40 Global_step 3267000	Train_loss: 0.1530	Eval_AUC: 0.8354
Epoch 40 Global_step 3268000	Train_loss: 0.1487	Eval_AUC: 0.8366
Epoch 40 Global_step 3269000	Train_loss: 0.1560	Eval_AUC: 0.8369
Epoch 40 Global_step 3270000	Train_loss: 0.1574	Eval_AUC: 0.8383
Epoch 40 Global_step 3271000	Train_loss: 0.1513	Eval_AUC: 0.8353
Epoch 40 Global_step 3272000	Train_loss: 0.1580	Eval_AUC: 0.8383
Epoch 40 Global_step 3273000	Train_loss: 0.1564	Eval_AUC: 0.8361
Epoch 40 Global_step 3274000	Train_loss: 0.1575	Eval_AUC: 0.8321
Epoch 40 Global_step 3275000	Train_loss: 0.1563	Eval_AUC: 0.8345
Epoch 40 Global_step 3276000	Train_loss: 0.1568	Eval_AUC: 0.8367
Epoch 40 Global_step 3277000	Train_loss: 0.1570	Eval_AUC: 0.8363
Epoch 40 Global_step 3278000	Train_loss: 0.1575	Eval_AUC: 0.8349
Epoch 40 Global_step 3279000	Train_loss: 0.1592	Eval_AUC: 0.8348
Epoch 40 Global_step 3280000	Train_loss: 0.1587	Eval_AUC: 0.8343
Epoch 40 Global_step 3281000	Train_loss: 0.1616	Eval_AUC: 0.8345
Epoch 40 Global_step 3282000	Train_loss: 0.1632	Eval_AUC: 0.8341
Epoch 40 Global_step 3283000	Train_loss: 0.1641	Eval_AUC: 0.8353
Epoch 40 Global_step 3284000	Train_loss: 0.1651	Eval_AUC: 0.8338
Epoch 40 Global_step 3285000	Train_loss: 0.1636	Eval_AUC: 0.8371
Epoch 40 Global_step 3286000	Train_loss: 0.1635	Eval_AUC: 0.8351
Epoch 40 Global_step 3287000	Train_loss: 0.1611	Eval_AUC: 0.8348
Epoch 40 Global_step 3288000	Train_loss: 0.1684	Eval_AUC: 0.8351
Epoch 40 Global_step 3289000	Train_loss: 0.1681	Eval_AUC: 0.8338
Epoch 40 Global_step 3290000	Train_loss: 0.1615	Eval_AUC: 0.8331
Epoch 40 Global_step 3291000	Train_loss: 0.1651	Eval_AUC: 0.8350
Epoch 40 Global_step 3292000	Train_loss: 0.1674	Eval_AUC: 0.8349
Epoch 40 Global_step 3293000	Train_loss: 0.1697	Eval_AUC: 0.8359
Epoch 40 Global_step 3294000	Train_loss: 0.1699	Eval_AUC: 0.8328
Epoch 40 Global_step 3295000	Train_loss: 0.1712	Eval_AUC: 0.8351
Epoch 40 Global_step 3296000	Train_loss: 0.1697	Eval_AUC: 0.8362
Epoch 40 Global_step 3297000	Train_loss: 0.1641	Eval_AUC: 0.8373
Epoch 40 Global_step 3298000	Train_loss: 0.1748	Eval_AUC: 0.8350
Epoch 40 Global_step 3299000	Train_loss: 0.1716	Eval_AUC: 0.8367
Epoch 40 Global_step 3300000	Train_loss: 0.1679	Eval_AUC: 0.8363
Epoch 40 Global_step 3301000	Train_loss: 0.1710	Eval_AUC: 0.8344
Epoch 40 Global_step 3302000	Train_loss: 0.1767	Eval_AUC: 0.8347
Epoch 40 Global_step 3303000	Train_loss: 0.1780	Eval_AUC: 0.8359
Epoch 40 Global_step 3304000	Train_loss: 0.1771	Eval_AUC: 0.8332
Epoch 40 Global_step 3305000	Train_loss: 0.1780	Eval_AUC: 0.8340
Epoch 40 Global_step 3306000	Train_loss: 0.1679	Eval_AUC: 0.8345
Epoch 40 Global_step 3307000	Train_loss: 0.1811	Eval_AUC: 0.8369
Epoch 40 Global_step 3308000	Train_loss: 0.1778	Eval_AUC: 0.8353
Epoch 40 Global_step 3309000	Train_loss: 0.1735	Eval_AUC: 0.8341
Epoch 40 Global_step 3310000	Train_loss: 0.1723	Eval_AUC: 0.8360
Epoch 40 Global_step 3311000	Train_loss: 0.1758	Eval_AUC: 0.8338
Epoch 40 Global_step 3312000	Train_loss: 0.1762	Eval_AUC: 0.8368
Epoch 40 Global_step 3313000	Train_loss: 0.1763	Eval_AUC: 0.8360
Epoch 40 Global_step 3314000	Train_loss: 0.1786	Eval_AUC: 0.8351
Epoch 40 Global_step 3315000	Train_loss: 0.1778	Eval_AUC: 0.8348
Epoch 40 Global_step 3316000	Train_loss: 0.1765	Eval_AUC: 0.8341
Epoch 40 Global_step 3317000	Train_loss: 0.1808	Eval_AUC: 0.8369
Epoch 40 Global_step 3318000	Train_loss: 0.1821	Eval_AUC: 0.8347
Epoch 40 Global_step 3319000	Train_loss: 0.1833	Eval_AUC: 0.8353
Epoch 40 Global_step 3320000	Train_loss: 0.1804	Eval_AUC: 0.8362
Epoch 40 Global_step 3321000	Train_loss: 0.1739	Eval_AUC: 0.8347
Epoch 40 Global_step 3322000	Train_loss: 0.1790	Eval_AUC: 0.8384
Epoch 40 Global_step 3323000	Train_loss: 0.1797	Eval_AUC: 0.8328
Epoch 40 Global_step 3324000	Train_loss: 0.1855	Eval_AUC: 0.8338
Epoch 40 Global_step 3325000	Train_loss: 0.1800	Eval_AUC: 0.8361
Epoch 40 Global_step 3326000	Train_loss: 0.1829	Eval_AUC: 0.8356
Epoch 40 Global_step 3327000	Train_loss: 0.1841	Eval_AUC: 0.8336
Epoch 40 Global_step 3328000	Train_loss: 0.1848	Eval_AUC: 0.8333
Epoch 40 Global_step 3329000	Train_loss: 0.1874	Eval_AUC: 0.8353
Epoch 40 Global_step 3330000	Train_loss: 0.1824	Eval_AUC: 0.8359
Epoch 40 Global_step 3331000	Train_loss: 0.1854	Eval_AUC: 0.8350
Epoch 40 Global_step 3332000	Train_loss: 0.1862	Eval_AUC: 0.8361
Epoch 40 Global_step 3333000	Train_loss: 0.1802	Eval_AUC: 0.8352
Epoch 40 Global_step 3334000	Train_loss: 0.1859	Eval_AUC: 0.8365
Epoch 40 Global_step 3335000	Train_loss: 0.1845	Eval_AUC: 0.8339
Epoch 40 Global_step 3336000	Train_loss: 0.1903	Eval_AUC: 0.8338
Epoch 40 Global_step 3337000	Train_loss: 0.1845	Eval_AUC: 0.8345
Epoch 40 Global_step 3338000	Train_loss: 0.1827	Eval_AUC: 0.8354
Epoch 40 Global_step 3339000	Train_loss: 0.1925	Eval_AUC: 0.8339
Epoch 40 Global_step 3340000	Train_loss: 0.1894	Eval_AUC: 0.8330
Epoch 40 Global_step 3341000	Train_loss: 0.1921	Eval_AUC: 0.8349
Epoch 40 Global_step 3342000	Train_loss: 0.1872	Eval_AUC: 0.8365
Epoch 40 DONE	Cost time: 35248.06
Epoch 41 Global_step 3343000	Train_loss: 0.0800	Eval_AUC: 0.8363
Epoch 41 Global_step 3344000	Train_loss: 0.1512	Eval_AUC: 0.8364
Epoch 41 Global_step 3345000	Train_loss: 0.1432	Eval_AUC: 0.8364
Epoch 41 Global_step 3346000	Train_loss: 0.1491	Eval_AUC: 0.8370
Epoch 41 Global_step 3347000	Train_loss: 0.1484	Eval_AUC: 0.8351
Epoch 41 Global_step 3348000	Train_loss: 0.1482	Eval_AUC: 0.8359
Epoch 41 Global_step 3349000	Train_loss: 0.1493	Eval_AUC: 0.8352
Epoch 41 Global_step 3350000	Train_loss: 0.1482	Eval_AUC: 0.8338
Epoch 41 Global_step 3351000	Train_loss: 0.1488	Eval_AUC: 0.8338
Epoch 41 Global_step 3352000	Train_loss: 0.1484	Eval_AUC: 0.8363
Epoch 41 Global_step 3353000	Train_loss: 0.1508	Eval_AUC: 0.8339
Epoch 41 Global_step 3354000	Train_loss: 0.1546	Eval_AUC: 0.8357
Epoch 41 Global_step 3355000	Train_loss: 0.1553	Eval_AUC: 0.8345
Epoch 41 Global_step 3356000	Train_loss: 0.1524	Eval_AUC: 0.8355
Epoch 41 Global_step 3357000	Train_loss: 0.1479	Eval_AUC: 0.8359
Epoch 41 Global_step 3358000	Train_loss: 0.1541	Eval_AUC: 0.8358
Epoch 41 Global_step 3359000	Train_loss: 0.1534	Eval_AUC: 0.8352
Epoch 41 Global_step 3360000	Train_loss: 0.1548	Eval_AUC: 0.8348
Epoch 41 Global_step 3361000	Train_loss: 0.1513	Eval_AUC: 0.8350
Epoch 41 Global_step 3362000	Train_loss: 0.1591	Eval_AUC: 0.8359
Epoch 41 Global_step 3363000	Train_loss: 0.1598	Eval_AUC: 0.8352
Epoch 41 Global_step 3364000	Train_loss: 0.1608	Eval_AUC: 0.8335
Epoch 41 Global_step 3365000	Train_loss: 0.1608	Eval_AUC: 0.8335
Epoch 41 Global_step 3366000	Train_loss: 0.1592	Eval_AUC: 0.8357
Epoch 41 Global_step 3367000	Train_loss: 0.1615	Eval_AUC: 0.8325
Epoch 41 Global_step 3368000	Train_loss: 0.1609	Eval_AUC: 0.8329
Epoch 41 Global_step 3369000	Train_loss: 0.1653	Eval_AUC: 0.8343
Epoch 41 Global_step 3370000	Train_loss: 0.1628	Eval_AUC: 0.8343
Epoch 41 Global_step 3371000	Train_loss: 0.1613	Eval_AUC: 0.8351
Epoch 41 Global_step 3372000	Train_loss: 0.1572	Eval_AUC: 0.8313
Epoch 41 Global_step 3373000	Train_loss: 0.1629	Eval_AUC: 0.8346
Epoch 41 Global_step 3374000	Train_loss: 0.1644	Eval_AUC: 0.8345
Epoch 41 Global_step 3375000	Train_loss: 0.1685	Eval_AUC: 0.8336
Epoch 41 Global_step 3376000	Train_loss: 0.1654	Eval_AUC: 0.8330
Epoch 41 Global_step 3377000	Train_loss: 0.1654	Eval_AUC: 0.8361
Epoch 41 Global_step 3378000	Train_loss: 0.1614	Eval_AUC: 0.8338
Epoch 41 Global_step 3379000	Train_loss: 0.1640	Eval_AUC: 0.8326
Epoch 41 Global_step 3380000	Train_loss: 0.1699	Eval_AUC: 0.8341
Epoch 41 Global_step 3381000	Train_loss: 0.1656	Eval_AUC: 0.8319
Epoch 41 Global_step 3382000	Train_loss: 0.1659	Eval_AUC: 0.8357
Epoch 41 Global_step 3383000	Train_loss: 0.1653	Eval_AUC: 0.8338
Epoch 41 Global_step 3384000	Train_loss: 0.1680	Eval_AUC: 0.8331
Epoch 41 Global_step 3385000	Train_loss: 0.1743	Eval_AUC: 0.8350
Epoch 41 Global_step 3386000	Train_loss: 0.1708	Eval_AUC: 0.8351
Epoch 41 Global_step 3387000	Train_loss: 0.1676	Eval_AUC: 0.8348
Epoch 41 Global_step 3388000	Train_loss: 0.1736	Eval_AUC: 0.8344
Epoch 41 Global_step 3389000	Train_loss: 0.1722	Eval_AUC: 0.8331
Epoch 41 Global_step 3390000	Train_loss: 0.1692	Eval_AUC: 0.8330
Epoch 41 Global_step 3391000	Train_loss: 0.1723	Eval_AUC: 0.8331
Epoch 41 Global_step 3392000	Train_loss: 0.1727	Eval_AUC: 0.8343
Epoch 41 Global_step 3393000	Train_loss: 0.1761	Eval_AUC: 0.8315
Epoch 41 Global_step 3394000	Train_loss: 0.1744	Eval_AUC: 0.8323
Epoch 41 Global_step 3395000	Train_loss: 0.1749	Eval_AUC: 0.8325
Epoch 41 Global_step 3396000	Train_loss: 0.1767	Eval_AUC: 0.8338
Epoch 41 Global_step 3397000	Train_loss: 0.1734	Eval_AUC: 0.8347
Epoch 41 Global_step 3398000	Train_loss: 0.1727	Eval_AUC: 0.8353
Epoch 41 Global_step 3399000	Train_loss: 0.1759	Eval_AUC: 0.8343
Epoch 41 Global_step 3400000	Train_loss: 0.1789	Eval_AUC: 0.8342
Epoch 41 Global_step 3401000	Train_loss: 0.1738	Eval_AUC: 0.8332
Epoch 41 Global_step 3402000	Train_loss: 0.1746	Eval_AUC: 0.8347
Epoch 41 Global_step 3403000	Train_loss: 0.1802	Eval_AUC: 0.8334
Epoch 41 Global_step 3404000	Train_loss: 0.1791	Eval_AUC: 0.8341
Epoch 41 Global_step 3405000	Train_loss: 0.1795	Eval_AUC: 0.8342
Epoch 41 Global_step 3406000	Train_loss: 0.1777	Eval_AUC: 0.8322
Epoch 41 Global_step 3407000	Train_loss: 0.1734	Eval_AUC: 0.8345
Epoch 41 Global_step 3408000	Train_loss: 0.1787	Eval_AUC: 0.8362
Epoch 41 Global_step 3409000	Train_loss: 0.1843	Eval_AUC: 0.8362
Epoch 41 Global_step 3410000	Train_loss: 0.1809	Eval_AUC: 0.8353
Epoch 41 Global_step 3411000	Train_loss: 0.1782	Eval_AUC: 0.8350
Epoch 41 Global_step 3412000	Train_loss: 0.1834	Eval_AUC: 0.8307
Epoch 41 Global_step 3413000	Train_loss: 0.1870	Eval_AUC: 0.8320
Epoch 41 Global_step 3414000	Train_loss: 0.1808	Eval_AUC: 0.8334
Epoch 41 Global_step 3415000	Train_loss: 0.1793	Eval_AUC: 0.8342
Epoch 41 Global_step 3416000	Train_loss: 0.1806	Eval_AUC: 0.8344
Epoch 41 Global_step 3417000	Train_loss: 0.1819	Eval_AUC: 0.8339
Epoch 41 Global_step 3418000	Train_loss: 0.1837	Eval_AUC: 0.8328
Epoch 41 Global_step 3419000	Train_loss: 0.1823	Eval_AUC: 0.8361
Epoch 41 Global_step 3420000	Train_loss: 0.1846	Eval_AUC: 0.8373
Epoch 41 Global_step 3421000	Train_loss: 0.1884	Eval_AUC: 0.8364
Epoch 41 Global_step 3422000	Train_loss: 0.1812	Eval_AUC: 0.8347
Epoch 41 Global_step 3423000	Train_loss: 0.1827	Eval_AUC: 0.8342
Epoch 41 Global_step 3424000	Train_loss: 0.1843	Eval_AUC: 0.8365
Epoch 41 DONE	Cost time: 36075.64
Epoch 42 Global_step 3425000	Train_loss: 0.1438	Eval_AUC: 0.8340
Epoch 42 Global_step 3426000	Train_loss: 0.1475	Eval_AUC: 0.8331
Epoch 42 Global_step 3427000	Train_loss: 0.1434	Eval_AUC: 0.8357
Epoch 42 Global_step 3428000	Train_loss: 0.1425	Eval_AUC: 0.8362
Epoch 42 Global_step 3429000	Train_loss: 0.1459	Eval_AUC: 0.8359
Epoch 42 Global_step 3430000	Train_loss: 0.1445	Eval_AUC: 0.8347
Epoch 42 Global_step 3431000	Train_loss: 0.1480	Eval_AUC: 0.8341
Epoch 42 Global_step 3432000	Train_loss: 0.1488	Eval_AUC: 0.8343
Epoch 42 Global_step 3433000	Train_loss: 0.1479	Eval_AUC: 0.8338
Epoch 42 Global_step 3434000	Train_loss: 0.1454	Eval_AUC: 0.8342
Epoch 42 Global_step 3435000	Train_loss: 0.1457	Eval_AUC: 0.8338
Epoch 42 Global_step 3436000	Train_loss: 0.1500	Eval_AUC: 0.8304
Epoch 42 Global_step 3437000	Train_loss: 0.1481	Eval_AUC: 0.8347
Epoch 42 Global_step 3438000	Train_loss: 0.1491	Eval_AUC: 0.8330
Epoch 42 Global_step 3439000	Train_loss: 0.1541	Eval_AUC: 0.8307
Epoch 42 Global_step 3440000	Train_loss: 0.1490	Eval_AUC: 0.8323
Epoch 42 Global_step 3441000	Train_loss: 0.1515	Eval_AUC: 0.8332
Epoch 42 Global_step 3442000	Train_loss: 0.1552	Eval_AUC: 0.8326
Epoch 42 Global_step 3443000	Train_loss: 0.1516	Eval_AUC: 0.8336
Epoch 42 Global_step 3444000	Train_loss: 0.1558	Eval_AUC: 0.8332
Epoch 42 Global_step 3445000	Train_loss: 0.1545	Eval_AUC: 0.8350
Epoch 42 Global_step 3446000	Train_loss: 0.1538	Eval_AUC: 0.8353
Epoch 42 Global_step 3447000	Train_loss: 0.1537	Eval_AUC: 0.8333
Epoch 42 Global_step 3448000	Train_loss: 0.1499	Eval_AUC: 0.8345
Epoch 42 Global_step 3449000	Train_loss: 0.1597	Eval_AUC: 0.8337
Epoch 42 Global_step 3450000	Train_loss: 0.1521	Eval_AUC: 0.8325
Epoch 42 Global_step 3451000	Train_loss: 0.1525	Eval_AUC: 0.8342
Epoch 42 Global_step 3452000	Train_loss: 0.1531	Eval_AUC: 0.8324
Epoch 42 Global_step 3453000	Train_loss: 0.1568	Eval_AUC: 0.8328
Epoch 42 Global_step 3454000	Train_loss: 0.1571	Eval_AUC: 0.8315
Epoch 42 Global_step 3455000	Train_loss: 0.1604	Eval_AUC: 0.8330
Epoch 42 Global_step 3456000	Train_loss: 0.1589	Eval_AUC: 0.8326
Epoch 42 Global_step 3457000	Train_loss: 0.1583	Eval_AUC: 0.8340
Epoch 42 Global_step 3458000	Train_loss: 0.1598	Eval_AUC: 0.8334
Epoch 42 Global_step 3459000	Train_loss: 0.1597	Eval_AUC: 0.8319
Epoch 42 Global_step 3460000	Train_loss: 0.1601	Eval_AUC: 0.8328
Epoch 42 Global_step 3461000	Train_loss: 0.1673	Eval_AUC: 0.8345
Epoch 42 Global_step 3462000	Train_loss: 0.1647	Eval_AUC: 0.8326
Epoch 42 Global_step 3463000	Train_loss: 0.1616	Eval_AUC: 0.8319
Epoch 42 Global_step 3464000	Train_loss: 0.1651	Eval_AUC: 0.8332
Epoch 42 Global_step 3465000	Train_loss: 0.1664	Eval_AUC: 0.8328
Epoch 42 Global_step 3466000	Train_loss: 0.1708	Eval_AUC: 0.8329
Epoch 42 Global_step 3467000	Train_loss: 0.1613	Eval_AUC: 0.8330
Epoch 42 Global_step 3468000	Train_loss: 0.1667	Eval_AUC: 0.8331
Epoch 42 Global_step 3469000	Train_loss: 0.1678	Eval_AUC: 0.8323
Epoch 42 Global_step 3470000	Train_loss: 0.1655	Eval_AUC: 0.8335
Epoch 42 Global_step 3471000	Train_loss: 0.1650	Eval_AUC: 0.8348
Epoch 42 Global_step 3472000	Train_loss: 0.1713	Eval_AUC: 0.8330
Epoch 42 Global_step 3473000	Train_loss: 0.1655	Eval_AUC: 0.8315
Epoch 42 Global_step 3474000	Train_loss: 0.1692	Eval_AUC: 0.8337
Epoch 42 Global_step 3475000	Train_loss: 0.1653	Eval_AUC: 0.8332
Epoch 42 Global_step 3476000	Train_loss: 0.1654	Eval_AUC: 0.8328
Epoch 42 Global_step 3477000	Train_loss: 0.1691	Eval_AUC: 0.8320
Epoch 42 Global_step 3478000	Train_loss: 0.1726	Eval_AUC: 0.8348
Epoch 42 Global_step 3479000	Train_loss: 0.1762	Eval_AUC: 0.8349
Epoch 42 Global_step 3480000	Train_loss: 0.1756	Eval_AUC: 0.8312
Epoch 42 Global_step 3481000	Train_loss: 0.1740	Eval_AUC: 0.8328
Epoch 42 Global_step 3482000	Train_loss: 0.1735	Eval_AUC: 0.8340
Epoch 42 Global_step 3483000	Train_loss: 0.1724	Eval_AUC: 0.8319
Epoch 42 Global_step 3484000	Train_loss: 0.1692	Eval_AUC: 0.8334
Epoch 42 Global_step 3485000	Train_loss: 0.1752	Eval_AUC: 0.8334
Epoch 42 Global_step 3486000	Train_loss: 0.1696	Eval_AUC: 0.8325
Epoch 42 Global_step 3487000	Train_loss: 0.1737	Eval_AUC: 0.8350
Epoch 42 Global_step 3488000	Train_loss: 0.1724	Eval_AUC: 0.8344
Epoch 42 Global_step 3489000	Train_loss: 0.1780	Eval_AUC: 0.8322
Epoch 42 Global_step 3490000	Train_loss: 0.1764	Eval_AUC: 0.8343
Epoch 42 Global_step 3491000	Train_loss: 0.1761	Eval_AUC: 0.8303
Epoch 42 Global_step 3492000	Train_loss: 0.1753	Eval_AUC: 0.8336
Epoch 42 Global_step 3493000	Train_loss: 0.1779	Eval_AUC: 0.8331
Epoch 42 Global_step 3494000	Train_loss: 0.1734	Eval_AUC: 0.8347
Epoch 42 Global_step 3495000	Train_loss: 0.1812	Eval_AUC: 0.8345
Epoch 42 Global_step 3496000	Train_loss: 0.1786	Eval_AUC: 0.8335
Epoch 42 Global_step 3497000	Train_loss: 0.1824	Eval_AUC: 0.8359
Epoch 42 Global_step 3498000	Train_loss: 0.1809	Eval_AUC: 0.8332
Epoch 42 Global_step 3499000	Train_loss: 0.1814	Eval_AUC: 0.8299
Epoch 42 Global_step 3500000	Train_loss: 0.1793	Eval_AUC: 0.8341
Epoch 42 Global_step 3501000	Train_loss: 0.1802	Eval_AUC: 0.8341
Epoch 42 Global_step 3502000	Train_loss: 0.1791	Eval_AUC: 0.8344
Epoch 42 Global_step 3503000	Train_loss: 0.1836	Eval_AUC: 0.8329
Epoch 42 Global_step 3504000	Train_loss: 0.1792	Eval_AUC: 0.8365
Epoch 42 Global_step 3505000	Train_loss: 0.1778	Eval_AUC: 0.8350
Epoch 42 DONE	Cost time: 36904.59
Epoch 43 Global_step 3506000	Train_loss: 0.0649	Eval_AUC: 0.8340
Epoch 43 Global_step 3507000	Train_loss: 0.1403	Eval_AUC: 0.8353
Epoch 43 Global_step 3508000	Train_loss: 0.1447	Eval_AUC: 0.8335
Epoch 43 Global_step 3509000	Train_loss: 0.1424	Eval_AUC: 0.8347
Epoch 43 Global_step 3510000	Train_loss: 0.1453	Eval_AUC: 0.8365
Epoch 43 Global_step 3511000	Train_loss: 0.1399	Eval_AUC: 0.8350
Epoch 43 Global_step 3512000	Train_loss: 0.1414	Eval_AUC: 0.8344
Epoch 43 Global_step 3513000	Train_loss: 0.1439	Eval_AUC: 0.8334
Epoch 43 Global_step 3514000	Train_loss: 0.1457	Eval_AUC: 0.8355
Epoch 43 Global_step 3515000	Train_loss: 0.1444	Eval_AUC: 0.8295
Epoch 43 Global_step 3516000	Train_loss: 0.1438	Eval_AUC: 0.8334
Epoch 43 Global_step 3517000	Train_loss: 0.1436	Eval_AUC: 0.8337
Epoch 43 Global_step 3518000	Train_loss: 0.1449	Eval_AUC: 0.8337
Epoch 43 Global_step 3519000	Train_loss: 0.1456	Eval_AUC: 0.8335
Epoch 43 Global_step 3520000	Train_loss: 0.1491	Eval_AUC: 0.8318
Epoch 43 Global_step 3521000	Train_loss: 0.1439	Eval_AUC: 0.8333
Epoch 43 Global_step 3522000	Train_loss: 0.1439	Eval_AUC: 0.8342
Epoch 43 Global_step 3523000	Train_loss: 0.1466	Eval_AUC: 0.8300
Epoch 43 Global_step 3524000	Train_loss: 0.1491	Eval_AUC: 0.8335
Epoch 43 Global_step 3525000	Train_loss: 0.1524	Eval_AUC: 0.8319
Epoch 43 Global_step 3526000	Train_loss: 0.1507	Eval_AUC: 0.8330
Epoch 43 Global_step 3527000	Train_loss: 0.1522	Eval_AUC: 0.8327
Epoch 43 Global_step 3528000	Train_loss: 0.1547	Eval_AUC: 0.8326
Epoch 43 Global_step 3529000	Train_loss: 0.1518	Eval_AUC: 0.8301
Epoch 43 Global_step 3530000	Train_loss: 0.1471	Eval_AUC: 0.8335
Epoch 43 Global_step 3531000	Train_loss: 0.1523	Eval_AUC: 0.8328
Epoch 43 Global_step 3532000	Train_loss: 0.1507	Eval_AUC: 0.8342
Epoch 43 Global_step 3533000	Train_loss: 0.1618	Eval_AUC: 0.8306
Epoch 43 Global_step 3534000	Train_loss: 0.1510	Eval_AUC: 0.8345
Epoch 43 Global_step 3535000	Train_loss: 0.1566	Eval_AUC: 0.8326
Epoch 43 Global_step 3536000	Train_loss: 0.1625	Eval_AUC: 0.8322
Epoch 43 Global_step 3537000	Train_loss: 0.1580	Eval_AUC: 0.8318
Epoch 43 Global_step 3538000	Train_loss: 0.1574	Eval_AUC: 0.8329
Epoch 43 Global_step 3539000	Train_loss: 0.1545	Eval_AUC: 0.8329
Epoch 43 Global_step 3540000	Train_loss: 0.1557	Eval_AUC: 0.8344
Epoch 43 Global_step 3541000	Train_loss: 0.1572	Eval_AUC: 0.8329
Epoch 43 Global_step 3542000	Train_loss: 0.1569	Eval_AUC: 0.8312
Epoch 43 Global_step 3543000	Train_loss: 0.1627	Eval_AUC: 0.8320
Epoch 43 Global_step 3544000	Train_loss: 0.1651	Eval_AUC: 0.8335
Epoch 43 Global_step 3545000	Train_loss: 0.1617	Eval_AUC: 0.8338
Epoch 43 Global_step 3546000	Train_loss: 0.1586	Eval_AUC: 0.8337
Epoch 43 Global_step 3547000	Train_loss: 0.1643	Eval_AUC: 0.8320
Epoch 43 Global_step 3548000	Train_loss: 0.1684	Eval_AUC: 0.8324
Epoch 43 Global_step 3549000	Train_loss: 0.1592	Eval_AUC: 0.8344
Epoch 43 Global_step 3550000	Train_loss: 0.1626	Eval_AUC: 0.8314
Epoch 43 Global_step 3551000	Train_loss: 0.1660	Eval_AUC: 0.8321
Epoch 43 Global_step 3552000	Train_loss: 0.1655	Eval_AUC: 0.8335
Epoch 43 Global_step 3553000	Train_loss: 0.1621	Eval_AUC: 0.8326
Epoch 43 Global_step 3554000	Train_loss: 0.1677	Eval_AUC: 0.8325
Epoch 43 Global_step 3555000	Train_loss: 0.1704	Eval_AUC: 0.8312
Epoch 43 Global_step 3556000	Train_loss: 0.1671	Eval_AUC: 0.8336
Epoch 43 Global_step 3557000	Train_loss: 0.1637	Eval_AUC: 0.8335
Epoch 43 Global_step 3558000	Train_loss: 0.1655	Eval_AUC: 0.8318
Epoch 43 Global_step 3559000	Train_loss: 0.1640	Eval_AUC: 0.8331
Epoch 43 Global_step 3560000	Train_loss: 0.1653	Eval_AUC: 0.8322
Epoch 43 Global_step 3561000	Train_loss: 0.1697	Eval_AUC: 0.8360
Epoch 43 Global_step 3562000	Train_loss: 0.1696	Eval_AUC: 0.8327
Epoch 43 Global_step 3563000	Train_loss: 0.1702	Eval_AUC: 0.8326
Epoch 43 Global_step 3564000	Train_loss: 0.1650	Eval_AUC: 0.8328
Epoch 43 Global_step 3565000	Train_loss: 0.1672	Eval_AUC: 0.8332
Epoch 43 Global_step 3566000	Train_loss: 0.1653	Eval_AUC: 0.8317
Epoch 43 Global_step 3567000	Train_loss: 0.1702	Eval_AUC: 0.8334
Epoch 43 Global_step 3568000	Train_loss: 0.1701	Eval_AUC: 0.8352
Epoch 43 Global_step 3569000	Train_loss: 0.1650	Eval_AUC: 0.8307
Epoch 43 Global_step 3570000	Train_loss: 0.1764	Eval_AUC: 0.8344
Epoch 43 Global_step 3571000	Train_loss: 0.1691	Eval_AUC: 0.8345
Epoch 43 Global_step 3572000	Train_loss: 0.1737	Eval_AUC: 0.8337
Epoch 43 Global_step 3573000	Train_loss: 0.1749	Eval_AUC: 0.8329
Epoch 43 Global_step 3574000	Train_loss: 0.1743	Eval_AUC: 0.8321
Epoch 43 Global_step 3575000	Train_loss: 0.1776	Eval_AUC: 0.8360
Epoch 43 Global_step 3576000	Train_loss: 0.1760	Eval_AUC: 0.8342
Epoch 43 Global_step 3577000	Train_loss: 0.1723	Eval_AUC: 0.8348
Epoch 43 Global_step 3578000	Train_loss: 0.1767	Eval_AUC: 0.8318
Epoch 43 Global_step 3579000	Train_loss: 0.1718	Eval_AUC: 0.8355
Epoch 43 Global_step 3580000	Train_loss: 0.1740	Eval_AUC: 0.8342
Epoch 43 Global_step 3581000	Train_loss: 0.1777	Eval_AUC: 0.8348
Epoch 43 Global_step 3582000	Train_loss: 0.1766	Eval_AUC: 0.8346
Epoch 43 Global_step 3583000	Train_loss: 0.1743	Eval_AUC: 0.8363
Epoch 43 Global_step 3584000	Train_loss: 0.1762	Eval_AUC: 0.8354
Epoch 43 Global_step 3585000	Train_loss: 0.1788	Eval_AUC: 0.8339
Epoch 43 Global_step 3586000	Train_loss: 0.1732	Eval_AUC: 0.8327
Epoch 43 Global_step 3587000	Train_loss: 0.1746	Eval_AUC: 0.8327
Epoch 43 DONE	Cost time: 37753.46
Epoch 44 Global_step 3588000	Train_loss: 0.1327	Eval_AUC: 0.8342
Epoch 44 Global_step 3589000	Train_loss: 0.1417	Eval_AUC: 0.8363
Epoch 44 Global_step 3590000	Train_loss: 0.1398	Eval_AUC: 0.8349
Epoch 44 Global_step 3591000	Train_loss: 0.1364	Eval_AUC: 0.8347
Epoch 44 Global_step 3592000	Train_loss: 0.1372	Eval_AUC: 0.8335
Epoch 44 Global_step 3593000	Train_loss: 0.1378	Eval_AUC: 0.8347
Epoch 44 Global_step 3594000	Train_loss: 0.1382	Eval_AUC: 0.8332
Epoch 44 Global_step 3595000	Train_loss: 0.1384	Eval_AUC: 0.8327
Epoch 44 Global_step 3596000	Train_loss: 0.1401	Eval_AUC: 0.8334
Epoch 44 Global_step 3597000	Train_loss: 0.1390	Eval_AUC: 0.8326
Epoch 44 Global_step 3598000	Train_loss: 0.1389	Eval_AUC: 0.8348
Epoch 44 Global_step 3599000	Train_loss: 0.1445	Eval_AUC: 0.8347
Epoch 44 Global_step 3600000	Train_loss: 0.1451	Eval_AUC: 0.8319
Epoch 44 Global_step 3601000	Train_loss: 0.1374	Eval_AUC: 0.8324
Epoch 44 Global_step 3602000	Train_loss: 0.1410	Eval_AUC: 0.8296
Epoch 44 Global_step 3603000	Train_loss: 0.1406	Eval_AUC: 0.8333
Epoch 44 Global_step 3604000	Train_loss: 0.1448	Eval_AUC: 0.8308
Epoch 44 Global_step 3605000	Train_loss: 0.1475	Eval_AUC: 0.8337
Epoch 44 Global_step 3606000	Train_loss: 0.1419	Eval_AUC: 0.8321
Epoch 44 Global_step 3607000	Train_loss: 0.1439	Eval_AUC: 0.8340
Epoch 44 Global_step 3608000	Train_loss: 0.1460	Eval_AUC: 0.8333
Epoch 44 Global_step 3609000	Train_loss: 0.1450	Eval_AUC: 0.8339
Epoch 44 Global_step 3610000	Train_loss: 0.1516	Eval_AUC: 0.8313
Epoch 44 Global_step 3611000	Train_loss: 0.1496	Eval_AUC: 0.8342
Epoch 44 Global_step 3612000	Train_loss: 0.1507	Eval_AUC: 0.8352
Epoch 44 Global_step 3613000	Train_loss: 0.1452	Eval_AUC: 0.8337
Epoch 44 Global_step 3614000	Train_loss: 0.1491	Eval_AUC: 0.8319
Epoch 44 Global_step 3615000	Train_loss: 0.1517	Eval_AUC: 0.8318
Epoch 44 Global_step 3616000	Train_loss: 0.1529	Eval_AUC: 0.8339
Epoch 44 Global_step 3617000	Train_loss: 0.1529	Eval_AUC: 0.8342
Epoch 44 Global_step 3618000	Train_loss: 0.1518	Eval_AUC: 0.8336
Epoch 44 Global_step 3619000	Train_loss: 0.1521	Eval_AUC: 0.8333
Epoch 44 Global_step 3620000	Train_loss: 0.1524	Eval_AUC: 0.8293
Epoch 44 Global_step 3621000	Train_loss: 0.1505	Eval_AUC: 0.8333
Epoch 44 Global_step 3622000	Train_loss: 0.1621	Eval_AUC: 0.8324
Epoch 44 Global_step 3623000	Train_loss: 0.1555	Eval_AUC: 0.8323
Epoch 44 Global_step 3624000	Train_loss: 0.1558	Eval_AUC: 0.8313
Epoch 44 Global_step 3625000	Train_loss: 0.1539	Eval_AUC: 0.8334
Epoch 44 Global_step 3626000	Train_loss: 0.1577	Eval_AUC: 0.8328
Epoch 44 Global_step 3627000	Train_loss: 0.1593	Eval_AUC: 0.8336
Epoch 44 Global_step 3628000	Train_loss: 0.1546	Eval_AUC: 0.8348
Epoch 44 Global_step 3629000	Train_loss: 0.1631	Eval_AUC: 0.8325
Epoch 44 Global_step 3630000	Train_loss: 0.1589	Eval_AUC: 0.8320
Epoch 44 Global_step 3631000	Train_loss: 0.1656	Eval_AUC: 0.8323
Epoch 44 Global_step 3632000	Train_loss: 0.1602	Eval_AUC: 0.8324
Epoch 44 Global_step 3633000	Train_loss: 0.1621	Eval_AUC: 0.8312
Epoch 44 Global_step 3634000	Train_loss: 0.1616	Eval_AUC: 0.8341
Epoch 44 Global_step 3635000	Train_loss: 0.1596	Eval_AUC: 0.8348
Epoch 44 Global_step 3636000	Train_loss: 0.1619	Eval_AUC: 0.8323
Epoch 44 Global_step 3637000	Train_loss: 0.1605	Eval_AUC: 0.8339
Epoch 44 Global_step 3638000	Train_loss: 0.1667	Eval_AUC: 0.8342
Epoch 44 Global_step 3639000	Train_loss: 0.1613	Eval_AUC: 0.8336
Epoch 44 Global_step 3640000	Train_loss: 0.1594	Eval_AUC: 0.8345
Epoch 44 Global_step 3641000	Train_loss: 0.1621	Eval_AUC: 0.8322
Epoch 44 Global_step 3642000	Train_loss: 0.1623	Eval_AUC: 0.8324
Epoch 44 Global_step 3643000	Train_loss: 0.1636	Eval_AUC: 0.8335
Epoch 44 Global_step 3644000	Train_loss: 0.1713	Eval_AUC: 0.8348
Epoch 44 Global_step 3645000	Train_loss: 0.1624	Eval_AUC: 0.8333
Epoch 44 Global_step 3646000	Train_loss: 0.1573	Eval_AUC: 0.8324
Epoch 44 Global_step 3647000	Train_loss: 0.1622	Eval_AUC: 0.8310
Epoch 44 Global_step 3648000	Train_loss: 0.1635	Eval_AUC: 0.8337
Epoch 44 Global_step 3649000	Train_loss: 0.1635	Eval_AUC: 0.8296
Epoch 44 Global_step 3650000	Train_loss: 0.1660	Eval_AUC: 0.8329
Epoch 44 Global_step 3651000	Train_loss: 0.1754	Eval_AUC: 0.8321
Epoch 44 Global_step 3652000	Train_loss: 0.1604	Eval_AUC: 0.8331
Epoch 44 Global_step 3653000	Train_loss: 0.1732	Eval_AUC: 0.8329
Epoch 44 Global_step 3654000	Train_loss: 0.1699	Eval_AUC: 0.8329
Epoch 44 Global_step 3655000	Train_loss: 0.1658	Eval_AUC: 0.8342
Epoch 44 Global_step 3656000	Train_loss: 0.1666	Eval_AUC: 0.8351
Epoch 44 Global_step 3657000	Train_loss: 0.1686	Eval_AUC: 0.8345
Epoch 44 Global_step 3658000	Train_loss: 0.1728	Eval_AUC: 0.8336
Epoch 44 Global_step 3659000	Train_loss: 0.1697	Eval_AUC: 0.8341
Epoch 44 Global_step 3660000	Train_loss: 0.1694	Eval_AUC: 0.8347
Epoch 44 Global_step 3661000	Train_loss: 0.1741	Eval_AUC: 0.8341
Epoch 44 Global_step 3662000	Train_loss: 0.1680	Eval_AUC: 0.8362
Epoch 44 Global_step 3663000	Train_loss: 0.1697	Eval_AUC: 0.8342
Epoch 44 Global_step 3664000	Train_loss: 0.1753	Eval_AUC: 0.8342
Epoch 44 Global_step 3665000	Train_loss: 0.1704	Eval_AUC: 0.8318
Epoch 44 Global_step 3666000	Train_loss: 0.1740	Eval_AUC: 0.8362
Epoch 44 Global_step 3667000	Train_loss: 0.1758	Eval_AUC: 0.8334
Epoch 44 Global_step 3668000	Train_loss: 0.1769	Eval_AUC: 0.8321
Epoch 44 DONE	Cost time: 38578.42
Epoch 45 Global_step 3669000	Train_loss: 0.0573	Eval_AUC: 0.8351
Epoch 45 Global_step 3670000	Train_loss: 0.1353	Eval_AUC: 0.8344
Epoch 45 Global_step 3671000	Train_loss: 0.1364	Eval_AUC: 0.8346
Epoch 45 Global_step 3672000	Train_loss: 0.1328	Eval_AUC: 0.8329
Epoch 45 Global_step 3673000	Train_loss: 0.1389	Eval_AUC: 0.8345
Epoch 45 Global_step 3674000	Train_loss: 0.1379	Eval_AUC: 0.8320
Epoch 45 Global_step 3675000	Train_loss: 0.1369	Eval_AUC: 0.8333
Epoch 45 Global_step 3676000	Train_loss: 0.1387	Eval_AUC: 0.8336
Epoch 45 Global_step 3677000	Train_loss: 0.1362	Eval_AUC: 0.8334
Epoch 45 Global_step 3678000	Train_loss: 0.1349	Eval_AUC: 0.8321
Epoch 45 Global_step 3679000	Train_loss: 0.1421	Eval_AUC: 0.8356
Epoch 45 Global_step 3680000	Train_loss: 0.1388	Eval_AUC: 0.8330
Epoch 45 Global_step 3681000	Train_loss: 0.1418	Eval_AUC: 0.8335
Epoch 45 Global_step 3682000	Train_loss: 0.1388	Eval_AUC: 0.8319
Epoch 45 Global_step 3683000	Train_loss: 0.1390	Eval_AUC: 0.8311
Epoch 45 Global_step 3684000	Train_loss: 0.1359	Eval_AUC: 0.8343
Epoch 45 Global_step 3685000	Train_loss: 0.1382	Eval_AUC: 0.8337
Epoch 45 Global_step 3686000	Train_loss: 0.1378	Eval_AUC: 0.8340
Epoch 45 Global_step 3687000	Train_loss: 0.1434	Eval_AUC: 0.8305
Epoch 45 Global_step 3688000	Train_loss: 0.1457	Eval_AUC: 0.8318
Epoch 45 Global_step 3689000	Train_loss: 0.1421	Eval_AUC: 0.8325
Epoch 45 Global_step 3690000	Train_loss: 0.1435	Eval_AUC: 0.8337
Epoch 45 Global_step 3691000	Train_loss: 0.1451	Eval_AUC: 0.8346
Epoch 45 Global_step 3692000	Train_loss: 0.1502	Eval_AUC: 0.8348
Epoch 45 Global_step 3693000	Train_loss: 0.1427	Eval_AUC: 0.8334
Epoch 45 Global_step 3694000	Train_loss: 0.1492	Eval_AUC: 0.8317
Epoch 45 Global_step 3695000	Train_loss: 0.1452	Eval_AUC: 0.8327
Epoch 45 Global_step 3696000	Train_loss: 0.1471	Eval_AUC: 0.8344
Epoch 45 Global_step 3697000	Train_loss: 0.1534	Eval_AUC: 0.8335
Epoch 45 Global_step 3698000	Train_loss: 0.1492	Eval_AUC: 0.8325
Epoch 45 Global_step 3699000	Train_loss: 0.1431	Eval_AUC: 0.8338
Epoch 45 Global_step 3700000	Train_loss: 0.1469	Eval_AUC: 0.8341
Epoch 45 Global_step 3701000	Train_loss: 0.1541	Eval_AUC: 0.8336
Epoch 45 Global_step 3702000	Train_loss: 0.1489	Eval_AUC: 0.8325
Epoch 45 Global_step 3703000	Train_loss: 0.1543	Eval_AUC: 0.8349
Epoch 45 Global_step 3704000	Train_loss: 0.1505	Eval_AUC: 0.8306
Epoch 45 Global_step 3705000	Train_loss: 0.1543	Eval_AUC: 0.8334
Epoch 45 Global_step 3706000	Train_loss: 0.1501	Eval_AUC: 0.8304
Epoch 45 Global_step 3707000	Train_loss: 0.1480	Eval_AUC: 0.8349
Epoch 45 Global_step 3708000	Train_loss: 0.1588	Eval_AUC: 0.8336
Epoch 45 Global_step 3709000	Train_loss: 0.1590	Eval_AUC: 0.8329
Epoch 45 Global_step 3710000	Train_loss: 0.1591	Eval_AUC: 0.8290
Epoch 45 Global_step 3711000	Train_loss: 0.1582	Eval_AUC: 0.8312
Epoch 45 Global_step 3712000	Train_loss: 0.1565	Eval_AUC: 0.8341
Epoch 45 Global_step 3713000	Train_loss: 0.1551	Eval_AUC: 0.8306
Epoch 45 Global_step 3714000	Train_loss: 0.1594	Eval_AUC: 0.8302
Epoch 45 Global_step 3715000	Train_loss: 0.1526	Eval_AUC: 0.8326
Epoch 45 Global_step 3716000	Train_loss: 0.1553	Eval_AUC: 0.8335
Epoch 45 Global_step 3717000	Train_loss: 0.1566	Eval_AUC: 0.8333
Epoch 45 Global_step 3718000	Train_loss: 0.1607	Eval_AUC: 0.8315
Epoch 45 Global_step 3719000	Train_loss: 0.1582	Eval_AUC: 0.8335
Epoch 45 Global_step 3720000	Train_loss: 0.1628	Eval_AUC: 0.8336
Epoch 45 Global_step 3721000	Train_loss: 0.1590	Eval_AUC: 0.8323
Epoch 45 Global_step 3722000	Train_loss: 0.1580	Eval_AUC: 0.8295
Epoch 45 Global_step 3723000	Train_loss: 0.1629	Eval_AUC: 0.8352
Epoch 45 Global_step 3724000	Train_loss: 0.1611	Eval_AUC: 0.8321
Epoch 45 Global_step 3725000	Train_loss: 0.1585	Eval_AUC: 0.8325
Epoch 45 Global_step 3726000	Train_loss: 0.1616	Eval_AUC: 0.8303
Epoch 45 Global_step 3727000	Train_loss: 0.1615	Eval_AUC: 0.8328
Epoch 45 Global_step 3728000	Train_loss: 0.1646	Eval_AUC: 0.8328
Epoch 45 Global_step 3729000	Train_loss: 0.1649	Eval_AUC: 0.8318
Epoch 45 Global_step 3730000	Train_loss: 0.1631	Eval_AUC: 0.8327
Epoch 45 Global_step 3731000	Train_loss: 0.1662	Eval_AUC: 0.8314
Epoch 45 Global_step 3732000	Train_loss: 0.1657	Eval_AUC: 0.8324
Epoch 45 Global_step 3733000	Train_loss: 0.1665	Eval_AUC: 0.8321
Epoch 45 Global_step 3734000	Train_loss: 0.1709	Eval_AUC: 0.8308
Epoch 45 Global_step 3735000	Train_loss: 0.1680	Eval_AUC: 0.8328
Epoch 45 Global_step 3736000	Train_loss: 0.1651	Eval_AUC: 0.8325
Epoch 45 Global_step 3737000	Train_loss: 0.1640	Eval_AUC: 0.8295
Epoch 45 Global_step 3738000	Train_loss: 0.1602	Eval_AUC: 0.8343
Epoch 45 Global_step 3739000	Train_loss: 0.1607	Eval_AUC: 0.8356
Epoch 45 Global_step 3740000	Train_loss: 0.1706	Eval_AUC: 0.8351
Epoch 45 Global_step 3741000	Train_loss: 0.1652	Eval_AUC: 0.8354
Epoch 45 Global_step 3742000	Train_loss: 0.1638	Eval_AUC: 0.8344
Epoch 45 Global_step 3743000	Train_loss: 0.1696	Eval_AUC: 0.8340
Epoch 45 Global_step 3744000	Train_loss: 0.1703	Eval_AUC: 0.8334
Epoch 45 Global_step 3745000	Train_loss: 0.1711	Eval_AUC: 0.8342
Epoch 45 Global_step 3746000	Train_loss: 0.1691	Eval_AUC: 0.8360
Epoch 45 Global_step 3747000	Train_loss: 0.1629	Eval_AUC: 0.8342
Epoch 45 Global_step 3748000	Train_loss: 0.1677	Eval_AUC: 0.8323
Epoch 45 Global_step 3749000	Train_loss: 0.1741	Eval_AUC: 0.8344
Epoch 45 Global_step 3750000	Train_loss: 0.1727	Eval_AUC: 0.8315
Epoch 45 DONE	Cost time: 39381.19
Epoch 46 Global_step 3751000	Train_loss: 0.1226	Eval_AUC: 0.8335
Epoch 46 Global_step 3752000	Train_loss: 0.1389	Eval_AUC: 0.8310
Epoch 46 Global_step 3753000	Train_loss: 0.1304	Eval_AUC: 0.8343
Epoch 46 Global_step 3754000	Train_loss: 0.1375	Eval_AUC: 0.8328
Epoch 46 Global_step 3755000	Train_loss: 0.1352	Eval_AUC: 0.8348
Epoch 46 Global_step 3756000	Train_loss: 0.1288	Eval_AUC: 0.8345
Epoch 46 Global_step 3757000	Train_loss: 0.1297	Eval_AUC: 0.8322
Epoch 46 Global_step 3758000	Train_loss: 0.1331	Eval_AUC: 0.8339
Epoch 46 Global_step 3759000	Train_loss: 0.1367	Eval_AUC: 0.8320
Epoch 46 Global_step 3760000	Train_loss: 0.1367	Eval_AUC: 0.8342
Epoch 46 Global_step 3761000	Train_loss: 0.1331	Eval_AUC: 0.8337
Epoch 46 Global_step 3762000	Train_loss: 0.1368	Eval_AUC: 0.8318
Epoch 46 Global_step 3763000	Train_loss: 0.1379	Eval_AUC: 0.8321
Epoch 46 Global_step 3764000	Train_loss: 0.1388	Eval_AUC: 0.8302
Epoch 46 Global_step 3765000	Train_loss: 0.1442	Eval_AUC: 0.8322
Epoch 46 Global_step 3766000	Train_loss: 0.1441	Eval_AUC: 0.8314
Epoch 46 Global_step 3767000	Train_loss: 0.1422	Eval_AUC: 0.8316
Epoch 46 Global_step 3768000	Train_loss: 0.1405	Eval_AUC: 0.8327
Epoch 46 Global_step 3769000	Train_loss: 0.1365	Eval_AUC: 0.8330
Epoch 46 Global_step 3770000	Train_loss: 0.1410	Eval_AUC: 0.8313
Epoch 46 Global_step 3771000	Train_loss: 0.1397	Eval_AUC: 0.8305
Epoch 46 Global_step 3772000	Train_loss: 0.1413	Eval_AUC: 0.8325
Epoch 46 Global_step 3773000	Train_loss: 0.1400	Eval_AUC: 0.8339
Epoch 46 Global_step 3774000	Train_loss: 0.1373	Eval_AUC: 0.8331
Epoch 46 Global_step 3775000	Train_loss: 0.1424	Eval_AUC: 0.8300
Epoch 46 Global_step 3776000	Train_loss: 0.1442	Eval_AUC: 0.8336
Epoch 46 Global_step 3777000	Train_loss: 0.1492	Eval_AUC: 0.8346
Epoch 46 Global_step 3778000	Train_loss: 0.1414	Eval_AUC: 0.8317
Epoch 46 Global_step 3779000	Train_loss: 0.1449	Eval_AUC: 0.8326
Epoch 46 Global_step 3780000	Train_loss: 0.1458	Eval_AUC: 0.8299
Epoch 46 Global_step 3781000	Train_loss: 0.1472	Eval_AUC: 0.8327
Epoch 46 Global_step 3782000	Train_loss: 0.1469	Eval_AUC: 0.8323
Epoch 46 Global_step 3783000	Train_loss: 0.1416	Eval_AUC: 0.8315
Epoch 46 Global_step 3784000	Train_loss: 0.1476	Eval_AUC: 0.8332
Epoch 46 Global_step 3785000	Train_loss: 0.1508	Eval_AUC: 0.8315
Epoch 46 Global_step 3786000	Train_loss: 0.1518	Eval_AUC: 0.8316
Epoch 46 Global_step 3787000	Train_loss: 0.1535	Eval_AUC: 0.8312
Epoch 46 Global_step 3788000	Train_loss: 0.1506	Eval_AUC: 0.8313
Epoch 46 Global_step 3789000	Train_loss: 0.1472	Eval_AUC: 0.8323
Epoch 46 Global_step 3790000	Train_loss: 0.1465	Eval_AUC: 0.8309
Epoch 46 Global_step 3791000	Train_loss: 0.1492	Eval_AUC: 0.8311
Epoch 46 Global_step 3792000	Train_loss: 0.1494	Eval_AUC: 0.8318
Epoch 46 Global_step 3793000	Train_loss: 0.1480	Eval_AUC: 0.8361
Epoch 46 Global_step 3794000	Train_loss: 0.1549	Eval_AUC: 0.8328
Epoch 46 Global_step 3795000	Train_loss: 0.1510	Eval_AUC: 0.8324
Epoch 46 Global_step 3796000	Train_loss: 0.1513	Eval_AUC: 0.8324
Epoch 46 Global_step 3797000	Train_loss: 0.1514	Eval_AUC: 0.8327
Epoch 46 Global_step 3798000	Train_loss: 0.1511	Eval_AUC: 0.8321
Epoch 46 Global_step 3799000	Train_loss: 0.1540	Eval_AUC: 0.8308
Epoch 46 Global_step 3800000	Train_loss: 0.1543	Eval_AUC: 0.8313
Epoch 46 Global_step 3801000	Train_loss: 0.1545	Eval_AUC: 0.8333
Epoch 46 Global_step 3802000	Train_loss: 0.1578	Eval_AUC: 0.8322
Epoch 46 Global_step 3803000	Train_loss: 0.1571	Eval_AUC: 0.8334
Epoch 46 Global_step 3804000	Train_loss: 0.1539	Eval_AUC: 0.8319
Epoch 46 Global_step 3805000	Train_loss: 0.1583	Eval_AUC: 0.8315
Epoch 46 Global_step 3806000	Train_loss: 0.1529	Eval_AUC: 0.8313
Epoch 46 Global_step 3807000	Train_loss: 0.1572	Eval_AUC: 0.8300
Epoch 46 Global_step 3808000	Train_loss: 0.1636	Eval_AUC: 0.8315
Epoch 46 Global_step 3809000	Train_loss: 0.1585	Eval_AUC: 0.8316
Epoch 46 Global_step 3810000	Train_loss: 0.1621	Eval_AUC: 0.8315
Epoch 46 Global_step 3811000	Train_loss: 0.1554	Eval_AUC: 0.8321
Epoch 46 Global_step 3812000	Train_loss: 0.1614	Eval_AUC: 0.8330
Epoch 46 Global_step 3813000	Train_loss: 0.1602	Eval_AUC: 0.8330
Epoch 46 Global_step 3814000	Train_loss: 0.1573	Eval_AUC: 0.8327
Epoch 46 Global_step 3815000	Train_loss: 0.1621	Eval_AUC: 0.8299
Epoch 46 Global_step 3816000	Train_loss: 0.1628	Eval_AUC: 0.8306
Epoch 46 Global_step 3817000	Train_loss: 0.1591	Eval_AUC: 0.8305
Epoch 46 Global_step 3818000	Train_loss: 0.1646	Eval_AUC: 0.8312
Epoch 46 Global_step 3819000	Train_loss: 0.1621	Eval_AUC: 0.8287
Epoch 46 Global_step 3820000	Train_loss: 0.1683	Eval_AUC: 0.8316
Epoch 46 Global_step 3821000	Train_loss: 0.1657	Eval_AUC: 0.8326
Epoch 46 Global_step 3822000	Train_loss: 0.1611	Eval_AUC: 0.8324
Epoch 46 Global_step 3823000	Train_loss: 0.1679	Eval_AUC: 0.8319
Epoch 46 Global_step 3824000	Train_loss: 0.1703	Eval_AUC: 0.8308
Epoch 46 Global_step 3825000	Train_loss: 0.1629	Eval_AUC: 0.8340
Epoch 46 Global_step 3826000	Train_loss: 0.1659	Eval_AUC: 0.8337
Epoch 46 Global_step 3827000	Train_loss: 0.1630	Eval_AUC: 0.8306
Epoch 46 Global_step 3828000	Train_loss: 0.1677	Eval_AUC: 0.8327
Epoch 46 Global_step 3829000	Train_loss: 0.1674	Eval_AUC: 0.8331
Epoch 46 Global_step 3830000	Train_loss: 0.1694	Eval_AUC: 0.8319
Epoch 46 Global_step 3831000	Train_loss: 0.1675	Eval_AUC: 0.8319
Epoch 46 DONE	Cost time: 40024.93
Epoch 47 Global_step 3832000	Train_loss: 0.0485	Eval_AUC: 0.8327
Epoch 47 Global_step 3833000	Train_loss: 0.1283	Eval_AUC: 0.8321
Epoch 47 Global_step 3834000	Train_loss: 0.1296	Eval_AUC: 0.8335
Epoch 47 Global_step 3835000	Train_loss: 0.1286	Eval_AUC: 0.8342
Epoch 47 Global_step 3836000	Train_loss: 0.1301	Eval_AUC: 0.8328
Epoch 47 Global_step 3837000	Train_loss: 0.1273	Eval_AUC: 0.8297
Epoch 47 Global_step 3838000	Train_loss: 0.1323	Eval_AUC: 0.8332
Epoch 47 Global_step 3839000	Train_loss: 0.1294	Eval_AUC: 0.8344
Epoch 47 Global_step 3840000	Train_loss: 0.1309	Eval_AUC: 0.8316
Epoch 47 Global_step 3841000	Train_loss: 0.1323	Eval_AUC: 0.8330
Epoch 47 Global_step 3842000	Train_loss: 0.1378	Eval_AUC: 0.8320
Epoch 47 Global_step 3843000	Train_loss: 0.1304	Eval_AUC: 0.8315
Epoch 47 Global_step 3844000	Train_loss: 0.1357	Eval_AUC: 0.8300
Epoch 47 Global_step 3845000	Train_loss: 0.1333	Eval_AUC: 0.8327
Epoch 47 Global_step 3846000	Train_loss: 0.1367	Eval_AUC: 0.8296
Epoch 47 Global_step 3847000	Train_loss: 0.1325	Eval_AUC: 0.8310
Epoch 47 Global_step 3848000	Train_loss: 0.1347	Eval_AUC: 0.8306
Epoch 47 Global_step 3849000	Train_loss: 0.1361	Eval_AUC: 0.8331
Epoch 47 Global_step 3850000	Train_loss: 0.1354	Eval_AUC: 0.8315
Epoch 47 Global_step 3851000	Train_loss: 0.1376	Eval_AUC: 0.8312
Epoch 47 Global_step 3852000	Train_loss: 0.1340	Eval_AUC: 0.8308
Epoch 47 Global_step 3853000	Train_loss: 0.1402	Eval_AUC: 0.8305
Epoch 47 Global_step 3854000	Train_loss: 0.1424	Eval_AUC: 0.8316
Epoch 47 Global_step 3855000	Train_loss: 0.1394	Eval_AUC: 0.8342
Epoch 47 Global_step 3856000	Train_loss: 0.1437	Eval_AUC: 0.8342
Epoch 47 Global_step 3857000	Train_loss: 0.1367	Eval_AUC: 0.8291
Epoch 47 Global_step 3858000	Train_loss: 0.1408	Eval_AUC: 0.8307
Epoch 47 Global_step 3859000	Train_loss: 0.1425	Eval_AUC: 0.8308
Epoch 47 Global_step 3860000	Train_loss: 0.1420	Eval_AUC: 0.8316
Epoch 47 Global_step 3861000	Train_loss: 0.1412	Eval_AUC: 0.8302
Epoch 47 Global_step 3862000	Train_loss: 0.1413	Eval_AUC: 0.8325
Epoch 47 Global_step 3863000	Train_loss: 0.1440	Eval_AUC: 0.8313
Epoch 47 Global_step 3864000	Train_loss: 0.1394	Eval_AUC: 0.8314
Epoch 47 Global_step 3865000	Train_loss: 0.1460	Eval_AUC: 0.8319
Epoch 47 Global_step 3866000	Train_loss: 0.1446	Eval_AUC: 0.8313
Epoch 47 Global_step 3867000	Train_loss: 0.1408	Eval_AUC: 0.8317
Epoch 47 Global_step 3868000	Train_loss: 0.1434	Eval_AUC: 0.8329
Epoch 47 Global_step 3869000	Train_loss: 0.1489	Eval_AUC: 0.8322
Epoch 47 Global_step 3870000	Train_loss: 0.1445	Eval_AUC: 0.8328
Epoch 47 Global_step 3871000	Train_loss: 0.1478	Eval_AUC: 0.8306
Epoch 47 Global_step 3872000	Train_loss: 0.1509	Eval_AUC: 0.8273
Epoch 47 Global_step 3873000	Train_loss: 0.1506	Eval_AUC: 0.8339
Epoch 47 Global_step 3874000	Train_loss: 0.1490	Eval_AUC: 0.8312
Epoch 47 Global_step 3875000	Train_loss: 0.1478	Eval_AUC: 0.8312
Epoch 47 Global_step 3876000	Train_loss: 0.1467	Eval_AUC: 0.8312
Epoch 47 Global_step 3877000	Train_loss: 0.1493	Eval_AUC: 0.8325
Epoch 47 Global_step 3878000	Train_loss: 0.1504	Eval_AUC: 0.8310
Epoch 47 Global_step 3879000	Train_loss: 0.1460	Eval_AUC: 0.8308
Epoch 47 Global_step 3880000	Train_loss: 0.1526	Eval_AUC: 0.8317
Epoch 47 Global_step 3881000	Train_loss: 0.1510	Eval_AUC: 0.8319
Epoch 47 Global_step 3882000	Train_loss: 0.1533	Eval_AUC: 0.8317
Epoch 47 Global_step 3883000	Train_loss: 0.1545	Eval_AUC: 0.8305
Epoch 47 Global_step 3884000	Train_loss: 0.1543	Eval_AUC: 0.8281
Epoch 47 Global_step 3885000	Train_loss: 0.1539	Eval_AUC: 0.8311
Epoch 47 Global_step 3886000	Train_loss: 0.1532	Eval_AUC: 0.8339
Epoch 47 Global_step 3887000	Train_loss: 0.1533	Eval_AUC: 0.8321
Epoch 47 Global_step 3888000	Train_loss: 0.1560	Eval_AUC: 0.8320
Epoch 47 Global_step 3889000	Train_loss: 0.1556	Eval_AUC: 0.8304
Epoch 47 Global_step 3890000	Train_loss: 0.1570	Eval_AUC: 0.8321
Epoch 47 Global_step 3891000	Train_loss: 0.1648	Eval_AUC: 0.8301
Epoch 47 Global_step 3892000	Train_loss: 0.1647	Eval_AUC: 0.8311
Epoch 47 Global_step 3893000	Train_loss: 0.1556	Eval_AUC: 0.8324
Epoch 47 Global_step 3894000	Train_loss: 0.1600	Eval_AUC: 0.8345
Epoch 47 Global_step 3895000	Train_loss: 0.1543	Eval_AUC: 0.8327
Epoch 47 Global_step 3896000	Train_loss: 0.1530	Eval_AUC: 0.8315
Epoch 47 Global_step 3897000	Train_loss: 0.1624	Eval_AUC: 0.8298
Epoch 47 Global_step 3898000	Train_loss: 0.1541	Eval_AUC: 0.8310
Epoch 47 Global_step 3899000	Train_loss: 0.1585	Eval_AUC: 0.8311
Epoch 47 Global_step 3900000	Train_loss: 0.1579	Eval_AUC: 0.8336
Epoch 47 Global_step 3901000	Train_loss: 0.1589	Eval_AUC: 0.8339
Epoch 47 Global_step 3902000	Train_loss: 0.1553	Eval_AUC: 0.8331
Epoch 47 Global_step 3903000	Train_loss: 0.1570	Eval_AUC: 0.8341
Epoch 47 Global_step 3904000	Train_loss: 0.1639	Eval_AUC: 0.8314
Epoch 47 Global_step 3905000	Train_loss: 0.1630	Eval_AUC: 0.8345
Epoch 47 Global_step 3906000	Train_loss: 0.1628	Eval_AUC: 0.8308
Epoch 47 Global_step 3907000	Train_loss: 0.1600	Eval_AUC: 0.8326
Epoch 47 Global_step 3908000	Train_loss: 0.1602	Eval_AUC: 0.8304
Epoch 47 Global_step 3909000	Train_loss: 0.1642	Eval_AUC: 0.8332
Epoch 47 Global_step 3910000	Train_loss: 0.1630	Eval_AUC: 0.8313
Epoch 47 Global_step 3911000	Train_loss: 0.1635	Eval_AUC: 0.8320
Epoch 47 Global_step 3912000	Train_loss: 0.1597	Eval_AUC: 0.8324
Epoch 47 Global_step 3913000	Train_loss: 0.1642	Eval_AUC: 0.8348
Epoch 47 DONE	Cost time: 40671.76
Epoch 48 Global_step 3914000	Train_loss: 0.1128	Eval_AUC: 0.8325
Epoch 48 Global_step 3915000	Train_loss: 0.1248	Eval_AUC: 0.8345
Epoch 48 Global_step 3916000	Train_loss: 0.1290	Eval_AUC: 0.8318
Epoch 48 Global_step 3917000	Train_loss: 0.1290	Eval_AUC: 0.8322
Epoch 48 Global_step 3918000	Train_loss: 0.1261	Eval_AUC: 0.8328
Epoch 48 Global_step 3919000	Train_loss: 0.1287	Eval_AUC: 0.8309
Epoch 48 Global_step 3920000	Train_loss: 0.1290	Eval_AUC: 0.8328
Epoch 48 Global_step 3921000	Train_loss: 0.1294	Eval_AUC: 0.8303
Epoch 48 Global_step 3922000	Train_loss: 0.1284	Eval_AUC: 0.8306
Epoch 48 Global_step 3923000	Train_loss: 0.1303	Eval_AUC: 0.8328
Epoch 48 Global_step 3924000	Train_loss: 0.1269	Eval_AUC: 0.8313
Epoch 48 Global_step 3925000	Train_loss: 0.1306	Eval_AUC: 0.8314
Epoch 48 Global_step 3926000	Train_loss: 0.1297	Eval_AUC: 0.8321
Epoch 48 Global_step 3927000	Train_loss: 0.1246	Eval_AUC: 0.8313
Epoch 48 Global_step 3928000	Train_loss: 0.1322	Eval_AUC: 0.8319
Epoch 48 Global_step 3929000	Train_loss: 0.1334	Eval_AUC: 0.8306
Epoch 48 Global_step 3930000	Train_loss: 0.1295	Eval_AUC: 0.8310
Epoch 48 Global_step 3931000	Train_loss: 0.1296	Eval_AUC: 0.8299
Epoch 48 Global_step 3932000	Train_loss: 0.1321	Eval_AUC: 0.8324
Epoch 48 Global_step 3933000	Train_loss: 0.1332	Eval_AUC: 0.8310
Epoch 48 Global_step 3934000	Train_loss: 0.1298	Eval_AUC: 0.8303
Epoch 48 Global_step 3935000	Train_loss: 0.1345	Eval_AUC: 0.8305
Epoch 48 Global_step 3936000	Train_loss: 0.1352	Eval_AUC: 0.8285
Epoch 48 Global_step 3937000	Train_loss: 0.1401	Eval_AUC: 0.8328
Epoch 48 Global_step 3938000	Train_loss: 0.1340	Eval_AUC: 0.8313
Epoch 48 Global_step 3939000	Train_loss: 0.1407	Eval_AUC: 0.8317
Epoch 48 Global_step 3940000	Train_loss: 0.1345	Eval_AUC: 0.8307
Epoch 48 Global_step 3941000	Train_loss: 0.1365	Eval_AUC: 0.8329
Epoch 48 Global_step 3942000	Train_loss: 0.1395	Eval_AUC: 0.8294
Epoch 48 Global_step 3943000	Train_loss: 0.1374	Eval_AUC: 0.8307
Epoch 48 Global_step 3944000	Train_loss: 0.1388	Eval_AUC: 0.8313
Epoch 48 Global_step 3945000	Train_loss: 0.1405	Eval_AUC: 0.8318
Epoch 48 Global_step 3946000	Train_loss: 0.1447	Eval_AUC: 0.8327
Epoch 48 Global_step 3947000	Train_loss: 0.1416	Eval_AUC: 0.8286
Epoch 48 Global_step 3948000	Train_loss: 0.1374	Eval_AUC: 0.8323
Epoch 48 Global_step 3949000	Train_loss: 0.1409	Eval_AUC: 0.8323
Epoch 48 Global_step 3950000	Train_loss: 0.1431	Eval_AUC: 0.8293
Epoch 48 Global_step 3951000	Train_loss: 0.1470	Eval_AUC: 0.8278
Epoch 48 Global_step 3952000	Train_loss: 0.1434	Eval_AUC: 0.8303
Epoch 48 Global_step 3953000	Train_loss: 0.1456	Eval_AUC: 0.8305
Epoch 48 Global_step 3954000	Train_loss: 0.1457	Eval_AUC: 0.8300
Epoch 48 Global_step 3955000	Train_loss: 0.1383	Eval_AUC: 0.8285
Epoch 48 Global_step 3956000	Train_loss: 0.1433	Eval_AUC: 0.8301
Epoch 48 Global_step 3957000	Train_loss: 0.1422	Eval_AUC: 0.8298
Epoch 48 Global_step 3958000	Train_loss: 0.1478	Eval_AUC: 0.8306
Epoch 48 Global_step 3959000	Train_loss: 0.1465	Eval_AUC: 0.8311
Epoch 48 Global_step 3960000	Train_loss: 0.1460	Eval_AUC: 0.8320
Epoch 48 Global_step 3961000	Train_loss: 0.1469	Eval_AUC: 0.8302
Epoch 48 Global_step 3962000	Train_loss: 0.1449	Eval_AUC: 0.8330
Epoch 48 Global_step 3963000	Train_loss: 0.1513	Eval_AUC: 0.8292
Epoch 48 Global_step 3964000	Train_loss: 0.1508	Eval_AUC: 0.8304
Epoch 48 Global_step 3965000	Train_loss: 0.1487	Eval_AUC: 0.8316
Epoch 48 Global_step 3966000	Train_loss: 0.1498	Eval_AUC: 0.8302
Epoch 48 Global_step 3967000	Train_loss: 0.1527	Eval_AUC: 0.8301
Epoch 48 Global_step 3968000	Train_loss: 0.1537	Eval_AUC: 0.8308
Epoch 48 Global_step 3969000	Train_loss: 0.1445	Eval_AUC: 0.8315
Epoch 48 Global_step 3970000	Train_loss: 0.1498	Eval_AUC: 0.8299
Epoch 48 Global_step 3971000	Train_loss: 0.1526	Eval_AUC: 0.8325
Epoch 48 Global_step 3972000	Train_loss: 0.1515	Eval_AUC: 0.8318
Epoch 48 Global_step 3973000	Train_loss: 0.1503	Eval_AUC: 0.8331
Epoch 48 Global_step 3974000	Train_loss: 0.1586	Eval_AUC: 0.8282
Epoch 48 Global_step 3975000	Train_loss: 0.1536	Eval_AUC: 0.8322
Epoch 48 Global_step 3976000	Train_loss: 0.1574	Eval_AUC: 0.8325
Epoch 48 Global_step 3977000	Train_loss: 0.1539	Eval_AUC: 0.8315
Epoch 48 Global_step 3978000	Train_loss: 0.1545	Eval_AUC: 0.8288
Epoch 48 Global_step 3979000	Train_loss: 0.1568	Eval_AUC: 0.8318
Epoch 48 Global_step 3980000	Train_loss: 0.1615	Eval_AUC: 0.8328
Epoch 48 Global_step 3981000	Train_loss: 0.1570	Eval_AUC: 0.8286
Epoch 48 Global_step 3982000	Train_loss: 0.1558	Eval_AUC: 0.8324
Epoch 48 Global_step 3983000	Train_loss: 0.1555	Eval_AUC: 0.8331
Epoch 48 Global_step 3984000	Train_loss: 0.1548	Eval_AUC: 0.8316
Epoch 48 Global_step 3985000	Train_loss: 0.1626	Eval_AUC: 0.8326
Epoch 48 Global_step 3986000	Train_loss: 0.1586	Eval_AUC: 0.8298
Epoch 48 Global_step 3987000	Train_loss: 0.1599	Eval_AUC: 0.8303
Epoch 48 Global_step 3988000	Train_loss: 0.1583	Eval_AUC: 0.8320
Epoch 48 Global_step 3989000	Train_loss: 0.1593	Eval_AUC: 0.8308
Epoch 48 Global_step 3990000	Train_loss: 0.1548	Eval_AUC: 0.8301
Epoch 48 Global_step 3991000	Train_loss: 0.1557	Eval_AUC: 0.8317
Epoch 48 Global_step 3992000	Train_loss: 0.1616	Eval_AUC: 0.8303
Epoch 48 Global_step 3993000	Train_loss: 0.1621	Eval_AUC: 0.8326
Epoch 48 Global_step 3994000	Train_loss: 0.1542	Eval_AUC: 0.8331
Epoch 48 DONE	Cost time: 41315.44
Epoch 49 Global_step 3995000	Train_loss: 0.0415	Eval_AUC: 0.8330
Epoch 49 Global_step 3996000	Train_loss: 0.1270	Eval_AUC: 0.8322
Epoch 49 Global_step 3997000	Train_loss: 0.1248	Eval_AUC: 0.8333
Epoch 49 Global_step 3998000	Train_loss: 0.1201	Eval_AUC: 0.8336
Epoch 49 Global_step 3999000	Train_loss: 0.1272	Eval_AUC: 0.8297
Epoch 49 Global_step 4000000	Train_loss: 0.1230	Eval_AUC: 0.8308
Epoch 49 Global_step 4001000	Train_loss: 0.1231	Eval_AUC: 0.8302
Epoch 49 Global_step 4002000	Train_loss: 0.1230	Eval_AUC: 0.8324
Epoch 49 Global_step 4003000	Train_loss: 0.1284	Eval_AUC: 0.8308
Epoch 49 Global_step 4004000	Train_loss: 0.1262	Eval_AUC: 0.8334
Epoch 49 Global_step 4005000	Train_loss: 0.1269	Eval_AUC: 0.8323
Epoch 49 Global_step 4006000	Train_loss: 0.1240	Eval_AUC: 0.8319
Epoch 49 Global_step 4007000	Train_loss: 0.1283	Eval_AUC: 0.8323
Epoch 49 Global_step 4008000	Train_loss: 0.1257	Eval_AUC: 0.8322
Epoch 49 Global_step 4009000	Train_loss: 0.1232	Eval_AUC: 0.8309
Epoch 49 Global_step 4010000	Train_loss: 0.1268	Eval_AUC: 0.8314
Epoch 49 Global_step 4011000	Train_loss: 0.1297	Eval_AUC: 0.8326
Epoch 49 Global_step 4012000	Train_loss: 0.1300	Eval_AUC: 0.8305
Epoch 49 Global_step 4013000	Train_loss: 0.1335	Eval_AUC: 0.8329
Epoch 49 Global_step 4014000	Train_loss: 0.1315	Eval_AUC: 0.8297
Epoch 49 Global_step 4015000	Train_loss: 0.1317	Eval_AUC: 0.8311
Epoch 49 Global_step 4016000	Train_loss: 0.1321	Eval_AUC: 0.8282
Epoch 49 Global_step 4017000	Train_loss: 0.1314	Eval_AUC: 0.8316
Epoch 49 Global_step 4018000	Train_loss: 0.1336	Eval_AUC: 0.8296
Epoch 49 Global_step 4019000	Train_loss: 0.1292	Eval_AUC: 0.8293
Epoch 49 Global_step 4020000	Train_loss: 0.1343	Eval_AUC: 0.8302
Epoch 49 Global_step 4021000	Train_loss: 0.1304	Eval_AUC: 0.8307
Epoch 49 Global_step 4022000	Train_loss: 0.1321	Eval_AUC: 0.8278
Epoch 49 Global_step 4023000	Train_loss: 0.1367	Eval_AUC: 0.8321
Epoch 49 Global_step 4024000	Train_loss: 0.1357	Eval_AUC: 0.8311
Epoch 49 Global_step 4025000	Train_loss: 0.1367	Eval_AUC: 0.8312
Epoch 49 Global_step 4026000	Train_loss: 0.1403	Eval_AUC: 0.8311
Epoch 49 Global_step 4027000	Train_loss: 0.1405	Eval_AUC: 0.8287
Epoch 49 Global_step 4028000	Train_loss: 0.1427	Eval_AUC: 0.8300
Epoch 49 Global_step 4029000	Train_loss: 0.1436	Eval_AUC: 0.8309
Epoch 49 Global_step 4030000	Train_loss: 0.1349	Eval_AUC: 0.8293
Epoch 49 Global_step 4031000	Train_loss: 0.1380	Eval_AUC: 0.8329
Epoch 49 Global_step 4032000	Train_loss: 0.1428	Eval_AUC: 0.8320
Epoch 49 Global_step 4033000	Train_loss: 0.1375	Eval_AUC: 0.8294
Epoch 49 Global_step 4034000	Train_loss: 0.1413	Eval_AUC: 0.8290
Epoch 49 Global_step 4035000	Train_loss: 0.1386	Eval_AUC: 0.8296
Epoch 49 Global_step 4036000	Train_loss: 0.1433	Eval_AUC: 0.8293
Epoch 49 Global_step 4037000	Train_loss: 0.1380	Eval_AUC: 0.8318
Epoch 49 Global_step 4038000	Train_loss: 0.1461	Eval_AUC: 0.8283
Epoch 49 Global_step 4039000	Train_loss: 0.1414	Eval_AUC: 0.8332
Epoch 49 Global_step 4040000	Train_loss: 0.1435	Eval_AUC: 0.8311
Epoch 49 Global_step 4041000	Train_loss: 0.1410	Eval_AUC: 0.8305
Epoch 49 Global_step 4042000	Train_loss: 0.1440	Eval_AUC: 0.8292
Epoch 49 Global_step 4043000	Train_loss: 0.1452	Eval_AUC: 0.8297
Epoch 49 Global_step 4044000	Train_loss: 0.1428	Eval_AUC: 0.8300
Epoch 49 Global_step 4045000	Train_loss: 0.1464	Eval_AUC: 0.8301
Epoch 49 Global_step 4046000	Train_loss: 0.1489	Eval_AUC: 0.8322
Epoch 49 Global_step 4047000	Train_loss: 0.1468	Eval_AUC: 0.8318
Epoch 49 Global_step 4048000	Train_loss: 0.1482	Eval_AUC: 0.8304
Epoch 49 Global_step 4049000	Train_loss: 0.1472	Eval_AUC: 0.8302
Epoch 49 Global_step 4050000	Train_loss: 0.1461	Eval_AUC: 0.8343
Epoch 49 Global_step 4051000	Train_loss: 0.1461	Eval_AUC: 0.8330
Epoch 49 Global_step 4052000	Train_loss: 0.1448	Eval_AUC: 0.8319
Epoch 49 Global_step 4053000	Train_loss: 0.1480	Eval_AUC: 0.8306
Epoch 49 Global_step 4054000	Train_loss: 0.1546	Eval_AUC: 0.8280
Epoch 49 Global_step 4055000	Train_loss: 0.1506	Eval_AUC: 0.8306
Epoch 49 Global_step 4056000	Train_loss: 0.1514	Eval_AUC: 0.8291
Epoch 49 Global_step 4057000	Train_loss: 0.1549	Eval_AUC: 0.8311
Epoch 49 Global_step 4058000	Train_loss: 0.1468	Eval_AUC: 0.8301
Epoch 49 Global_step 4059000	Train_loss: 0.1512	Eval_AUC: 0.8306
Epoch 49 Global_step 4060000	Train_loss: 0.1519	Eval_AUC: 0.8324
Epoch 49 Global_step 4061000	Train_loss: 0.1515	Eval_AUC: 0.8319
Epoch 49 Global_step 4062000	Train_loss: 0.1538	Eval_AUC: 0.8325
Epoch 49 Global_step 4063000	Train_loss: 0.1536	Eval_AUC: 0.8288
Epoch 49 Global_step 4064000	Train_loss: 0.1522	Eval_AUC: 0.8318
Epoch 49 Global_step 4065000	Train_loss: 0.1555	Eval_AUC: 0.8301
Epoch 49 Global_step 4066000	Train_loss: 0.1564	Eval_AUC: 0.8300
Epoch 49 Global_step 4067000	Train_loss: 0.1507	Eval_AUC: 0.8305
Epoch 49 Global_step 4068000	Train_loss: 0.1508	Eval_AUC: 0.8309
Epoch 49 Global_step 4069000	Train_loss: 0.1545	Eval_AUC: 0.8277
Epoch 49 Global_step 4070000	Train_loss: 0.1601	Eval_AUC: 0.8292
Epoch 49 Global_step 4071000	Train_loss: 0.1529	Eval_AUC: 0.8304
Epoch 49 Global_step 4072000	Train_loss: 0.1615	Eval_AUC: 0.8293
Epoch 49 Global_step 4073000	Train_loss: 0.1582	Eval_AUC: 0.8305
Epoch 49 Global_step 4074000	Train_loss: 0.1569	Eval_AUC: 0.8318
Epoch 49 Global_step 4075000	Train_loss: 0.1616	Eval_AUC: 0.8302
Epoch 49 Global_step 4076000	Train_loss: 0.1585	Eval_AUC: 0.8325
Epoch 49 DONE	Cost time: 41961.89
('best test_auc:', 0.881956102563628)
